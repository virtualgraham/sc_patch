{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, datasets\n",
    " \n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    " \n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    " \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm # progress bar\n",
    "\n",
    "import skimage\n",
    "from skimage import img_as_ubyte, img_as_float32\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import math\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Parameters \n",
    "#########################################\n",
    "\n",
    "viz_image_paths = glob('/Users/racoon/Downloads/open-images-sample/*.jpg')\n",
    "training_image_paths = glob('/data/open-images-dataset/train/*.jpg')\n",
    "validation_image_paths = glob('/data/open-images-dataset/validation/*.jpg')\n",
    "\n",
    "train_dataset_length = 409600\n",
    "validation_dataset_length = 20480\n",
    "train_batch_size = 1024\n",
    "validation_batch_size = 1024\n",
    "num_epochs = 1500\n",
    "save_after_epochs = 1 \n",
    "backup_after_epochs = 5 \n",
    "model_save_prefix = \"variation_a\"\n",
    "reuse_image_count = 4\n",
    "\n",
    "patch_dim = 32\n",
    "gap = 10\n",
    "jitter = 5\n",
    "gray_portion = .30\n",
    "\n",
    "learn_rate = 0.0001\n",
    "momentum = 0.974\n",
    "weight_decay = 0.0005\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Utilities \n",
    "#########################################\n",
    "\n",
    "def imshow(img,text=None,should_save=False):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
    "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()  \n",
    "\n",
    "def show_plot(iteration,loss,fname):\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.savefig(fname)\n",
    "    plt.show()\n",
    "    \n",
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        for i, t in enumerate(tensor):\n",
    "            t.mul_(self.std[i%3]).add_(self.mean[i%3])\n",
    "        return tensor\n",
    "\n",
    "unorm = UnNormalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#########################################\n",
    "# This class generates patches for training\n",
    "#########################################\n",
    "\n",
    "patch_order_arr = [\n",
    "  (0, 1, 2, 3),\n",
    "  (0, 1, 3, 2),\n",
    "  (0, 2, 1, 3),\n",
    "  (0, 2, 3, 1),\n",
    "  (0, 3, 1, 2),\n",
    "  (0, 3, 2, 1),\n",
    "  (1, 0, 2, 3),\n",
    "  (1, 0, 3, 2),\n",
    "  (1, 2, 0, 3),\n",
    "  (1, 2, 3, 0),\n",
    "  (1, 3, 0, 2),\n",
    "  (1, 3, 2, 0),\n",
    "  (2, 0, 1, 3),\n",
    "  (2, 0, 3, 1),\n",
    "  (2, 1, 0, 3),\n",
    "  (2, 1, 3, 0),\n",
    "  (2, 3, 0, 1),\n",
    "  (2, 3, 1, 0),\n",
    "  (3, 0, 1, 2),\n",
    "  (3, 0, 2, 1),\n",
    "  (3, 1, 0, 2),\n",
    "  (3, 1, 2, 0),\n",
    "  (3, 2, 0, 1),\n",
    "  (3, 2, 1, 0)\n",
    "]\n",
    "\n",
    "class ShufflePatchDataset(Dataset):\n",
    "\n",
    "  def __init__(self, image_paths, patch_dim, length, gap, jitter, transform=None):\n",
    "    self.image_paths = image_paths\n",
    "    self.patch_dim = patch_dim\n",
    "    self.length = length\n",
    "    self.gap = gap\n",
    "    self.jitter = jitter\n",
    "    self.transform = transform\n",
    "    self.color_shift = 2\n",
    "    self.margin = math.ceil((2*patch_dim + 2*jitter + 2*self.color_shift + gap)/2)\n",
    "    self.min_width = 2 * self.margin + 1\n",
    "    self.image_reused = 0\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.length\n",
    "  \n",
    "  def half_gap(self):\n",
    "    return math.ceil(self.gap/2)\n",
    "\n",
    "  def random_jitter(self):\n",
    "    return int(math.floor((self.jitter * 2 * random.random()))) - self.jitter\n",
    "\n",
    "  def random_shift(self):\n",
    "    return random.randrange(self.color_shift * 2 + 1)\n",
    "\n",
    "  # crops the patch by self.color_shift on each side\n",
    "  def prep_patch(self, image, gray):\n",
    " \n",
    "    cropped = np.empty((self.patch_dim, self.patch_dim, 3), dtype=np.uint8)\n",
    "\n",
    "    if(gray):\n",
    "\n",
    "      pil_patch = Image.fromarray(image)\n",
    "      pil_patch = pil_patch.convert('L')\n",
    "      pil_patch = pil_patch.convert('RGB')\n",
    "      np.copyto(cropped, np.array(pil_patch)[self.color_shift:self.color_shift+self.patch_dim, self.color_shift:self.color_shift+self.patch_dim, :])\n",
    "      \n",
    "    else:\n",
    "\n",
    "      shift = [self.random_shift() for _ in range(6)]\n",
    "      cropped[:,:,0] = image[shift[0]:shift[0]+self.patch_dim, shift[1]:shift[1]+self.patch_dim, 0]\n",
    "      cropped[:,:,1] = image[shift[2]:shift[2]+self.patch_dim, shift[3]:shift[3]+self.patch_dim, 1]\n",
    "      cropped[:,:,2] = image[shift[4]:shift[4]+self.patch_dim, shift[5]:shift[5]+self.patch_dim, 2]\n",
    "\n",
    "    return cropped\n",
    "\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    # [y, x, chan], dtype=uint8, top_left is (0,0)\n",
    "    \n",
    "    image_index = int(math.floor((len(self.image_paths) * random.random())))\n",
    "    \n",
    "    if self.image_reused == 0:\n",
    "      pil_image = Image.open(self.image_paths[image_index]).convert('RGB')\n",
    "      self.pil_image = pil_image.resize((int(round(pil_image.size[0]/3)), int(round(pil_image.size[1]/3))))\n",
    "      self.image_reused = reuse_image_count\n",
    "    else:\n",
    "      self.image_reused -= 1\n",
    "\n",
    "    image = np.array(self.pil_image)\n",
    "\n",
    "    # If image is too small, try another image\n",
    "    if (image.shape[0] - self.min_width) <= 0 or (image.shape[1] - self.min_width) <= 0:\n",
    "        return self.__getitem__(index)\n",
    "    \n",
    "    center_y_coord = int(math.floor((image.shape[0] - self.margin*2) * random.random())) + self.margin\n",
    "    center_x_coord = int(math.floor((image.shape[1] - self.margin*2) * random.random())) + self.margin\n",
    "\n",
    "    patch_coords = [\n",
    "      (\n",
    "        center_y_coord - (self.patch_dim + self.half_gap() + self.random_jitter() + self.color_shift),\n",
    "        center_x_coord - (self.patch_dim + self.half_gap() + self.random_jitter() + self.color_shift)\n",
    "      ),\n",
    "      (\n",
    "        center_y_coord - (self.patch_dim + self.half_gap() + self.random_jitter() + self.color_shift),\n",
    "        center_x_coord + self.half_gap() + self.random_jitter() - self.color_shift\n",
    "      ),\n",
    "      (\n",
    "        center_y_coord + self.half_gap() + self.random_jitter() - self.color_shift,\n",
    "        center_x_coord - (self.patch_dim + self.half_gap() + self.random_jitter() + self.color_shift)\n",
    "      ),\n",
    "      (\n",
    "        center_y_coord + self.half_gap() + self.random_jitter() - self.color_shift,\n",
    "        center_x_coord + self.half_gap() + self.random_jitter() - self.color_shift\n",
    "      )\n",
    "    ]\n",
    "    \n",
    "    patch_shuffle_order_label = int(math.floor((24 * random.random())))\n",
    "\n",
    "    patch_coords = [pc for _,pc in sorted(zip(patch_order_arr[patch_shuffle_order_label],patch_coords))]\n",
    "\n",
    "    patch_a = image[patch_coords[0][0]:patch_coords[0][0]+self.patch_dim+2*self.color_shift, patch_coords[0][1]:patch_coords[0][1]+self.patch_dim+2*self.color_shift]\n",
    "    patch_b = image[patch_coords[1][0]:patch_coords[1][0]+self.patch_dim+2*self.color_shift, patch_coords[1][1]:patch_coords[1][1]+self.patch_dim+2*self.color_shift]\n",
    "    patch_c = image[patch_coords[2][0]:patch_coords[2][0]+self.patch_dim+2*self.color_shift, patch_coords[2][1]:patch_coords[2][1]+self.patch_dim+2*self.color_shift]\n",
    "    patch_d = image[patch_coords[3][0]:patch_coords[3][0]+self.patch_dim+2*self.color_shift, patch_coords[3][1]:patch_coords[3][1]+self.patch_dim+2*self.color_shift]\n",
    "\n",
    "    gray = random.random() < gray_portion\n",
    "\n",
    "    patch_a = self.prep_patch(patch_a, gray)\n",
    "    patch_b = self.prep_patch(patch_b, gray)\n",
    "    patch_c = self.prep_patch(patch_c, gray)\n",
    "    patch_d = self.prep_patch(patch_d, gray)\n",
    "\n",
    "    patch_shuffle_order_label = np.array(patch_shuffle_order_label).astype(np.int64)\n",
    "        \n",
    "    if self.transform:\n",
    "      patch_a = self.transform(patch_a)\n",
    "      patch_b = self.transform(patch_b)\n",
    "      patch_c = self.transform(patch_c)\n",
    "      patch_d = self.transform(patch_d)\n",
    "\n",
    "    return patch_a, patch_b, patch_c, patch_d, patch_shuffle_order_label\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##################################################\n",
    "# Creating Train/Validation dataset and dataloader\n",
    "##################################################\n",
    "\n",
    "traindataset = ShufflePatchDataset(training_image_paths, patch_dim, train_dataset_length, gap, jitter,\n",
    "                         transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(traindataset, \n",
    "                                          batch_size=train_batch_size,\n",
    "                                          num_workers=4,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "valdataset = ShufflePatchDataset(validation_image_paths, patch_dim, validation_dataset_length, gap, jitter,\n",
    "                         transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valdataset,\n",
    "                                        batch_size=validation_batch_size,\n",
    "                                        num_workers=4,\n",
    "                                        shuffle=False)\n",
    "\n",
    "\n",
    "vizdataset = ShufflePatchDataset(viz_image_paths, patch_dim, 1, gap, jitter,\n",
    "                         transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "\n",
    "vizloader = torch.utils.data.DataLoader(vizdataset,\n",
    "                                        batch_size=1,\n",
    "                                        shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [2]\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "# Visualizing validation dataset\n",
    "#############################\n",
    "\n",
    "example_batch_val = next(iter(vizloader))\n",
    "concatenated = torch.cat((unorm(example_batch_val[0]),unorm(example_batch_val[1]),unorm(example_batch_val[2]),unorm(example_batch_val[3])),0)\n",
    "imshow(torchvision.utils.make_grid(concatenated))\n",
    "print(f'Labels: {example_batch_val[4].numpy()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
      "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
      "              ReLU-6           [-1, 64, 32, 32]               0\n",
      "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
      "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
      "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
      "             ReLU-10          [-1, 128, 16, 16]               0\n",
      "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
      "             ReLU-13          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
      "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
      "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
      "             ReLU-17            [-1, 256, 8, 8]               0\n",
      "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
      "             ReLU-20            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-21            [-1, 256, 4, 4]               0\n",
      "           Conv2d-22            [-1, 512, 4, 4]       1,180,160\n",
      "      BatchNorm2d-23            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-24            [-1, 512, 4, 4]               0\n",
      "           Conv2d-25            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-27            [-1, 512, 4, 4]               0\n",
      "        MaxPool2d-28            [-1, 512, 2, 2]               0\n",
      "           Conv2d-29            [-1, 512, 2, 2]       2,359,808\n",
      "      BatchNorm2d-30            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-31            [-1, 512, 2, 2]               0\n",
      "           Conv2d-32            [-1, 512, 2, 2]       2,359,808\n",
      "      BatchNorm2d-33            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-34            [-1, 512, 2, 2]               0\n",
      "        MaxPool2d-35            [-1, 512, 1, 1]               0\n",
      "           Linear-36                 [-1, 1024]         525,312\n",
      "             ReLU-37                 [-1, 1024]               0\n",
      "          Dropout-38                 [-1, 1024]               0\n",
      "           Conv2d-39           [-1, 64, 32, 32]           1,792\n",
      "      BatchNorm2d-40           [-1, 64, 32, 32]             128\n",
      "             ReLU-41           [-1, 64, 32, 32]               0\n",
      "           Conv2d-42           [-1, 64, 32, 32]          36,928\n",
      "      BatchNorm2d-43           [-1, 64, 32, 32]             128\n",
      "             ReLU-44           [-1, 64, 32, 32]               0\n",
      "        MaxPool2d-45           [-1, 64, 16, 16]               0\n",
      "           Conv2d-46          [-1, 128, 16, 16]          73,856\n",
      "      BatchNorm2d-47          [-1, 128, 16, 16]             256\n",
      "             ReLU-48          [-1, 128, 16, 16]               0\n",
      "           Conv2d-49          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-50          [-1, 128, 16, 16]             256\n",
      "             ReLU-51          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-52            [-1, 128, 8, 8]               0\n",
      "           Conv2d-53            [-1, 256, 8, 8]         295,168\n",
      "      BatchNorm2d-54            [-1, 256, 8, 8]             512\n",
      "             ReLU-55            [-1, 256, 8, 8]               0\n",
      "           Conv2d-56            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-57            [-1, 256, 8, 8]             512\n",
      "             ReLU-58            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-59            [-1, 256, 4, 4]               0\n",
      "           Conv2d-60            [-1, 512, 4, 4]       1,180,160\n",
      "      BatchNorm2d-61            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-62            [-1, 512, 4, 4]               0\n",
      "           Conv2d-63            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-64            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-65            [-1, 512, 4, 4]               0\n",
      "        MaxPool2d-66            [-1, 512, 2, 2]               0\n",
      "           Conv2d-67            [-1, 512, 2, 2]       2,359,808\n",
      "      BatchNorm2d-68            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-69            [-1, 512, 2, 2]               0\n",
      "           Conv2d-70            [-1, 512, 2, 2]       2,359,808\n",
      "      BatchNorm2d-71            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-72            [-1, 512, 2, 2]               0\n",
      "        MaxPool2d-73            [-1, 512, 1, 1]               0\n",
      "           Linear-74                 [-1, 1024]         525,312\n",
      "             ReLU-75                 [-1, 1024]               0\n",
      "          Dropout-76                 [-1, 1024]               0\n",
      "           Conv2d-77           [-1, 64, 32, 32]           1,792\n",
      "      BatchNorm2d-78           [-1, 64, 32, 32]             128\n",
      "             ReLU-79           [-1, 64, 32, 32]               0\n",
      "           Conv2d-80           [-1, 64, 32, 32]          36,928\n",
      "      BatchNorm2d-81           [-1, 64, 32, 32]             128\n",
      "             ReLU-82           [-1, 64, 32, 32]               0\n",
      "        MaxPool2d-83           [-1, 64, 16, 16]               0\n",
      "           Conv2d-84          [-1, 128, 16, 16]          73,856\n",
      "      BatchNorm2d-85          [-1, 128, 16, 16]             256\n",
      "             ReLU-86          [-1, 128, 16, 16]               0\n",
      "           Conv2d-87          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-88          [-1, 128, 16, 16]             256\n",
      "             ReLU-89          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-90            [-1, 128, 8, 8]               0\n",
      "           Conv2d-91            [-1, 256, 8, 8]         295,168\n",
      "      BatchNorm2d-92            [-1, 256, 8, 8]             512\n",
      "             ReLU-93            [-1, 256, 8, 8]               0\n",
      "           Conv2d-94            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-95            [-1, 256, 8, 8]             512\n",
      "             ReLU-96            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-97            [-1, 256, 4, 4]               0\n",
      "           Conv2d-98            [-1, 512, 4, 4]       1,180,160\n",
      "      BatchNorm2d-99            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-100            [-1, 512, 4, 4]               0\n",
      "          Conv2d-101            [-1, 512, 4, 4]       2,359,808\n",
      "     BatchNorm2d-102            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-103            [-1, 512, 4, 4]               0\n",
      "       MaxPool2d-104            [-1, 512, 2, 2]               0\n",
      "          Conv2d-105            [-1, 512, 2, 2]       2,359,808\n",
      "     BatchNorm2d-106            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-107            [-1, 512, 2, 2]               0\n",
      "          Conv2d-108            [-1, 512, 2, 2]       2,359,808\n",
      "     BatchNorm2d-109            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-110            [-1, 512, 2, 2]               0\n",
      "       MaxPool2d-111            [-1, 512, 1, 1]               0\n",
      "          Linear-112                 [-1, 1024]         525,312\n",
      "            ReLU-113                 [-1, 1024]               0\n",
      "         Dropout-114                 [-1, 1024]               0\n",
      "          Conv2d-115           [-1, 64, 32, 32]           1,792\n",
      "     BatchNorm2d-116           [-1, 64, 32, 32]             128\n",
      "            ReLU-117           [-1, 64, 32, 32]               0\n",
      "          Conv2d-118           [-1, 64, 32, 32]          36,928\n",
      "     BatchNorm2d-119           [-1, 64, 32, 32]             128\n",
      "            ReLU-120           [-1, 64, 32, 32]               0\n",
      "       MaxPool2d-121           [-1, 64, 16, 16]               0\n",
      "          Conv2d-122          [-1, 128, 16, 16]          73,856\n",
      "     BatchNorm2d-123          [-1, 128, 16, 16]             256\n",
      "            ReLU-124          [-1, 128, 16, 16]               0\n",
      "          Conv2d-125          [-1, 128, 16, 16]         147,584\n",
      "     BatchNorm2d-126          [-1, 128, 16, 16]             256\n",
      "            ReLU-127          [-1, 128, 16, 16]               0\n",
      "       MaxPool2d-128            [-1, 128, 8, 8]               0\n",
      "          Conv2d-129            [-1, 256, 8, 8]         295,168\n",
      "     BatchNorm2d-130            [-1, 256, 8, 8]             512\n",
      "            ReLU-131            [-1, 256, 8, 8]               0\n",
      "          Conv2d-132            [-1, 256, 8, 8]         590,080\n",
      "     BatchNorm2d-133            [-1, 256, 8, 8]             512\n",
      "            ReLU-134            [-1, 256, 8, 8]               0\n",
      "       MaxPool2d-135            [-1, 256, 4, 4]               0\n",
      "          Conv2d-136            [-1, 512, 4, 4]       1,180,160\n",
      "     BatchNorm2d-137            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-138            [-1, 512, 4, 4]               0\n",
      "          Conv2d-139            [-1, 512, 4, 4]       2,359,808\n",
      "     BatchNorm2d-140            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-141            [-1, 512, 4, 4]               0\n",
      "       MaxPool2d-142            [-1, 512, 2, 2]               0\n",
      "          Conv2d-143            [-1, 512, 2, 2]       2,359,808\n",
      "     BatchNorm2d-144            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-145            [-1, 512, 2, 2]               0\n",
      "          Conv2d-146            [-1, 512, 2, 2]       2,359,808\n",
      "     BatchNorm2d-147            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-148            [-1, 512, 2, 2]               0\n",
      "       MaxPool2d-149            [-1, 512, 1, 1]               0\n",
      "          Linear-150                 [-1, 1024]         525,312\n",
      "            ReLU-151                 [-1, 1024]               0\n",
      "         Dropout-152                 [-1, 1024]               0\n",
      "          Linear-153                 [-1, 4096]      16,781,312\n",
      "            ReLU-154                 [-1, 4096]               0\n",
      "         Dropout-155                 [-1, 4096]               0\n",
      "          Linear-156                   [-1, 24]          98,328\n",
      "================================================================\n",
      "Total params: 56,624,408\n",
      "Trainable params: 56,624,408\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 339738624.00\n",
      "Forward/backward pass size (MB): 24.02\n",
      "Params size (MB): 216.00\n",
      "Estimated Total Size (MB): 339738864.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "# Model for learning patch position\n",
    "##################################################\n",
    "\n",
    "class VggNetwork(nn.Module):\n",
    "  def __init__(self,aux_logits = False):\n",
    "\n",
    "      super(VggNetwork, self).__init__()\n",
    "\n",
    "      self.cnn = nn.Sequential(\n",
    "\n",
    "        nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(64), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(64), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "        nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(128), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(128), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "        nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(256), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(256), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "        nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "      )\n",
    "    \n",
    "      self.fc6 = nn.Sequential(\n",
    "        nn.Linear(512, 1024),\n",
    "        nn.ReLU(True),\n",
    "        nn.Dropout(),\n",
    "      )\n",
    "\n",
    "      self.fc = nn.Sequential(\n",
    "        nn.Linear(4*1024, 4096),\n",
    "        nn.ReLU(True),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(4096, 24),\n",
    "      )\n",
    "\n",
    "  def forward_once(self, x):\n",
    "    output= self.cnn(x)\n",
    "    output = output.view(output.size()[0], -1)\n",
    "    output = self.fc6(output)\n",
    "    return output\n",
    "\n",
    "  def forward(self, patch_a, patch_b, patch_c, patch_d):\n",
    "    output_fc6_patch_a = self.forward_once(patch_a)\n",
    "    output_fc6_patch_b = self.forward_once(patch_b)\n",
    "    output_fc6_patch_c = self.forward_once(patch_c)\n",
    "    output_fc6_patch_d = self.forward_once(patch_d)\n",
    "\n",
    "    output = torch.cat((output_fc6_patch_a, output_fc6_patch_b, output_fc6_patch_c, output_fc6_patch_d), 1)\n",
    "    output = self.fc(output)\n",
    "\n",
    "    return output, output_fc6_patch_a, output_fc6_patch_b, output_fc6_patch_c, output_fc6_patch_d\n",
    "\n",
    "model = VggNetwork().to(device)\n",
    "summary(model, [(3, 32, 32), (3, 32, 32), (3, 32, 32), (3, 32, 32)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
