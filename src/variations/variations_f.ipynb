{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, datasets\n",
    " \n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    " \n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    " \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm # progress bar\n",
    "\n",
    "import skimage\n",
    "import cv2\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import math\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Parameters \n",
    "#########################################\n",
    "\n",
    "viz_image_paths = glob('/Users/racoon/Downloads/open-images-sample/*.jpg')\n",
    "training_image_paths = glob('/data/open-images-dataset/train/*.jpg')\n",
    "validation_image_paths = glob('/data/open-images-dataset/validation/*.jpg')\n",
    "\n",
    "train_dataset_length = 409600\n",
    "validation_dataset_length = 20480\n",
    "train_batch_size = 1024\n",
    "validation_batch_size = 1024\n",
    "num_epochs = 1500\n",
    "save_after_epochs = 1 \n",
    "backup_after_epochs = 5 \n",
    "model_save_prefix = \"variation_f\"\n",
    "reuse_image_count = 4\n",
    "\n",
    "patch_dim = 64\n",
    "\n",
    "learn_rate = 0.0001\n",
    "momentum = 0.974\n",
    "weight_decay = 0.0005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Utilities \n",
    "#########################################\n",
    "\n",
    "def imshow(img,text=None,should_save=False):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
    "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()  \n",
    "\n",
    "def show_plot(iteration,loss,fname):\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.savefig(fname)\n",
    "    plt.show()\n",
    "    \n",
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        for i, t in enumerate(tensor):\n",
    "            t.mul_(self.std[i%3]).add_(self.mean[i%3])\n",
    "        return tensor\n",
    "\n",
    "unorm = UnNormalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########################################\n",
    "# This class generates patches for training\n",
    "#########################################\n",
    "\n",
    "class ShufflePatchDataset(Dataset):\n",
    "\n",
    "  def __init__(self, image_paths, patch_dim, length, transform=None):\n",
    "    self.image_paths = image_paths\n",
    "    self.patch_dim = patch_dim\n",
    "    self.length = length\n",
    "    self.transform = transform\n",
    "    self.image_reused = 0\n",
    "    \n",
    "    self.margin = 10\n",
    "    self.window_width = self.patch_dim + 2*self.margin\n",
    "\n",
    "    self.min_image_width = self.window_width + 1\n",
    "\n",
    "    self.saliency = cv2.saliency.StaticSaliencyFineGrained_create()\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.length\n",
    "  \n",
    "\n",
    "  def saliency_check(self, window):\n",
    "    (success, saliency_map) = self.saliency.computeSaliency(cv2.cvtColor(window, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    patch_saliency_map = saliency_map[self.margin:self.margin+self.patch_dim, self.margin:self.margin+self.patch_dim]\n",
    "    patch_saliency = np.sum(patch_saliency_map > .5)\n",
    "    print('patch_saliency', patch_saliency)\n",
    "    \n",
    "    return patch_saliency >= 180 # 100 + 40 + 40\n",
    "\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    # [y, x, chan], dtype=uint8, top_left is (0,0)\n",
    "    \n",
    "    image_index = int(math.floor((len(self.image_paths) * random.random())))\n",
    "    \n",
    "    if self.image_reused == 0:\n",
    "      pil_image = Image.open(self.image_paths[image_index]).convert('RGB')\n",
    "      self.pil_image = pil_image.resize((int(round(pil_image.size[0]/3)), int(round(pil_image.size[1]/3))))\n",
    "      self.image_reused = reuse_image_count\n",
    "    else:\n",
    "      self.image_reused -= 1\n",
    "\n",
    "    image = np.array(self.pil_image)\n",
    "\n",
    "    # If image is too small, try another image\n",
    "    if (image.shape[0] - self.min_image_width) <= 0 or (image.shape[1] - self.min_image_width) <= 0:\n",
    "        return self.__getitem__(index)\n",
    "    \n",
    "    window_y_coord = int(math.floor((image.shape[0] - self.window_width) * random.random()))\n",
    "    window_x_coord = int(math.floor((image.shape[1] - self.window_width) * random.random()))\n",
    "\n",
    "    window = image[window_y_coord:window_y_coord+self.window_width, window_x_coord:window_x_coord+self.window_width]\n",
    "    \n",
    "    if not self.saliency_check(window):\n",
    "      return self.__getitem__(index)\n",
    "\n",
    "    rotation_label = int(math.floor((4 * random.random())))\n",
    "\n",
    "    if rotation_label>0:\n",
    "      window = np.rot90(window, rotation_label).copy()\n",
    "\n",
    "    patch = window[self.margin:self.margin+self.patch_dim, self.margin:self.margin+self.patch_dim]\n",
    "        \n",
    "    if self.transform:\n",
    "      patch = self.transform(patch)\n",
    "\n",
    "    return patch, np.array(rotation_label).astype(np.int64)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##################################################\n",
    "# Creating Train/Validation dataset and dataloader\n",
    "##################################################\n",
    "\n",
    "traindataset = ShufflePatchDataset(training_image_paths, patch_dim, train_dataset_length,\n",
    "                         transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(traindataset, \n",
    "                                          batch_size=train_batch_size,\n",
    "                                          num_workers=4,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "valdataset = ShufflePatchDataset(validation_image_paths, patch_dim, validation_dataset_length,\n",
    "                         transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valdataset,\n",
    "                                        batch_size=validation_batch_size,\n",
    "                                        num_workers=4,\n",
    "                                        shuffle=False)\n",
    "\n",
    "\n",
    "vizdataset = ShufflePatchDataset(viz_image_paths, patch_dim, 1, \n",
    "                         transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "\n",
    "vizloader = torch.utils.data.DataLoader(vizdataset,\n",
    "                                        batch_size=1,\n",
    "                                        shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch_saliency 3111\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-0d0ed0825d06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mexample_batch_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvizloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_batch_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Labels: {example_batch_val[4].numpy()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-49b38dae8056>\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(img, text, should_save)\u001b[0m\n\u001b[1;32m     10\u001b[0m         plt.text(75, 8, text, style='italic',fontweight='bold',\n\u001b[1;32m     11\u001b[0m             bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.5/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(a, axes)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m     \"\"\"\n\u001b[0;32m--> 653\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'transpose'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.5/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: axes don't match array"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#############################\n",
    "# Visualizing validation dataset\n",
    "#############################\n",
    "\n",
    "patch, label = next(iter(vizloader))\n",
    "concatenated = torch.cat((unorm(patch)),0)\n",
    "                         \n",
    "imshow(torchvision.utils.make_grid(concatenated, nrow=2))\n",
    "print(f'Labels: {example_batch_val[4].numpy()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
      "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
      "              ReLU-6           [-1, 64, 32, 32]               0\n",
      "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
      "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
      "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
      "             ReLU-10          [-1, 128, 16, 16]               0\n",
      "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
      "             ReLU-13          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
      "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
      "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
      "             ReLU-17            [-1, 256, 8, 8]               0\n",
      "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
      "             ReLU-20            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-21            [-1, 256, 4, 4]               0\n",
      "           Conv2d-22            [-1, 512, 4, 4]       1,180,160\n",
      "      BatchNorm2d-23            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-24            [-1, 512, 4, 4]               0\n",
      "           Conv2d-25            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-27            [-1, 512, 4, 4]               0\n",
      "        MaxPool2d-28            [-1, 512, 2, 2]               0\n",
      "           Conv2d-29            [-1, 512, 2, 2]       2,359,808\n",
      "      BatchNorm2d-30            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-31            [-1, 512, 2, 2]               0\n",
      "           Conv2d-32            [-1, 512, 2, 2]       2,359,808\n",
      "      BatchNorm2d-33            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-34            [-1, 512, 2, 2]               0\n",
      "        MaxPool2d-35            [-1, 512, 1, 1]               0\n",
      "           Linear-36                 [-1, 1024]         525,312\n",
      "             ReLU-37                 [-1, 1024]               0\n",
      "          Dropout-38                 [-1, 1024]               0\n",
      "           Conv2d-39           [-1, 64, 32, 32]           1,792\n",
      "      BatchNorm2d-40           [-1, 64, 32, 32]             128\n",
      "             ReLU-41           [-1, 64, 32, 32]               0\n",
      "           Conv2d-42           [-1, 64, 32, 32]          36,928\n",
      "      BatchNorm2d-43           [-1, 64, 32, 32]             128\n",
      "             ReLU-44           [-1, 64, 32, 32]               0\n",
      "        MaxPool2d-45           [-1, 64, 16, 16]               0\n",
      "           Conv2d-46          [-1, 128, 16, 16]          73,856\n",
      "      BatchNorm2d-47          [-1, 128, 16, 16]             256\n",
      "             ReLU-48          [-1, 128, 16, 16]               0\n",
      "           Conv2d-49          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-50          [-1, 128, 16, 16]             256\n",
      "             ReLU-51          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-52            [-1, 128, 8, 8]               0\n",
      "           Conv2d-53            [-1, 256, 8, 8]         295,168\n",
      "      BatchNorm2d-54            [-1, 256, 8, 8]             512\n",
      "             ReLU-55            [-1, 256, 8, 8]               0\n",
      "           Conv2d-56            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-57            [-1, 256, 8, 8]             512\n",
      "             ReLU-58            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-59            [-1, 256, 4, 4]               0\n",
      "           Conv2d-60            [-1, 512, 4, 4]       1,180,160\n",
      "      BatchNorm2d-61            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-62            [-1, 512, 4, 4]               0\n",
      "           Conv2d-63            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-64            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-65            [-1, 512, 4, 4]               0\n",
      "        MaxPool2d-66            [-1, 512, 2, 2]               0\n",
      "           Conv2d-67            [-1, 512, 2, 2]       2,359,808\n",
      "      BatchNorm2d-68            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-69            [-1, 512, 2, 2]               0\n",
      "           Conv2d-70            [-1, 512, 2, 2]       2,359,808\n",
      "      BatchNorm2d-71            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-72            [-1, 512, 2, 2]               0\n",
      "        MaxPool2d-73            [-1, 512, 1, 1]               0\n",
      "           Linear-74                 [-1, 1024]         525,312\n",
      "             ReLU-75                 [-1, 1024]               0\n",
      "          Dropout-76                 [-1, 1024]               0\n",
      "           Conv2d-77           [-1, 64, 32, 32]           1,792\n",
      "      BatchNorm2d-78           [-1, 64, 32, 32]             128\n",
      "             ReLU-79           [-1, 64, 32, 32]               0\n",
      "           Conv2d-80           [-1, 64, 32, 32]          36,928\n",
      "      BatchNorm2d-81           [-1, 64, 32, 32]             128\n",
      "             ReLU-82           [-1, 64, 32, 32]               0\n",
      "        MaxPool2d-83           [-1, 64, 16, 16]               0\n",
      "           Conv2d-84          [-1, 128, 16, 16]          73,856\n",
      "      BatchNorm2d-85          [-1, 128, 16, 16]             256\n",
      "             ReLU-86          [-1, 128, 16, 16]               0\n",
      "           Conv2d-87          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-88          [-1, 128, 16, 16]             256\n",
      "             ReLU-89          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-90            [-1, 128, 8, 8]               0\n",
      "           Conv2d-91            [-1, 256, 8, 8]         295,168\n",
      "      BatchNorm2d-92            [-1, 256, 8, 8]             512\n",
      "             ReLU-93            [-1, 256, 8, 8]               0\n",
      "           Conv2d-94            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-95            [-1, 256, 8, 8]             512\n",
      "             ReLU-96            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-97            [-1, 256, 4, 4]               0\n",
      "           Conv2d-98            [-1, 512, 4, 4]       1,180,160\n",
      "      BatchNorm2d-99            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-100            [-1, 512, 4, 4]               0\n",
      "          Conv2d-101            [-1, 512, 4, 4]       2,359,808\n",
      "     BatchNorm2d-102            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-103            [-1, 512, 4, 4]               0\n",
      "       MaxPool2d-104            [-1, 512, 2, 2]               0\n",
      "          Conv2d-105            [-1, 512, 2, 2]       2,359,808\n",
      "     BatchNorm2d-106            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-107            [-1, 512, 2, 2]               0\n",
      "          Conv2d-108            [-1, 512, 2, 2]       2,359,808\n",
      "     BatchNorm2d-109            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-110            [-1, 512, 2, 2]               0\n",
      "       MaxPool2d-111            [-1, 512, 1, 1]               0\n",
      "          Linear-112                 [-1, 1024]         525,312\n",
      "            ReLU-113                 [-1, 1024]               0\n",
      "         Dropout-114                 [-1, 1024]               0\n",
      "          Conv2d-115           [-1, 64, 32, 32]           1,792\n",
      "     BatchNorm2d-116           [-1, 64, 32, 32]             128\n",
      "            ReLU-117           [-1, 64, 32, 32]               0\n",
      "          Conv2d-118           [-1, 64, 32, 32]          36,928\n",
      "     BatchNorm2d-119           [-1, 64, 32, 32]             128\n",
      "            ReLU-120           [-1, 64, 32, 32]               0\n",
      "       MaxPool2d-121           [-1, 64, 16, 16]               0\n",
      "          Conv2d-122          [-1, 128, 16, 16]          73,856\n",
      "     BatchNorm2d-123          [-1, 128, 16, 16]             256\n",
      "            ReLU-124          [-1, 128, 16, 16]               0\n",
      "          Conv2d-125          [-1, 128, 16, 16]         147,584\n",
      "     BatchNorm2d-126          [-1, 128, 16, 16]             256\n",
      "            ReLU-127          [-1, 128, 16, 16]               0\n",
      "       MaxPool2d-128            [-1, 128, 8, 8]               0\n",
      "          Conv2d-129            [-1, 256, 8, 8]         295,168\n",
      "     BatchNorm2d-130            [-1, 256, 8, 8]             512\n",
      "            ReLU-131            [-1, 256, 8, 8]               0\n",
      "          Conv2d-132            [-1, 256, 8, 8]         590,080\n",
      "     BatchNorm2d-133            [-1, 256, 8, 8]             512\n",
      "            ReLU-134            [-1, 256, 8, 8]               0\n",
      "       MaxPool2d-135            [-1, 256, 4, 4]               0\n",
      "          Conv2d-136            [-1, 512, 4, 4]       1,180,160\n",
      "     BatchNorm2d-137            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-138            [-1, 512, 4, 4]               0\n",
      "          Conv2d-139            [-1, 512, 4, 4]       2,359,808\n",
      "     BatchNorm2d-140            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-141            [-1, 512, 4, 4]               0\n",
      "       MaxPool2d-142            [-1, 512, 2, 2]               0\n",
      "          Conv2d-143            [-1, 512, 2, 2]       2,359,808\n",
      "     BatchNorm2d-144            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-145            [-1, 512, 2, 2]               0\n",
      "          Conv2d-146            [-1, 512, 2, 2]       2,359,808\n",
      "     BatchNorm2d-147            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-148            [-1, 512, 2, 2]               0\n",
      "       MaxPool2d-149            [-1, 512, 1, 1]               0\n",
      "          Linear-150                 [-1, 1024]         525,312\n",
      "            ReLU-151                 [-1, 1024]               0\n",
      "         Dropout-152                 [-1, 1024]               0\n",
      "          Linear-153                 [-1, 4096]      16,781,312\n",
      "            ReLU-154                 [-1, 4096]               0\n",
      "         Dropout-155                 [-1, 4096]               0\n",
      "          Linear-156                   [-1, 24]          98,328\n",
      "================================================================\n",
      "Total params: 56,624,408\n",
      "Trainable params: 56,624,408\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 339738624.00\n",
      "Forward/backward pass size (MB): 24.02\n",
      "Params size (MB): 216.00\n",
      "Estimated Total Size (MB): 339738864.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "# Model for learning patch position\n",
    "##################################################\n",
    "\n",
    "class VggNetwork(nn.Module):\n",
    "  def __init__(self,aux_logits = False):\n",
    "\n",
    "      super(VggNetwork, self).__init__()\n",
    "\n",
    "      self.cnn = nn.Sequential(\n",
    "\n",
    "        nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(64), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(64), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "        nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(128), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(128), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "        nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(256), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(256), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "        nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "      )\n",
    "    \n",
    "      self.fc6 = nn.Sequential(\n",
    "        nn.Linear(512, 1024),\n",
    "        nn.ReLU(True),\n",
    "        nn.Dropout(),\n",
    "      )\n",
    "\n",
    "      self.fc = nn.Sequential(\n",
    "        nn.Linear(4*1024, 4096),\n",
    "        nn.ReLU(True),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(4096, 24),\n",
    "      )\n",
    "\n",
    "  def forward_once(self, x):\n",
    "    output= self.cnn(x)\n",
    "    output = output.view(output.size()[0], -1)\n",
    "    output = self.fc6(output)\n",
    "    return output\n",
    "\n",
    "  def forward(self, patch_a, patch_b, patch_c, patch_d):\n",
    "    output_fc6_patch_a = self.forward_once(patch_a)\n",
    "    output_fc6_patch_b = self.forward_once(patch_b)\n",
    "    output_fc6_patch_c = self.forward_once(patch_c)\n",
    "    output_fc6_patch_d = self.forward_once(patch_d)\n",
    "\n",
    "    output = torch.cat((output_fc6_patch_a, output_fc6_patch_b, output_fc6_patch_c, output_fc6_patch_d), 1)\n",
    "    output = self.fc(output)\n",
    "\n",
    "    return output, output_fc6_patch_a, output_fc6_patch_b, output_fc6_patch_c, output_fc6_patch_d\n",
    "\n",
    "model = VggNetwork().to(device)\n",
    "summary(model, [(3, 32, 32), (3, 32, 32), (3, 32, 32), (3, 32, 32)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
