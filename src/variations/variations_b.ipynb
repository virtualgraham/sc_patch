{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, datasets\n",
    " \n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    " \n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    " \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm # progress bar\n",
    "\n",
    "import skimage\n",
    "import cv2\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import math\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Parameters \n",
    "#########################################\n",
    "\n",
    "viz_image_paths = glob('/Users/racoon/Downloads/open-images-sample/*.jpg')\n",
    "training_image_paths = glob('/data/open-images-dataset/train/*.jpg')\n",
    "validation_image_paths = glob('/data/open-images-dataset/validation/*.jpg')\n",
    "\n",
    "train_dataset_length = 409600\n",
    "validation_dataset_length = 20480\n",
    "train_batch_size = 1024\n",
    "validation_batch_size = 1024\n",
    "num_epochs = 1500\n",
    "save_after_epochs = 1 \n",
    "backup_after_epochs = 5 \n",
    "model_save_prefix = \"variation_b\"\n",
    "reuse_image_count = 4\n",
    "\n",
    "patch_dim = 32\n",
    "gap = 10\n",
    "jitter = 5\n",
    "\n",
    "learn_rate = 0.0001\n",
    "momentum = 0.974\n",
    "weight_decay = 0.0005\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Utilities \n",
    "#########################################\n",
    "\n",
    "def imshow(img,text=None,should_save=False):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
    "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()  \n",
    "\n",
    "def show_plot(iteration,loss,fname):\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.savefig(fname)\n",
    "    plt.show()\n",
    "    \n",
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        for i, t in enumerate(tensor):\n",
    "            t.mul_(self.std[i%3]).add_(self.mean[i%3])\n",
    "        return tensor\n",
    "\n",
    "unorm = UnNormalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# This class generates patches for training\n",
    "#########################################\n",
    "\n",
    "patch_order_arr = [\n",
    "  (0, 1, 2, 3),\n",
    "  (0, 1, 3, 2),\n",
    "  (0, 2, 1, 3),\n",
    "  (0, 2, 3, 1),\n",
    "  (0, 3, 1, 2),\n",
    "  (0, 3, 2, 1),\n",
    "  (1, 0, 2, 3),\n",
    "  (1, 0, 3, 2),\n",
    "  (1, 2, 0, 3),\n",
    "  (1, 2, 3, 0),\n",
    "  (1, 3, 0, 2),\n",
    "  (1, 3, 2, 0),\n",
    "  (2, 0, 1, 3),\n",
    "  (2, 0, 3, 1),\n",
    "  (2, 1, 0, 3),\n",
    "  (2, 1, 3, 0),\n",
    "  (2, 3, 0, 1),\n",
    "  (2, 3, 1, 0),\n",
    "  (3, 0, 1, 2),\n",
    "  (3, 0, 2, 1),\n",
    "  (3, 1, 0, 2),\n",
    "  (3, 1, 2, 0),\n",
    "  (3, 2, 0, 1),\n",
    "  (3, 2, 1, 0)\n",
    "]\n",
    "\n",
    "class ShufflePatchDataset(Dataset):\n",
    "\n",
    "  def __init__(self, image_paths, patch_dim, length, gap, jitter, transform=None):\n",
    "    self.image_paths = image_paths\n",
    "    self.patch_dim = patch_dim\n",
    "    self.length = length\n",
    "    self.gap = gap\n",
    "    self.jitter = jitter\n",
    "    self.transform = transform\n",
    "    self.image_reused = 0\n",
    "    \n",
    "    self.sub_window_width = self.patch_dim + 2*self.jitter\n",
    "    self.window_width = 2*self.sub_window_width\n",
    "    \n",
    "    self.min_image_width = self.window_width + 1\n",
    "\n",
    "    self.saliency = cv2.saliency.StaticSaliencyFineGrained_create()\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.length\n",
    "  \n",
    "  def half_gap(self):\n",
    "    return math.ceil(self.gap/2)\n",
    "\n",
    "  def random_jitter(self):\n",
    "    return int(math.floor((self.jitter * 2 * random.random()))) - self.jitter\n",
    "\n",
    "  def saliency_check(self, window, patch_coords):\n",
    "    (success, saliency_map) = self.saliency.computeSaliency(cv2.cvtColor(window, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    high_saliency_patches = 0\n",
    "    med_saliency_patches = 0\n",
    "    for p in patch_coords:\n",
    "        patch_saliency_map = saliency_map[p[0]:p[0]+self.patch_dim, p[1]:p[1]+self.patch_dim]\n",
    "        patch_saliency = np.sum(patch_saliency_map > .5)\n",
    "        print('patch_saliency', patch_saliency)\n",
    "        if patch_saliency >= 500:\n",
    "          high_saliency_patches += 1\n",
    "        elif patch_saliency >= 100:\n",
    "          med_saliency_patches += 1\n",
    "\n",
    "    print('salient_patches', high_saliency_patches, med_saliency_patches, high_saliency_patches > 0 and (high_saliency_patches + med_saliency_patches) > 2)\n",
    "    return high_saliency_patches > 0 and (high_saliency_patches + med_saliency_patches) > 2\n",
    "\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    # [y, x, chan], dtype=uint8, top_left is (0,0)\n",
    "    \n",
    "    image_index = int(math.floor((len(self.image_paths) * random.random())))\n",
    "    \n",
    "    if self.image_reused == 0:\n",
    "      pil_image = Image.open(self.image_paths[image_index]).convert('RGB')\n",
    "      self.pil_image = pil_image.resize((int(round(pil_image.size[0]/3)), int(round(pil_image.size[1]/3))))\n",
    "      self.image_reused = reuse_image_count\n",
    "    else:\n",
    "      self.image_reused -= 1\n",
    "\n",
    "    image = np.array(self.pil_image)\n",
    "\n",
    "    # If image is too small, try another image\n",
    "    if (image.shape[0] - self.min_image_width) <= 0 or (image.shape[1] - self.min_image_width) <= 0:\n",
    "        return self.__getitem__(index)\n",
    "    \n",
    "    window_y_coord = int(math.floor((image.shape[0] - self.window_width) * random.random()))\n",
    "    window_x_coord = int(math.floor((image.shape[1] - self.window_width) * random.random()))\n",
    "\n",
    "    window = image[window_y_coord:window_y_coord+self.window_width, window_x_coord:window_x_coord+self.window_width]\n",
    "    order_label = int(math.floor((24 * random.random()))) \n",
    "    \n",
    "    patch_coords = [\n",
    "      (0, 0),\n",
    "      (0, self.sub_window_width),\n",
    "      (self.sub_window_width, 0),\n",
    "      (self.sub_window_width, self.sub_window_width),\n",
    "    ]\n",
    "\n",
    "    patch_coords = [pc for _,pc in sorted(zip(patch_order_arr[order_label],patch_coords))]\n",
    "\n",
    "    if not self.saliency_check(window, patch_coords):\n",
    "      return self.__getitem__(index)\n",
    "\n",
    "    patch_a = window[patch_coords[0][0]:patch_coords[0][0]+self.patch_dim, patch_coords[0][1]:patch_coords[0][1]+self.patch_dim]\n",
    "    patch_b = window[patch_coords[1][0]:patch_coords[1][0]+self.patch_dim, patch_coords[1][1]:patch_coords[1][1]+self.patch_dim]\n",
    "    patch_c = window[patch_coords[2][0]:patch_coords[2][0]+self.patch_dim, patch_coords[2][1]:patch_coords[2][1]+self.patch_dim]\n",
    "    patch_d = window[patch_coords[3][0]:patch_coords[3][0]+self.patch_dim, patch_coords[3][1]:patch_coords[3][1]+self.patch_dim]\n",
    "\n",
    "    combined_label = np.array(order_label).astype(np.int64)\n",
    "        \n",
    "    if self.transform:\n",
    "      patch_a = self.transform(patch_a)\n",
    "      patch_b = self.transform(patch_b)\n",
    "      patch_c = self.transform(patch_c)\n",
    "      patch_d = self.transform(patch_d)\n",
    "\n",
    "    return patch_a, patch_b, patch_c, patch_d, combined_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##################################################\n",
    "# Creating Train/Validation dataset and dataloader\n",
    "##################################################\n",
    "\n",
    "traindataset = ShufflePatchDataset(training_image_paths, patch_dim, train_dataset_length, gap, jitter,\n",
    "                         transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(traindataset, \n",
    "                                          batch_size=train_batch_size,\n",
    "                                          num_workers=4,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "valdataset = ShufflePatchDataset(validation_image_paths, patch_dim, validation_dataset_length, gap, jitter,\n",
    "                         transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valdataset,\n",
    "                                        batch_size=validation_batch_size,\n",
    "                                        num_workers=4,\n",
    "                                        shuffle=False)\n",
    "\n",
    "\n",
    "vizdataset = ShufflePatchDataset(viz_image_paths, patch_dim, 1, gap, jitter,\n",
    "                         transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "\n",
    "vizloader = torch.utils.data.DataLoader(vizdataset,\n",
    "                                        batch_size=1,\n",
    "                                        shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch_saliency 45\n",
      "patch_saliency 151\n",
      "patch_saliency 406\n",
      "patch_saliency 217\n",
      "salient_patches 0 3 False\n",
      "patch_saliency 641\n",
      "patch_saliency 33\n",
      "patch_saliency 347\n",
      "patch_saliency 522\n",
      "salient_patches 2 1 True\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [14]\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "# Visualizing validation dataset\n",
    "#############################\n",
    "\n",
    "example_batch_val = next(iter(vizloader))\n",
    "concatenated = torch.cat((unorm(example_batch_val[0]),unorm(example_batch_val[1]),unorm(example_batch_val[2]),unorm(example_batch_val[3])),0)\n",
    "imshow(torchvision.utils.make_grid(concatenated))\n",
    "print(f'Labels: {example_batch_val[4].numpy()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
      "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
      "              ReLU-6           [-1, 64, 32, 32]               0\n",
      "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
      "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
      "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
      "             ReLU-10          [-1, 128, 16, 16]               0\n",
      "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
      "             ReLU-13          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
      "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
      "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
      "             ReLU-17            [-1, 256, 8, 8]               0\n",
      "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
      "             ReLU-20            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-21            [-1, 256, 4, 4]               0\n",
      "           Conv2d-22            [-1, 512, 4, 4]       1,180,160\n",
      "      BatchNorm2d-23            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-24            [-1, 512, 4, 4]               0\n",
      "           Conv2d-25            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-27            [-1, 512, 4, 4]               0\n",
      "        MaxPool2d-28            [-1, 512, 2, 2]               0\n",
      "           Conv2d-29            [-1, 512, 2, 2]       2,359,808\n",
      "      BatchNorm2d-30            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-31            [-1, 512, 2, 2]               0\n",
      "           Conv2d-32            [-1, 512, 2, 2]       2,359,808\n",
      "      BatchNorm2d-33            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-34            [-1, 512, 2, 2]               0\n",
      "        MaxPool2d-35            [-1, 512, 1, 1]               0\n",
      "           Linear-36                 [-1, 1024]         525,312\n",
      "             ReLU-37                 [-1, 1024]               0\n",
      "          Dropout-38                 [-1, 1024]               0\n",
      "           Conv2d-39           [-1, 64, 32, 32]           1,792\n",
      "      BatchNorm2d-40           [-1, 64, 32, 32]             128\n",
      "             ReLU-41           [-1, 64, 32, 32]               0\n",
      "           Conv2d-42           [-1, 64, 32, 32]          36,928\n",
      "      BatchNorm2d-43           [-1, 64, 32, 32]             128\n",
      "             ReLU-44           [-1, 64, 32, 32]               0\n",
      "        MaxPool2d-45           [-1, 64, 16, 16]               0\n",
      "           Conv2d-46          [-1, 128, 16, 16]          73,856\n",
      "      BatchNorm2d-47          [-1, 128, 16, 16]             256\n",
      "             ReLU-48          [-1, 128, 16, 16]               0\n",
      "           Conv2d-49          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-50          [-1, 128, 16, 16]             256\n",
      "             ReLU-51          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-52            [-1, 128, 8, 8]               0\n",
      "           Conv2d-53            [-1, 256, 8, 8]         295,168\n",
      "      BatchNorm2d-54            [-1, 256, 8, 8]             512\n",
      "             ReLU-55            [-1, 256, 8, 8]               0\n",
      "           Conv2d-56            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-57            [-1, 256, 8, 8]             512\n",
      "             ReLU-58            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-59            [-1, 256, 4, 4]               0\n",
      "           Conv2d-60            [-1, 512, 4, 4]       1,180,160\n",
      "      BatchNorm2d-61            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-62            [-1, 512, 4, 4]               0\n",
      "           Conv2d-63            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-64            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-65            [-1, 512, 4, 4]               0\n",
      "        MaxPool2d-66            [-1, 512, 2, 2]               0\n",
      "           Conv2d-67            [-1, 512, 2, 2]       2,359,808\n",
      "      BatchNorm2d-68            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-69            [-1, 512, 2, 2]               0\n",
      "           Conv2d-70            [-1, 512, 2, 2]       2,359,808\n",
      "      BatchNorm2d-71            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-72            [-1, 512, 2, 2]               0\n",
      "        MaxPool2d-73            [-1, 512, 1, 1]               0\n",
      "           Linear-74                 [-1, 1024]         525,312\n",
      "             ReLU-75                 [-1, 1024]               0\n",
      "          Dropout-76                 [-1, 1024]               0\n",
      "           Conv2d-77           [-1, 64, 32, 32]           1,792\n",
      "      BatchNorm2d-78           [-1, 64, 32, 32]             128\n",
      "             ReLU-79           [-1, 64, 32, 32]               0\n",
      "           Conv2d-80           [-1, 64, 32, 32]          36,928\n",
      "      BatchNorm2d-81           [-1, 64, 32, 32]             128\n",
      "             ReLU-82           [-1, 64, 32, 32]               0\n",
      "        MaxPool2d-83           [-1, 64, 16, 16]               0\n",
      "           Conv2d-84          [-1, 128, 16, 16]          73,856\n",
      "      BatchNorm2d-85          [-1, 128, 16, 16]             256\n",
      "             ReLU-86          [-1, 128, 16, 16]               0\n",
      "           Conv2d-87          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-88          [-1, 128, 16, 16]             256\n",
      "             ReLU-89          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-90            [-1, 128, 8, 8]               0\n",
      "           Conv2d-91            [-1, 256, 8, 8]         295,168\n",
      "      BatchNorm2d-92            [-1, 256, 8, 8]             512\n",
      "             ReLU-93            [-1, 256, 8, 8]               0\n",
      "           Conv2d-94            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-95            [-1, 256, 8, 8]             512\n",
      "             ReLU-96            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-97            [-1, 256, 4, 4]               0\n",
      "           Conv2d-98            [-1, 512, 4, 4]       1,180,160\n",
      "      BatchNorm2d-99            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-100            [-1, 512, 4, 4]               0\n",
      "          Conv2d-101            [-1, 512, 4, 4]       2,359,808\n",
      "     BatchNorm2d-102            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-103            [-1, 512, 4, 4]               0\n",
      "       MaxPool2d-104            [-1, 512, 2, 2]               0\n",
      "          Conv2d-105            [-1, 512, 2, 2]       2,359,808\n",
      "     BatchNorm2d-106            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-107            [-1, 512, 2, 2]               0\n",
      "          Conv2d-108            [-1, 512, 2, 2]       2,359,808\n",
      "     BatchNorm2d-109            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-110            [-1, 512, 2, 2]               0\n",
      "       MaxPool2d-111            [-1, 512, 1, 1]               0\n",
      "          Linear-112                 [-1, 1024]         525,312\n",
      "            ReLU-113                 [-1, 1024]               0\n",
      "         Dropout-114                 [-1, 1024]               0\n",
      "          Conv2d-115           [-1, 64, 32, 32]           1,792\n",
      "     BatchNorm2d-116           [-1, 64, 32, 32]             128\n",
      "            ReLU-117           [-1, 64, 32, 32]               0\n",
      "          Conv2d-118           [-1, 64, 32, 32]          36,928\n",
      "     BatchNorm2d-119           [-1, 64, 32, 32]             128\n",
      "            ReLU-120           [-1, 64, 32, 32]               0\n",
      "       MaxPool2d-121           [-1, 64, 16, 16]               0\n",
      "          Conv2d-122          [-1, 128, 16, 16]          73,856\n",
      "     BatchNorm2d-123          [-1, 128, 16, 16]             256\n",
      "            ReLU-124          [-1, 128, 16, 16]               0\n",
      "          Conv2d-125          [-1, 128, 16, 16]         147,584\n",
      "     BatchNorm2d-126          [-1, 128, 16, 16]             256\n",
      "            ReLU-127          [-1, 128, 16, 16]               0\n",
      "       MaxPool2d-128            [-1, 128, 8, 8]               0\n",
      "          Conv2d-129            [-1, 256, 8, 8]         295,168\n",
      "     BatchNorm2d-130            [-1, 256, 8, 8]             512\n",
      "            ReLU-131            [-1, 256, 8, 8]               0\n",
      "          Conv2d-132            [-1, 256, 8, 8]         590,080\n",
      "     BatchNorm2d-133            [-1, 256, 8, 8]             512\n",
      "            ReLU-134            [-1, 256, 8, 8]               0\n",
      "       MaxPool2d-135            [-1, 256, 4, 4]               0\n",
      "          Conv2d-136            [-1, 512, 4, 4]       1,180,160\n",
      "     BatchNorm2d-137            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-138            [-1, 512, 4, 4]               0\n",
      "          Conv2d-139            [-1, 512, 4, 4]       2,359,808\n",
      "     BatchNorm2d-140            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-141            [-1, 512, 4, 4]               0\n",
      "       MaxPool2d-142            [-1, 512, 2, 2]               0\n",
      "          Conv2d-143            [-1, 512, 2, 2]       2,359,808\n",
      "     BatchNorm2d-144            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-145            [-1, 512, 2, 2]               0\n",
      "          Conv2d-146            [-1, 512, 2, 2]       2,359,808\n",
      "     BatchNorm2d-147            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-148            [-1, 512, 2, 2]               0\n",
      "       MaxPool2d-149            [-1, 512, 1, 1]               0\n",
      "          Linear-150                 [-1, 1024]         525,312\n",
      "            ReLU-151                 [-1, 1024]               0\n",
      "         Dropout-152                 [-1, 1024]               0\n",
      "          Linear-153                 [-1, 4096]      16,781,312\n",
      "            ReLU-154                 [-1, 4096]               0\n",
      "         Dropout-155                 [-1, 4096]               0\n",
      "          Linear-156                   [-1, 24]          98,328\n",
      "================================================================\n",
      "Total params: 56,624,408\n",
      "Trainable params: 56,624,408\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 339738624.00\n",
      "Forward/backward pass size (MB): 24.02\n",
      "Params size (MB): 216.00\n",
      "Estimated Total Size (MB): 339738864.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "# Model for learning patch position\n",
    "##################################################\n",
    "\n",
    "class VggNetwork(nn.Module):\n",
    "  def __init__(self,aux_logits = False):\n",
    "\n",
    "      super(VggNetwork, self).__init__()\n",
    "\n",
    "      self.cnn = nn.Sequential(\n",
    "\n",
    "        nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(64), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(64), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "        nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(128), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(128), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "        nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(256), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(256), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "        nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "      )\n",
    "    \n",
    "      self.fc6 = nn.Sequential(\n",
    "        nn.Linear(512, 1024),\n",
    "        nn.ReLU(True),\n",
    "        nn.Dropout(),\n",
    "      )\n",
    "\n",
    "      self.fc = nn.Sequential(\n",
    "        nn.Linear(4*1024, 4096),\n",
    "        nn.ReLU(True),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(4096, 24),\n",
    "      )\n",
    "\n",
    "  def forward_once(self, x):\n",
    "    output= self.cnn(x)\n",
    "    output = output.view(output.size()[0], -1)\n",
    "    output = self.fc6(output)\n",
    "    return output\n",
    "\n",
    "  def forward(self, patch_a, patch_b, patch_c, patch_d):\n",
    "    output_fc6_patch_a = self.forward_once(patch_a)\n",
    "    output_fc6_patch_b = self.forward_once(patch_b)\n",
    "    output_fc6_patch_c = self.forward_once(patch_c)\n",
    "    output_fc6_patch_d = self.forward_once(patch_d)\n",
    "\n",
    "    output = torch.cat((output_fc6_patch_a, output_fc6_patch_b, output_fc6_patch_c, output_fc6_patch_d), 1)\n",
    "    output = self.fc(output)\n",
    "\n",
    "    return output, output_fc6_patch_a, output_fc6_patch_b, output_fc6_patch_c, output_fc6_patch_d\n",
    "\n",
    "model = VggNetwork().to(device)\n",
    "summary(model, [(3, 32, 32), (3, 32, 32), (3, 32, 32), (3, 32, 32)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
