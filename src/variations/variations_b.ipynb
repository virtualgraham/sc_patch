{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, datasets\n",
    " \n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    " \n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    " \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm # progress bar\n",
    "\n",
    "import skimage\n",
    "from skimage import img_as_ubyte, img_as_float32\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import math\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Parameters \n",
    "#########################################\n",
    "\n",
    "viz_image_paths = glob('/Users/racoon/Downloads/open-images-sample/*.jpg')\n",
    "training_image_paths = glob('/data/open-images-dataset/train/*.jpg')\n",
    "validation_image_paths = glob('/data/open-images-dataset/validation/*.jpg')\n",
    "\n",
    "train_dataset_length = 409600\n",
    "validation_dataset_length = 20480\n",
    "train_batch_size = 1024\n",
    "validation_batch_size = 1024\n",
    "num_epochs = 1500\n",
    "save_after_epochs = 1 \n",
    "backup_after_epochs = 5 \n",
    "model_save_prefix = \"variation_b\"\n",
    "reuse_image_count = 4\n",
    "\n",
    "patch_dim = 32\n",
    "gap = 10\n",
    "jitter = 5\n",
    "\n",
    "learn_rate = 0.0001\n",
    "momentum = 0.974\n",
    "weight_decay = 0.0005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Utilities \n",
    "#########################################\n",
    "\n",
    "def imshow(img,text=None,should_save=False):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
    "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()  \n",
    "\n",
    "def show_plot(iteration,loss,fname):\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.savefig(fname)\n",
    "    plt.show()\n",
    "    \n",
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        for i, t in enumerate(tensor):\n",
    "            t.mul_(self.std[i%3]).add_(self.mean[i%3])\n",
    "        return tensor\n",
    "\n",
    "unorm = UnNormalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########################################\n",
    "# This class generates patches for training\n",
    "#########################################\n",
    "\n",
    "patch_order_arr = [\n",
    "  (0, 1, 2, 3),\n",
    "  (0, 1, 3, 2),\n",
    "  (0, 2, 1, 3),\n",
    "  (0, 2, 3, 1),\n",
    "  (0, 3, 1, 2),\n",
    "  (0, 3, 2, 1),\n",
    "  (1, 0, 2, 3),\n",
    "  (1, 0, 3, 2),\n",
    "  (1, 2, 0, 3),\n",
    "  (1, 2, 3, 0),\n",
    "  (1, 3, 0, 2),\n",
    "  (1, 3, 2, 0),\n",
    "  (2, 0, 1, 3),\n",
    "  (2, 0, 3, 1),\n",
    "  (2, 1, 0, 3),\n",
    "  (2, 1, 3, 0),\n",
    "  (2, 3, 0, 1),\n",
    "  (2, 3, 1, 0),\n",
    "  (3, 0, 1, 2),\n",
    "  (3, 0, 2, 1),\n",
    "  (3, 1, 0, 2),\n",
    "  (3, 1, 2, 0),\n",
    "  (3, 2, 0, 1),\n",
    "  (3, 2, 1, 0)\n",
    "]\n",
    "\n",
    "class ShufflePatchDataset(Dataset):\n",
    "\n",
    "  def __init__(self, image_paths, patch_dim, length, gap, jitter, transform=None):\n",
    "    self.image_paths = image_paths\n",
    "    self.patch_dim = patch_dim\n",
    "    self.length = length\n",
    "    self.gap = gap\n",
    "    self.jitter = jitter\n",
    "    self.transform = transform\n",
    "    self.margin = math.ceil((2*self.patch_dim + 2*self.jitter + self.gap)/2)\n",
    "    self.min_width = 2 * self.margin + 1\n",
    "    self.image_reused = 0\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.length\n",
    "  \n",
    "  def half_gap(self):\n",
    "    return math.ceil(self.gap/2)\n",
    "\n",
    "  def random_jitter(self):\n",
    "    return int(math.floor((self.jitter * 2 * random.random()))) - self.jitter\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    # [y, x, chan], dtype=uint8, top_left is (0,0)\n",
    "    \n",
    "    image_index = int(math.floor((len(self.image_paths) * random.random())))\n",
    "    \n",
    "    if self.image_reused == 0:\n",
    "      pil_image = Image.open(self.image_paths[image_index]).convert('RGB')\n",
    "      self.pil_image = pil_image.resize((int(round(pil_image.size[0]/3)), int(round(pil_image.size[1]/3))))\n",
    "      self.image_reused = reuse_image_count\n",
    "    else:\n",
    "      self.image_reused -= 1\n",
    "\n",
    "    image = np.array(self.pil_image)\n",
    "\n",
    "    # If image is too small, try another image\n",
    "    if (image.shape[0] - self.min_width) <= 0 or (image.shape[1] - self.min_width) <= 0:\n",
    "        return self.__getitem__(index)\n",
    "    \n",
    "    center_y_coord = int(math.floor((image.shape[0] - self.margin*2) * random.random())) + self.margin\n",
    "    center_x_coord = int(math.floor((image.shape[1] - self.margin*2) * random.random())) + self.margin\n",
    "\n",
    "    patch_coords = [\n",
    "      (\n",
    "        center_y_coord - (self.patch_dim + self.half_gap() + self.random_jitter()),\n",
    "        center_x_coord - (self.patch_dim + self.half_gap() + self.random_jitter())\n",
    "      ),\n",
    "      (\n",
    "        center_y_coord - (self.patch_dim + self.half_gap() + self.random_jitter()),\n",
    "        center_x_coord + self.half_gap() + self.random_jitter()\n",
    "      ),\n",
    "      (\n",
    "        center_y_coord + self.half_gap() + self.random_jitter(),\n",
    "        center_x_coord - (self.patch_dim + self.half_gap() + self.random_jitter())\n",
    "      ),\n",
    "      (\n",
    "        center_y_coord + self.half_gap() + self.random_jitter(),\n",
    "        center_x_coord + self.half_gap() + self.random_jitter()\n",
    "      )\n",
    "    ]\n",
    "    \n",
    "    patch_shuffle_order_label = int(math.floor((24 * random.random())))\n",
    "\n",
    "    patch_coords = [pc for _,pc in sorted(zip(patch_order_arr[patch_shuffle_order_label],patch_coords))]\n",
    "\n",
    "    patch_a = image[patch_coords[0][0]:patch_coords[0][0]+self.patch_dim, patch_coords[0][1]:patch_coords[0][1]+self.patch_dim]\n",
    "    patch_b = image[patch_coords[1][0]:patch_coords[1][0]+self.patch_dim, patch_coords[1][1]:patch_coords[1][1]+self.patch_dim]\n",
    "    patch_c = image[patch_coords[2][0]:patch_coords[2][0]+self.patch_dim, patch_coords[2][1]:patch_coords[2][1]+self.patch_dim]\n",
    "    patch_d = image[patch_coords[3][0]:patch_coords[3][0]+self.patch_dim, patch_coords[3][1]:patch_coords[3][1]+self.patch_dim]\n",
    "\n",
    "    patch_shuffle_order_label = np.array(patch_shuffle_order_label).astype(np.int64)\n",
    "        \n",
    "    if self.transform:\n",
    "      patch_a = self.transform(patch_a)\n",
    "      patch_b = self.transform(patch_b)\n",
    "      patch_c = self.transform(patch_c)\n",
    "      patch_d = self.transform(patch_d)\n",
    "\n",
    "    return patch_a, patch_b, patch_c, patch_d, patch_shuffle_order_label\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##################################################\n",
    "# Creating Train/Validation dataset and dataloader\n",
    "##################################################\n",
    "\n",
    "traindataset = ShufflePatchDataset(training_image_paths, patch_dim, train_dataset_length, gap, jitter,\n",
    "                         transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(traindataset, \n",
    "                                          batch_size=train_batch_size,\n",
    "                                          num_workers=4,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "valdataset = ShufflePatchDataset(validation_image_paths, patch_dim, validation_dataset_length, gap, jitter,\n",
    "                         transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valdataset,\n",
    "                                        batch_size=validation_batch_size,\n",
    "                                        num_workers=4,\n",
    "                                        shuffle=False)\n",
    "\n",
    "\n",
    "vizdataset = ShufflePatchDataset(viz_image_paths, patch_dim, 1, gap, jitter,\n",
    "                         transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "\n",
    "vizloader = torch.utils.data.DataLoader(vizdataset,\n",
    "                                        batch_size=1,\n",
    "                                        shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [15]\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "# Visualizing validation dataset\n",
    "#############################\n",
    "\n",
    "example_batch_val = next(iter(vizloader))\n",
    "concatenated = torch.cat((unorm(example_batch_val[0]),unorm(example_batch_val[1]),unorm(example_batch_val[2]),unorm(example_batch_val[3])),0)\n",
    "imshow(torchvision.utils.make_grid(concatenated, nrow=2))\n",
    "print(f'Labels: {example_batch_val[4].numpy()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
      "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
      "              ReLU-6           [-1, 64, 32, 32]               0\n",
      "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
      "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
      "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
      "             ReLU-10          [-1, 128, 16, 16]               0\n",
      "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
      "             ReLU-13          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
      "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
      "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
      "             ReLU-17            [-1, 256, 8, 8]               0\n",
      "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
      "             ReLU-20            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-21            [-1, 256, 4, 4]               0\n",
      "           Conv2d-22            [-1, 512, 4, 4]       1,180,160\n",
      "      BatchNorm2d-23            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-24            [-1, 512, 4, 4]               0\n",
      "           Conv2d-25            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-27            [-1, 512, 4, 4]               0\n",
      "        MaxPool2d-28            [-1, 512, 2, 2]               0\n",
      "           Conv2d-29            [-1, 512, 2, 2]       2,359,808\n",
      "      BatchNorm2d-30            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-31            [-1, 512, 2, 2]               0\n",
      "           Conv2d-32            [-1, 512, 2, 2]       2,359,808\n",
      "      BatchNorm2d-33            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-34            [-1, 512, 2, 2]               0\n",
      "        MaxPool2d-35            [-1, 512, 1, 1]               0\n",
      "           Linear-36                 [-1, 1024]         525,312\n",
      "             ReLU-37                 [-1, 1024]               0\n",
      "          Dropout-38                 [-1, 1024]               0\n",
      "           Conv2d-39           [-1, 64, 32, 32]           1,792\n",
      "      BatchNorm2d-40           [-1, 64, 32, 32]             128\n",
      "             ReLU-41           [-1, 64, 32, 32]               0\n",
      "           Conv2d-42           [-1, 64, 32, 32]          36,928\n",
      "      BatchNorm2d-43           [-1, 64, 32, 32]             128\n",
      "             ReLU-44           [-1, 64, 32, 32]               0\n",
      "        MaxPool2d-45           [-1, 64, 16, 16]               0\n",
      "           Conv2d-46          [-1, 128, 16, 16]          73,856\n",
      "      BatchNorm2d-47          [-1, 128, 16, 16]             256\n",
      "             ReLU-48          [-1, 128, 16, 16]               0\n",
      "           Conv2d-49          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-50          [-1, 128, 16, 16]             256\n",
      "             ReLU-51          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-52            [-1, 128, 8, 8]               0\n",
      "           Conv2d-53            [-1, 256, 8, 8]         295,168\n",
      "      BatchNorm2d-54            [-1, 256, 8, 8]             512\n",
      "             ReLU-55            [-1, 256, 8, 8]               0\n",
      "           Conv2d-56            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-57            [-1, 256, 8, 8]             512\n",
      "             ReLU-58            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-59            [-1, 256, 4, 4]               0\n",
      "           Conv2d-60            [-1, 512, 4, 4]       1,180,160\n",
      "      BatchNorm2d-61            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-62            [-1, 512, 4, 4]               0\n",
      "           Conv2d-63            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-64            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-65            [-1, 512, 4, 4]               0\n",
      "        MaxPool2d-66            [-1, 512, 2, 2]               0\n",
      "           Conv2d-67            [-1, 512, 2, 2]       2,359,808\n",
      "      BatchNorm2d-68            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-69            [-1, 512, 2, 2]               0\n",
      "           Conv2d-70            [-1, 512, 2, 2]       2,359,808\n",
      "      BatchNorm2d-71            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-72            [-1, 512, 2, 2]               0\n",
      "        MaxPool2d-73            [-1, 512, 1, 1]               0\n",
      "           Linear-74                 [-1, 1024]         525,312\n",
      "             ReLU-75                 [-1, 1024]               0\n",
      "          Dropout-76                 [-1, 1024]               0\n",
      "           Conv2d-77           [-1, 64, 32, 32]           1,792\n",
      "      BatchNorm2d-78           [-1, 64, 32, 32]             128\n",
      "             ReLU-79           [-1, 64, 32, 32]               0\n",
      "           Conv2d-80           [-1, 64, 32, 32]          36,928\n",
      "      BatchNorm2d-81           [-1, 64, 32, 32]             128\n",
      "             ReLU-82           [-1, 64, 32, 32]               0\n",
      "        MaxPool2d-83           [-1, 64, 16, 16]               0\n",
      "           Conv2d-84          [-1, 128, 16, 16]          73,856\n",
      "      BatchNorm2d-85          [-1, 128, 16, 16]             256\n",
      "             ReLU-86          [-1, 128, 16, 16]               0\n",
      "           Conv2d-87          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-88          [-1, 128, 16, 16]             256\n",
      "             ReLU-89          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-90            [-1, 128, 8, 8]               0\n",
      "           Conv2d-91            [-1, 256, 8, 8]         295,168\n",
      "      BatchNorm2d-92            [-1, 256, 8, 8]             512\n",
      "             ReLU-93            [-1, 256, 8, 8]               0\n",
      "           Conv2d-94            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-95            [-1, 256, 8, 8]             512\n",
      "             ReLU-96            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-97            [-1, 256, 4, 4]               0\n",
      "           Conv2d-98            [-1, 512, 4, 4]       1,180,160\n",
      "      BatchNorm2d-99            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-100            [-1, 512, 4, 4]               0\n",
      "          Conv2d-101            [-1, 512, 4, 4]       2,359,808\n",
      "     BatchNorm2d-102            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-103            [-1, 512, 4, 4]               0\n",
      "       MaxPool2d-104            [-1, 512, 2, 2]               0\n",
      "          Conv2d-105            [-1, 512, 2, 2]       2,359,808\n",
      "     BatchNorm2d-106            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-107            [-1, 512, 2, 2]               0\n",
      "          Conv2d-108            [-1, 512, 2, 2]       2,359,808\n",
      "     BatchNorm2d-109            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-110            [-1, 512, 2, 2]               0\n",
      "       MaxPool2d-111            [-1, 512, 1, 1]               0\n",
      "          Linear-112                 [-1, 1024]         525,312\n",
      "            ReLU-113                 [-1, 1024]               0\n",
      "         Dropout-114                 [-1, 1024]               0\n",
      "          Conv2d-115           [-1, 64, 32, 32]           1,792\n",
      "     BatchNorm2d-116           [-1, 64, 32, 32]             128\n",
      "            ReLU-117           [-1, 64, 32, 32]               0\n",
      "          Conv2d-118           [-1, 64, 32, 32]          36,928\n",
      "     BatchNorm2d-119           [-1, 64, 32, 32]             128\n",
      "            ReLU-120           [-1, 64, 32, 32]               0\n",
      "       MaxPool2d-121           [-1, 64, 16, 16]               0\n",
      "          Conv2d-122          [-1, 128, 16, 16]          73,856\n",
      "     BatchNorm2d-123          [-1, 128, 16, 16]             256\n",
      "            ReLU-124          [-1, 128, 16, 16]               0\n",
      "          Conv2d-125          [-1, 128, 16, 16]         147,584\n",
      "     BatchNorm2d-126          [-1, 128, 16, 16]             256\n",
      "            ReLU-127          [-1, 128, 16, 16]               0\n",
      "       MaxPool2d-128            [-1, 128, 8, 8]               0\n",
      "          Conv2d-129            [-1, 256, 8, 8]         295,168\n",
      "     BatchNorm2d-130            [-1, 256, 8, 8]             512\n",
      "            ReLU-131            [-1, 256, 8, 8]               0\n",
      "          Conv2d-132            [-1, 256, 8, 8]         590,080\n",
      "     BatchNorm2d-133            [-1, 256, 8, 8]             512\n",
      "            ReLU-134            [-1, 256, 8, 8]               0\n",
      "       MaxPool2d-135            [-1, 256, 4, 4]               0\n",
      "          Conv2d-136            [-1, 512, 4, 4]       1,180,160\n",
      "     BatchNorm2d-137            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-138            [-1, 512, 4, 4]               0\n",
      "          Conv2d-139            [-1, 512, 4, 4]       2,359,808\n",
      "     BatchNorm2d-140            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-141            [-1, 512, 4, 4]               0\n",
      "       MaxPool2d-142            [-1, 512, 2, 2]               0\n",
      "          Conv2d-143            [-1, 512, 2, 2]       2,359,808\n",
      "     BatchNorm2d-144            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-145            [-1, 512, 2, 2]               0\n",
      "          Conv2d-146            [-1, 512, 2, 2]       2,359,808\n",
      "     BatchNorm2d-147            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-148            [-1, 512, 2, 2]               0\n",
      "       MaxPool2d-149            [-1, 512, 1, 1]               0\n",
      "          Linear-150                 [-1, 1024]         525,312\n",
      "            ReLU-151                 [-1, 1024]               0\n",
      "         Dropout-152                 [-1, 1024]               0\n",
      "          Linear-153                 [-1, 4096]      16,781,312\n",
      "            ReLU-154                 [-1, 4096]               0\n",
      "         Dropout-155                 [-1, 4096]               0\n",
      "          Linear-156                   [-1, 24]          98,328\n",
      "================================================================\n",
      "Total params: 56,624,408\n",
      "Trainable params: 56,624,408\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 339738624.00\n",
      "Forward/backward pass size (MB): 24.02\n",
      "Params size (MB): 216.00\n",
      "Estimated Total Size (MB): 339738864.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "# Model for learning patch position\n",
    "##################################################\n",
    "\n",
    "class VggNetwork(nn.Module):\n",
    "  def __init__(self,aux_logits = False):\n",
    "\n",
    "      super(VggNetwork, self).__init__()\n",
    "\n",
    "      self.cnn = nn.Sequential(\n",
    "\n",
    "        nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(64), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(64), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "        nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(128), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(128), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "        nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(256), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(256), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "        nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "      )\n",
    "    \n",
    "      self.fc6 = nn.Sequential(\n",
    "        nn.Linear(512, 1024),\n",
    "        nn.ReLU(True),\n",
    "        nn.Dropout(),\n",
    "      )\n",
    "\n",
    "      self.fc = nn.Sequential(\n",
    "        nn.Linear(4*1024, 4096),\n",
    "        nn.ReLU(True),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(4096, 24),\n",
    "      )\n",
    "\n",
    "  def forward_once(self, x):\n",
    "    output= self.cnn(x)\n",
    "    output = output.view(output.size()[0], -1)\n",
    "    output = self.fc6(output)\n",
    "    return output\n",
    "\n",
    "  def forward(self, patch_a, patch_b, patch_c, patch_d):\n",
    "    output_fc6_patch_a = self.forward_once(patch_a)\n",
    "    output_fc6_patch_b = self.forward_once(patch_b)\n",
    "    output_fc6_patch_c = self.forward_once(patch_c)\n",
    "    output_fc6_patch_d = self.forward_once(patch_d)\n",
    "\n",
    "    output = torch.cat((output_fc6_patch_a, output_fc6_patch_b, output_fc6_patch_c, output_fc6_patch_d), 1)\n",
    "    output = self.fc(output)\n",
    "\n",
    "    return output, output_fc6_patch_a, output_fc6_patch_b, output_fc6_patch_c, output_fc6_patch_d\n",
    "\n",
    "model = VggNetwork().to(device)\n",
    "summary(model, [(3, 32, 32), (3, 32, 32), (3, 32, 32), (3, 32, 32)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
