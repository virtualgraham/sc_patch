{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, datasets\n",
    " \n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    " \n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    " \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm # progress bar\n",
    "\n",
    "import skimage\n",
    "from skimage import img_as_ubyte, img_as_float32\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import math\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Parameters \n",
    "#########################################\n",
    "\n",
    "viz_image_paths = glob('/Users/racoon/Downloads/open-images-sample/*.jpg')\n",
    "training_image_paths = glob('/data/open-images-dataset/train/*.jpg')\n",
    "validation_image_paths = glob('/data/open-images-dataset/validation/*.jpg')\n",
    "\n",
    "train_dataset_length = 40192 # 314 iterations\n",
    "validation_dataset_length = 2048 \n",
    "train_batch_size = 512\n",
    "validation_batch_size = 512\n",
    "num_epochs = 1500\n",
    "save_after_epochs = 1 \n",
    "backup_after_epochs = 10 \n",
    "model_save_prefix = \"variation_a\"\n",
    "\n",
    "patch_dim = 32\n",
    "gap = 10\n",
    "jitter = 5\n",
    "gray_portion = .30\n",
    "\n",
    "learn_rate = 0.001\n",
    "momentum = 0.974\n",
    "weight_decay = 0.0005\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Utilities \n",
    "#########################################\n",
    "\n",
    "def imshow(img,text=None,should_save=False):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
    "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()  \n",
    "\n",
    "def show_plot(iteration,loss,fname):\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.savefig(fname)\n",
    "    plt.show()\n",
    "    \n",
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        for i, t in enumerate(tensor):\n",
    "            t.mul_(self.std[i%3]).add_(self.mean[i%3])\n",
    "        return tensor\n",
    "\n",
    "unorm = UnNormalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#########################################\n",
    "# This class generates patches for training\n",
    "#########################################\n",
    "\n",
    "patch_order_arr = [\n",
    "  (0, 1, 2, 3),\n",
    "  (0, 1, 3, 2),\n",
    "  (0, 2, 1, 3),\n",
    "  (0, 2, 3, 1),\n",
    "  (0, 3, 1, 2),\n",
    "  (0, 3, 2, 1),\n",
    "  (1, 0, 2, 3),\n",
    "  (1, 0, 3, 2),\n",
    "  (1, 2, 0, 3),\n",
    "  (1, 2, 3, 0),\n",
    "  (1, 3, 0, 2),\n",
    "  (1, 3, 2, 0),\n",
    "  (2, 0, 1, 3),\n",
    "  (2, 0, 3, 1),\n",
    "  (2, 1, 0, 3),\n",
    "  (2, 1, 3, 0),\n",
    "  (2, 3, 0, 1),\n",
    "  (2, 3, 1, 0),\n",
    "  (3, 0, 1, 2),\n",
    "  (3, 0, 2, 1),\n",
    "  (3, 1, 0, 2),\n",
    "  (3, 1, 2, 0),\n",
    "  (3, 2, 0, 1),\n",
    "  (3, 2, 1, 0)\n",
    "]\n",
    "\n",
    "class ShufflePatchDataset(Dataset):\n",
    "\n",
    "  def __init__(self, image_paths, patch_dim, length, gap, jitter, transform=None):\n",
    "    self.image_paths = image_paths\n",
    "    self.patch_dim = patch_dim\n",
    "    self.length = length\n",
    "    self.gap = gap\n",
    "    self.jitter = jitter\n",
    "    self.transform = transform\n",
    "    self.color_shift = 1\n",
    "    self.margin = math.ceil((2*patch_dim + 2*jitter + 2*self.color_shift + gap)/2)\n",
    "    self.min_width = 2 * self.margin + 1\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.length\n",
    "  \n",
    "  def half_gap(self):\n",
    "    return math.ceil(self.gap/2)\n",
    "\n",
    "  def random_jitter(self):\n",
    "    return int(math.floor((self.jitter * 2 * random.random()))) - self.jitter\n",
    "\n",
    "  def random_shift(self):\n",
    "    return random.randrange(self.color_shift * 2 + 1)\n",
    "\n",
    "  # crops the patch by self.color_shift on each side\n",
    "  def prep_patch(self, image, gray):\n",
    " \n",
    "    cropped = np.empty((self.patch_dim, self.patch_dim, 3), dtype=np.uint8)\n",
    "\n",
    "    if(gray):\n",
    "\n",
    "      pil_patch = Image.fromarray(image)\n",
    "      pil_patch = pil_patch.convert('L')\n",
    "      pil_patch = pil_patch.convert('RGB')\n",
    "      np.copyto(cropped, np.array(pil_patch)[self.color_shift:self.color_shift+self.patch_dim, self.color_shift:self.color_shift+self.patch_dim, :])\n",
    "      \n",
    "    else:\n",
    "\n",
    "      shift = [self.random_shift() for _ in range(6)]\n",
    "      cropped[:,:,0] = image[shift[0]:shift[0]+self.patch_dim, shift[1]:shift[1]+self.patch_dim, 0]\n",
    "      cropped[:,:,1] = image[shift[2]:shift[2]+self.patch_dim, shift[3]:shift[3]+self.patch_dim, 1]\n",
    "      cropped[:,:,2] = image[shift[4]:shift[4]+self.patch_dim, shift[5]:shift[5]+self.patch_dim, 2]\n",
    "\n",
    "    return cropped\n",
    "\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    # [y, x, chan], dtype=uint8, top_left is (0,0)\n",
    "        \n",
    "    image_index = int(math.floor((len(self.image_paths) * random.random())))\n",
    "    \n",
    "    pil_image = Image.open(self.image_paths[image_index]).convert('RGB')\n",
    "    pil_image = pil_image.resize((int(round(pil_image.size[0]/3)), int(round(pil_image.size[1]/3))))\n",
    "\n",
    "    image = np.array(pil_image)\n",
    "\n",
    "    # If image is too small, try another image\n",
    "    if (image.shape[0] - self.min_width) <= 0 or (image.shape[1] - self.min_width) <= 0:\n",
    "        return self.__getitem__(index)\n",
    "    \n",
    "    center_y_coord = int(math.floor((image.shape[0] - self.margin*2) * random.random())) + self.margin\n",
    "    center_x_coord = int(math.floor((image.shape[1] - self.margin*2) * random.random())) + self.margin\n",
    "\n",
    "    patch_coords = [\n",
    "      (\n",
    "        center_y_coord - (self.patch_dim + self.half_gap() + self.random_jitter() + self.color_shift),\n",
    "        center_x_coord - (self.patch_dim + self.half_gap() + self.random_jitter() + self.color_shift)\n",
    "      ),\n",
    "      (\n",
    "        center_y_coord - (self.patch_dim + self.half_gap() + self.random_jitter() + self.color_shift),\n",
    "        center_x_coord + self.half_gap() + self.random_jitter() - self.color_shift\n",
    "      ),\n",
    "      (\n",
    "        center_y_coord + self.half_gap() + self.random_jitter() - self.color_shift,\n",
    "        center_x_coord - (self.patch_dim + self.half_gap() + self.random_jitter() + self.color_shift)\n",
    "      ),\n",
    "      (\n",
    "        center_y_coord + self.half_gap() + self.random_jitter() - self.color_shift,\n",
    "        center_x_coord + self.half_gap() + self.random_jitter() - self.color_shift\n",
    "      )\n",
    "    ]\n",
    "    \n",
    "    patch_shuffle_order_label = int(math.floor((24 * random.random())))\n",
    "\n",
    "    patch_coords = [pc for _,pc in sorted(zip(patch_order_arr[patch_shuffle_order_label],patch_coords))]\n",
    "\n",
    "    patch_a = image[patch_coords[0][0]:patch_coords[0][0]+self.patch_dim+2*self.color_shift, patch_coords[0][1]:patch_coords[0][1]+self.patch_dim+2*self.color_shift]\n",
    "    patch_b = image[patch_coords[1][0]:patch_coords[1][0]+self.patch_dim+2*self.color_shift, patch_coords[1][1]:patch_coords[1][1]+self.patch_dim+2*self.color_shift]\n",
    "    patch_c = image[patch_coords[2][0]:patch_coords[2][0]+self.patch_dim+2*self.color_shift, patch_coords[2][1]:patch_coords[2][1]+self.patch_dim+2*self.color_shift]\n",
    "    patch_d = image[patch_coords[3][0]:patch_coords[3][0]+self.patch_dim+2*self.color_shift, patch_coords[3][1]:patch_coords[3][1]+self.patch_dim+2*self.color_shift]\n",
    "\n",
    "    gray = random.random() < gray_portion\n",
    "\n",
    "    patch_a = self.prep_patch(patch_a, gray)\n",
    "    patch_b = self.prep_patch(patch_b, gray)\n",
    "    patch_c = self.prep_patch(patch_c, gray)\n",
    "    patch_d = self.prep_patch(patch_d, gray)\n",
    "\n",
    "    patch_shuffle_order_label = np.array(patch_shuffle_order_label).astype(np.int64)\n",
    "        \n",
    "    if self.transform:\n",
    "      patch_a = self.transform(patch_a)\n",
    "      patch_b = self.transform(patch_b)\n",
    "      patch_c = self.transform(patch_c)\n",
    "      patch_d = self.transform(patch_d)\n",
    "\n",
    "    return patch_a, patch_b, patch_c, patch_d, patch_shuffle_order_label\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##################################################\n",
    "# Creating Train/Validation dataset and dataloader\n",
    "##################################################\n",
    "\n",
    "traindataset = ShufflePatchDataset(training_image_paths, patch_dim, train_dataset_length, gap, jitter,\n",
    "                         transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(traindataset, \n",
    "                                          batch_size=train_batch_size,\n",
    "                                          num_workers=4,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "valdataset = ShufflePatchDataset(validation_image_paths, patch_dim, validation_dataset_length, gap, jitter,\n",
    "                         transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valdataset,\n",
    "                                        batch_size=validation_batch_size,\n",
    "                                        num_workers=4,\n",
    "                                        shuffle=False)\n",
    "\n",
    "\n",
    "vizdataset = ShufflePatchDataset(viz_image_paths, patch_dim, 1, gap, jitter,\n",
    "                         transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "\n",
    "vizloader = torch.utils.data.DataLoader(vizdataset,\n",
    "                                        batch_size=1,\n",
    "                                        shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [11]\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "# Visualizing validation dataset\n",
    "#############################\n",
    "\n",
    "example_batch_val = next(iter(vizloader))\n",
    "concatenated = torch.cat((unorm(example_batch_val[0]),unorm(example_batch_val[1]),unorm(example_batch_val[2]),unorm(example_batch_val[3])),0)\n",
    "imshow(torchvision.utils.make_grid(concatenated))\n",
    "print(f'Labels: {example_batch_val[4].numpy()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
      "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
      "              ReLU-6           [-1, 64, 32, 32]               0\n",
      "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
      "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
      "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
      "             ReLU-10          [-1, 128, 16, 16]               0\n",
      "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
      "             ReLU-13          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
      "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
      "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
      "             ReLU-17            [-1, 256, 8, 8]               0\n",
      "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
      "             ReLU-20            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-21            [-1, 256, 4, 4]               0\n",
      "           Conv2d-22            [-1, 512, 4, 4]       1,180,160\n",
      "      BatchNorm2d-23            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-24            [-1, 512, 4, 4]               0\n",
      "           Conv2d-25            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-27            [-1, 512, 4, 4]               0\n",
      "        MaxPool2d-28            [-1, 512, 2, 2]               0\n",
      "           Conv2d-29            [-1, 512, 2, 2]       2,359,808\n",
      "      BatchNorm2d-30            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-31            [-1, 512, 2, 2]               0\n",
      "           Conv2d-32            [-1, 512, 2, 2]       2,359,808\n",
      "      BatchNorm2d-33            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-34            [-1, 512, 2, 2]               0\n",
      "        MaxPool2d-35            [-1, 512, 1, 1]               0\n",
      "           Linear-36                 [-1, 1024]         525,312\n",
      "             ReLU-37                 [-1, 1024]               0\n",
      "          Dropout-38                 [-1, 1024]               0\n",
      "           Conv2d-39           [-1, 64, 32, 32]           1,792\n",
      "      BatchNorm2d-40           [-1, 64, 32, 32]             128\n",
      "             ReLU-41           [-1, 64, 32, 32]               0\n",
      "           Conv2d-42           [-1, 64, 32, 32]          36,928\n",
      "      BatchNorm2d-43           [-1, 64, 32, 32]             128\n",
      "             ReLU-44           [-1, 64, 32, 32]               0\n",
      "        MaxPool2d-45           [-1, 64, 16, 16]               0\n",
      "           Conv2d-46          [-1, 128, 16, 16]          73,856\n",
      "      BatchNorm2d-47          [-1, 128, 16, 16]             256\n",
      "             ReLU-48          [-1, 128, 16, 16]               0\n",
      "           Conv2d-49          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-50          [-1, 128, 16, 16]             256\n",
      "             ReLU-51          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-52            [-1, 128, 8, 8]               0\n",
      "           Conv2d-53            [-1, 256, 8, 8]         295,168\n",
      "      BatchNorm2d-54            [-1, 256, 8, 8]             512\n",
      "             ReLU-55            [-1, 256, 8, 8]               0\n",
      "           Conv2d-56            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-57            [-1, 256, 8, 8]             512\n",
      "             ReLU-58            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-59            [-1, 256, 4, 4]               0\n",
      "           Conv2d-60            [-1, 512, 4, 4]       1,180,160\n",
      "      BatchNorm2d-61            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-62            [-1, 512, 4, 4]               0\n",
      "           Conv2d-63            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-64            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-65            [-1, 512, 4, 4]               0\n",
      "        MaxPool2d-66            [-1, 512, 2, 2]               0\n",
      "           Conv2d-67            [-1, 512, 2, 2]       2,359,808\n",
      "      BatchNorm2d-68            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-69            [-1, 512, 2, 2]               0\n",
      "           Conv2d-70            [-1, 512, 2, 2]       2,359,808\n",
      "      BatchNorm2d-71            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-72            [-1, 512, 2, 2]               0\n",
      "        MaxPool2d-73            [-1, 512, 1, 1]               0\n",
      "           Linear-74                 [-1, 1024]         525,312\n",
      "             ReLU-75                 [-1, 1024]               0\n",
      "          Dropout-76                 [-1, 1024]               0\n",
      "           Conv2d-77           [-1, 64, 32, 32]           1,792\n",
      "      BatchNorm2d-78           [-1, 64, 32, 32]             128\n",
      "             ReLU-79           [-1, 64, 32, 32]               0\n",
      "           Conv2d-80           [-1, 64, 32, 32]          36,928\n",
      "      BatchNorm2d-81           [-1, 64, 32, 32]             128\n",
      "             ReLU-82           [-1, 64, 32, 32]               0\n",
      "        MaxPool2d-83           [-1, 64, 16, 16]               0\n",
      "           Conv2d-84          [-1, 128, 16, 16]          73,856\n",
      "      BatchNorm2d-85          [-1, 128, 16, 16]             256\n",
      "             ReLU-86          [-1, 128, 16, 16]               0\n",
      "           Conv2d-87          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-88          [-1, 128, 16, 16]             256\n",
      "             ReLU-89          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-90            [-1, 128, 8, 8]               0\n",
      "           Conv2d-91            [-1, 256, 8, 8]         295,168\n",
      "      BatchNorm2d-92            [-1, 256, 8, 8]             512\n",
      "             ReLU-93            [-1, 256, 8, 8]               0\n",
      "           Conv2d-94            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-95            [-1, 256, 8, 8]             512\n",
      "             ReLU-96            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-97            [-1, 256, 4, 4]               0\n",
      "           Conv2d-98            [-1, 512, 4, 4]       1,180,160\n",
      "      BatchNorm2d-99            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-100            [-1, 512, 4, 4]               0\n",
      "          Conv2d-101            [-1, 512, 4, 4]       2,359,808\n",
      "     BatchNorm2d-102            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-103            [-1, 512, 4, 4]               0\n",
      "       MaxPool2d-104            [-1, 512, 2, 2]               0\n",
      "          Conv2d-105            [-1, 512, 2, 2]       2,359,808\n",
      "     BatchNorm2d-106            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-107            [-1, 512, 2, 2]               0\n",
      "          Conv2d-108            [-1, 512, 2, 2]       2,359,808\n",
      "     BatchNorm2d-109            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-110            [-1, 512, 2, 2]               0\n",
      "       MaxPool2d-111            [-1, 512, 1, 1]               0\n",
      "          Linear-112                 [-1, 1024]         525,312\n",
      "            ReLU-113                 [-1, 1024]               0\n",
      "         Dropout-114                 [-1, 1024]               0\n",
      "          Conv2d-115           [-1, 64, 32, 32]           1,792\n",
      "     BatchNorm2d-116           [-1, 64, 32, 32]             128\n",
      "            ReLU-117           [-1, 64, 32, 32]               0\n",
      "          Conv2d-118           [-1, 64, 32, 32]          36,928\n",
      "     BatchNorm2d-119           [-1, 64, 32, 32]             128\n",
      "            ReLU-120           [-1, 64, 32, 32]               0\n",
      "       MaxPool2d-121           [-1, 64, 16, 16]               0\n",
      "          Conv2d-122          [-1, 128, 16, 16]          73,856\n",
      "     BatchNorm2d-123          [-1, 128, 16, 16]             256\n",
      "            ReLU-124          [-1, 128, 16, 16]               0\n",
      "          Conv2d-125          [-1, 128, 16, 16]         147,584\n",
      "     BatchNorm2d-126          [-1, 128, 16, 16]             256\n",
      "            ReLU-127          [-1, 128, 16, 16]               0\n",
      "       MaxPool2d-128            [-1, 128, 8, 8]               0\n",
      "          Conv2d-129            [-1, 256, 8, 8]         295,168\n",
      "     BatchNorm2d-130            [-1, 256, 8, 8]             512\n",
      "            ReLU-131            [-1, 256, 8, 8]               0\n",
      "          Conv2d-132            [-1, 256, 8, 8]         590,080\n",
      "     BatchNorm2d-133            [-1, 256, 8, 8]             512\n",
      "            ReLU-134            [-1, 256, 8, 8]               0\n",
      "       MaxPool2d-135            [-1, 256, 4, 4]               0\n",
      "          Conv2d-136            [-1, 512, 4, 4]       1,180,160\n",
      "     BatchNorm2d-137            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-138            [-1, 512, 4, 4]               0\n",
      "          Conv2d-139            [-1, 512, 4, 4]       2,359,808\n",
      "     BatchNorm2d-140            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-141            [-1, 512, 4, 4]               0\n",
      "       MaxPool2d-142            [-1, 512, 2, 2]               0\n",
      "          Conv2d-143            [-1, 512, 2, 2]       2,359,808\n",
      "     BatchNorm2d-144            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-145            [-1, 512, 2, 2]               0\n",
      "          Conv2d-146            [-1, 512, 2, 2]       2,359,808\n",
      "     BatchNorm2d-147            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-148            [-1, 512, 2, 2]               0\n",
      "       MaxPool2d-149            [-1, 512, 1, 1]               0\n",
      "          Linear-150                 [-1, 1024]         525,312\n",
      "            ReLU-151                 [-1, 1024]               0\n",
      "         Dropout-152                 [-1, 1024]               0\n",
      "          Linear-153                 [-1, 4096]      16,781,312\n",
      "            ReLU-154                 [-1, 4096]               0\n",
      "         Dropout-155                 [-1, 4096]               0\n",
      "          Linear-156                   [-1, 24]          98,328\n",
      "================================================================\n",
      "Total params: 56,624,408\n",
      "Trainable params: 56,624,408\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 339738624.00\n",
      "Forward/backward pass size (MB): 24.02\n",
      "Params size (MB): 216.00\n",
      "Estimated Total Size (MB): 339738864.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "# Model for learning patch position\n",
    "##################################################\n",
    "\n",
    "class VggNetwork(nn.Module):\n",
    "  def __init__(self,aux_logits = False):\n",
    "\n",
    "      super(VggNetwork, self).__init__()\n",
    "\n",
    "      self.cnn = nn.Sequential(\n",
    "\n",
    "        nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(64), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(64), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "        nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(128), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(128), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "        nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(256), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(256), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "        nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "      )\n",
    "    \n",
    "      self.fc6 = nn.Sequential(\n",
    "        nn.Linear(512, 1024),\n",
    "        nn.ReLU(True),\n",
    "        nn.Dropout(),\n",
    "      )\n",
    "\n",
    "      self.fc = nn.Sequential(\n",
    "        nn.Linear(4*1024, 4096),\n",
    "        nn.ReLU(True),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(4096, 24),\n",
    "      )\n",
    "\n",
    "  def forward_once(self, x):\n",
    "    output= self.cnn(x)\n",
    "    output = output.view(output.size()[0], -1)\n",
    "    output = self.fc6(output)\n",
    "    return output\n",
    "\n",
    "  def forward(self, patch_a, patch_b, patch_c, patch_d):\n",
    "    output_fc6_patch_a = self.forward_once(patch_a)\n",
    "    output_fc6_patch_b = self.forward_once(patch_b)\n",
    "    output_fc6_patch_c = self.forward_once(patch_c)\n",
    "    output_fc6_patch_d = self.forward_once(patch_d)\n",
    "\n",
    "    output = torch.cat((output_fc6_patch_a, output_fc6_patch_b, output_fc6_patch_c, output_fc6_patch_d), 1)\n",
    "    output = self.fc(output)\n",
    "\n",
    "    return output, output_fc6_patch_a, output_fc6_patch_b, output_fc6_patch_c, output_fc6_patch_d\n",
    "\n",
    "model = VggNetwork().to(device)\n",
    "summary(model, [(3, 32, 32), (3, 32, 32), (3, 32, 32), (3, 32, 32)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
