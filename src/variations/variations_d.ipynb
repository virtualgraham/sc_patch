{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, datasets\n",
    " \n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    " \n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    " \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm # progress bar\n",
    "\n",
    "import skimage\n",
    "import cv2\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import math\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Parameters \n",
    "#########################################\n",
    "\n",
    "viz_image_paths = glob('/Users/racoon/Downloads/open-images-sample/*.jpg')\n",
    "training_image_paths = glob('/data/open-images-dataset/train/*.jpg')\n",
    "validation_image_paths = glob('/data/open-images-dataset/validation/*.jpg')\n",
    "\n",
    "train_dataset_length = 409600\n",
    "validation_dataset_length = 20480\n",
    "train_batch_size = 1024\n",
    "validation_batch_size = 1024\n",
    "num_epochs = 1500\n",
    "save_after_epochs = 1 \n",
    "backup_after_epochs = 5 \n",
    "model_save_prefix = \"variation_b\"\n",
    "reuse_image_count = 4\n",
    "\n",
    "patch_dim = 32\n",
    "gap = 10\n",
    "jitter = 5\n",
    "\n",
    "learn_rate = 0.0001\n",
    "momentum = 0.974\n",
    "weight_decay = 0.0005\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Utilities \n",
    "#########################################\n",
    "\n",
    "def imshow(img,text=None,should_save=False):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
    "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()  \n",
    "\n",
    "def show_plot(iteration,loss,fname):\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.savefig(fname)\n",
    "    plt.show()\n",
    "    \n",
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        for i, t in enumerate(tensor):\n",
    "            t.mul_(self.std[i%3]).add_(self.mean[i%3])\n",
    "        return tensor\n",
    "\n",
    "unorm = UnNormalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# This class generates patches for training\n",
    "#########################################\n",
    "\n",
    "patch_order_arr = [\n",
    "  (0, 1, 2, 3),\n",
    "  (0, 1, 3, 2),\n",
    "  (0, 2, 1, 3),\n",
    "  (0, 2, 3, 1),\n",
    "  (0, 3, 1, 2),\n",
    "  (0, 3, 2, 1),\n",
    "  (1, 0, 2, 3),\n",
    "  (1, 0, 3, 2),\n",
    "  (1, 2, 0, 3),\n",
    "  (1, 2, 3, 0),\n",
    "  (1, 3, 0, 2),\n",
    "  (1, 3, 2, 0),\n",
    "  (2, 0, 1, 3),\n",
    "  (2, 0, 3, 1),\n",
    "  (2, 1, 0, 3),\n",
    "  (2, 1, 3, 0),\n",
    "  (2, 3, 0, 1),\n",
    "  (2, 3, 1, 0),\n",
    "  (3, 0, 1, 2),\n",
    "  (3, 0, 2, 1),\n",
    "  (3, 1, 0, 2),\n",
    "  (3, 1, 2, 0),\n",
    "  (3, 2, 0, 1),\n",
    "  (3, 2, 1, 0)\n",
    "]\n",
    "\n",
    "class ShufflePatchDataset(Dataset):\n",
    "\n",
    "  def __init__(self, image_paths, patch_dim, length, gap, jitter, transform=None):\n",
    "    self.image_paths = image_paths\n",
    "    self.patch_dim = patch_dim\n",
    "    self.length = length\n",
    "    self.gap = gap\n",
    "    self.jitter = jitter\n",
    "    self.transform = transform\n",
    "    self.image_reused = 0\n",
    "    \n",
    "    self.sub_window_width = self.patch_dim + 2*self.jitter\n",
    "    self.window_width = 2*self.sub_window_width\n",
    "    \n",
    "    self.min_image_width = self.window_width + 1\n",
    "\n",
    "    self.saliency = cv2.saliency.StaticSaliencyFineGrained_create()\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.length\n",
    "  \n",
    "  def half_gap(self):\n",
    "    return math.ceil(self.gap/2)\n",
    "\n",
    "  def random_jitter(self):\n",
    "    return int(math.floor((self.jitter * 2 * random.random()))) - self.jitter\n",
    "\n",
    "  def saliency_check(self, window, patch_coords):\n",
    "    (success, saliency_map) = self.saliency.computeSaliency(cv2.cvtColor(window, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    high_saliency_patches = 0\n",
    "    med_saliency_patches = 0\n",
    "    for p in patch_coords:\n",
    "        patch_saliency_map = saliency_map[p[0]:p[0]+self.patch_dim, p[1]:p[1]+self.patch_dim]\n",
    "        patch_saliency = np.sum(patch_saliency_map > .5)\n",
    "        print('patch_saliency', patch_saliency)\n",
    "        if patch_saliency >= 500:\n",
    "          high_saliency_patches += 1\n",
    "        elif patch_saliency >= 100:\n",
    "          med_saliency_patches += 1\n",
    "\n",
    "    print('salient_patches', high_saliency_patches, med_saliency_patches, high_saliency_patches > 0 and (high_saliency_patches + med_saliency_patches) > 2)\n",
    "    return high_saliency_patches > 0 and (high_saliency_patches + med_saliency_patches) > 2\n",
    "\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    # [y, x, chan], dtype=uint8, top_left is (0,0)\n",
    "    \n",
    "    image_index = int(math.floor((len(self.image_paths) * random.random())))\n",
    "    \n",
    "    if self.image_reused == 0:\n",
    "      pil_image = Image.open(self.image_paths[image_index]).convert('RGB')\n",
    "      self.pil_image = pil_image.resize((int(round(pil_image.size[0]/3)), int(round(pil_image.size[1]/3))))\n",
    "      self.image_reused = reuse_image_count\n",
    "    else:\n",
    "      self.image_reused -= 1\n",
    "\n",
    "    image = np.array(self.pil_image)\n",
    "\n",
    "    # If image is too small, try another image\n",
    "    if (image.shape[0] - self.min_image_width) <= 0 or (image.shape[1] - self.min_image_width) <= 0:\n",
    "        return self.__getitem__(index)\n",
    "    \n",
    "    window_y_coord = int(math.floor((image.shape[0] - self.window_width) * random.random()))\n",
    "    window_x_coord = int(math.floor((image.shape[1] - self.window_width) * random.random()))\n",
    "\n",
    "    window = image[window_y_coord:window_y_coord+self.window_width, window_x_coord:window_x_coord+self.window_width]\n",
    "    \n",
    "    rotation_label = int(math.floor((4 * random.random())))\n",
    "    order_label = int(math.floor((24 * random.random()))) \n",
    "    \n",
    "    if rotation_label>0:\n",
    "      window = np.rot90(window, rotation_label).copy()\n",
    "\n",
    "    patch_coords = [\n",
    "      (0, 0),\n",
    "      (0, self.sub_window_width),\n",
    "      (self.sub_window_width, 0),\n",
    "      (self.sub_window_width, self.sub_window_width),\n",
    "    ]\n",
    "\n",
    "    patch_coords = [pc for _,pc in sorted(zip(patch_order_arr[order_label],patch_coords))]\n",
    "\n",
    "    if not self.saliency_check(window, patch_coords):\n",
    "      return self.__getitem__(index)\n",
    "\n",
    "    patch_a = window[patch_coords[0][0]:patch_coords[0][0]+self.patch_dim, patch_coords[0][1]:patch_coords[0][1]+self.patch_dim]\n",
    "    patch_b = window[patch_coords[1][0]:patch_coords[1][0]+self.patch_dim, patch_coords[1][1]:patch_coords[1][1]+self.patch_dim]\n",
    "    patch_c = window[patch_coords[2][0]:patch_coords[2][0]+self.patch_dim, patch_coords[2][1]:patch_coords[2][1]+self.patch_dim]\n",
    "    patch_d = window[patch_coords[3][0]:patch_coords[3][0]+self.patch_dim, patch_coords[3][1]:patch_coords[3][1]+self.patch_dim]\n",
    "\n",
    "    combined_label = np.array(rotation_label * 24 + order_label).astype(np.int64)\n",
    "        \n",
    "    if self.transform:\n",
    "      patch_a = self.transform(patch_a)\n",
    "      patch_b = self.transform(patch_b)\n",
    "      patch_c = self.transform(patch_c)\n",
    "      patch_d = self.transform(patch_d)\n",
    "\n",
    "    return patch_a, patch_b, patch_c, patch_d, combined_label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##################################################\n",
    "# Creating Train/Validation dataset and dataloader\n",
    "##################################################\n",
    "\n",
    "traindataset = ShufflePatchDataset(training_image_paths, patch_dim, train_dataset_length, gap, jitter,\n",
    "                         transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(traindataset, \n",
    "                                          batch_size=train_batch_size,\n",
    "                                          num_workers=4,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "valdataset = ShufflePatchDataset(validation_image_paths, patch_dim, validation_dataset_length, gap, jitter,\n",
    "                         transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valdataset,\n",
    "                                        batch_size=validation_batch_size,\n",
    "                                        num_workers=4,\n",
    "                                        shuffle=False)\n",
    "\n",
    "\n",
    "vizdataset = ShufflePatchDataset(viz_image_paths, patch_dim, 1, gap, jitter,\n",
    "                         transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "\n",
    "vizloader = torch.utils.data.DataLoader(vizdataset,\n",
    "                                        batch_size=1,\n",
    "                                        shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch_saliency 0\n",
      "patch_saliency 0\n",
      "patch_saliency 0\n",
      "patch_saliency 0\n",
      "salient_patches 0 0 False\n",
      "patch_saliency 23\n",
      "patch_saliency 244\n",
      "patch_saliency 535\n",
      "patch_saliency 414\n",
      "salient_patches 1 2 True\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: [78]\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "# Visualizing validation dataset\n",
    "#############################\n",
    "\n",
    "example_batch_val = next(iter(vizloader))\n",
    "concatenated = torch.cat((unorm(example_batch_val[0]),unorm(example_batch_val[1]),unorm(example_batch_val[2]),unorm(example_batch_val[3])),0)\n",
    "imshow(torchvision.utils.make_grid(concatenated))\n",
    "print(f'Labels: {example_batch_val[4].numpy()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
      "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
      "              ReLU-6           [-1, 64, 32, 32]               0\n",
      "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
      "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
      "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
      "             ReLU-10          [-1, 128, 16, 16]               0\n",
      "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
      "             ReLU-13          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
      "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
      "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
      "             ReLU-17            [-1, 256, 8, 8]               0\n",
      "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
      "             ReLU-20            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-21            [-1, 256, 4, 4]               0\n",
      "           Conv2d-22            [-1, 512, 4, 4]       1,180,160\n",
      "      BatchNorm2d-23            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-24            [-1, 512, 4, 4]               0\n",
      "           Conv2d-25            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-27            [-1, 512, 4, 4]               0\n",
      "        MaxPool2d-28            [-1, 512, 2, 2]               0\n",
      "           Conv2d-29            [-1, 512, 2, 2]       2,359,808\n",
      "      BatchNorm2d-30            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-31            [-1, 512, 2, 2]               0\n",
      "           Conv2d-32            [-1, 512, 2, 2]       2,359,808\n",
      "      BatchNorm2d-33            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-34            [-1, 512, 2, 2]               0\n",
      "        MaxPool2d-35            [-1, 512, 1, 1]               0\n",
      "           Linear-36                 [-1, 1024]         525,312\n",
      "             ReLU-37                 [-1, 1024]               0\n",
      "          Dropout-38                 [-1, 1024]               0\n",
      "           Conv2d-39           [-1, 64, 32, 32]           1,792\n",
      "      BatchNorm2d-40           [-1, 64, 32, 32]             128\n",
      "             ReLU-41           [-1, 64, 32, 32]               0\n",
      "           Conv2d-42           [-1, 64, 32, 32]          36,928\n",
      "      BatchNorm2d-43           [-1, 64, 32, 32]             128\n",
      "             ReLU-44           [-1, 64, 32, 32]               0\n",
      "        MaxPool2d-45           [-1, 64, 16, 16]               0\n",
      "           Conv2d-46          [-1, 128, 16, 16]          73,856\n",
      "      BatchNorm2d-47          [-1, 128, 16, 16]             256\n",
      "             ReLU-48          [-1, 128, 16, 16]               0\n",
      "           Conv2d-49          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-50          [-1, 128, 16, 16]             256\n",
      "             ReLU-51          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-52            [-1, 128, 8, 8]               0\n",
      "           Conv2d-53            [-1, 256, 8, 8]         295,168\n",
      "      BatchNorm2d-54            [-1, 256, 8, 8]             512\n",
      "             ReLU-55            [-1, 256, 8, 8]               0\n",
      "           Conv2d-56            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-57            [-1, 256, 8, 8]             512\n",
      "             ReLU-58            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-59            [-1, 256, 4, 4]               0\n",
      "           Conv2d-60            [-1, 512, 4, 4]       1,180,160\n",
      "      BatchNorm2d-61            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-62            [-1, 512, 4, 4]               0\n",
      "           Conv2d-63            [-1, 512, 4, 4]       2,359,808\n",
      "      BatchNorm2d-64            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-65            [-1, 512, 4, 4]               0\n",
      "        MaxPool2d-66            [-1, 512, 2, 2]               0\n",
      "           Conv2d-67            [-1, 512, 2, 2]       2,359,808\n",
      "      BatchNorm2d-68            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-69            [-1, 512, 2, 2]               0\n",
      "           Conv2d-70            [-1, 512, 2, 2]       2,359,808\n",
      "      BatchNorm2d-71            [-1, 512, 2, 2]           1,024\n",
      "             ReLU-72            [-1, 512, 2, 2]               0\n",
      "        MaxPool2d-73            [-1, 512, 1, 1]               0\n",
      "           Linear-74                 [-1, 1024]         525,312\n",
      "             ReLU-75                 [-1, 1024]               0\n",
      "          Dropout-76                 [-1, 1024]               0\n",
      "           Conv2d-77           [-1, 64, 32, 32]           1,792\n",
      "      BatchNorm2d-78           [-1, 64, 32, 32]             128\n",
      "             ReLU-79           [-1, 64, 32, 32]               0\n",
      "           Conv2d-80           [-1, 64, 32, 32]          36,928\n",
      "      BatchNorm2d-81           [-1, 64, 32, 32]             128\n",
      "             ReLU-82           [-1, 64, 32, 32]               0\n",
      "        MaxPool2d-83           [-1, 64, 16, 16]               0\n",
      "           Conv2d-84          [-1, 128, 16, 16]          73,856\n",
      "      BatchNorm2d-85          [-1, 128, 16, 16]             256\n",
      "             ReLU-86          [-1, 128, 16, 16]               0\n",
      "           Conv2d-87          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-88          [-1, 128, 16, 16]             256\n",
      "             ReLU-89          [-1, 128, 16, 16]               0\n",
      "        MaxPool2d-90            [-1, 128, 8, 8]               0\n",
      "           Conv2d-91            [-1, 256, 8, 8]         295,168\n",
      "      BatchNorm2d-92            [-1, 256, 8, 8]             512\n",
      "             ReLU-93            [-1, 256, 8, 8]               0\n",
      "           Conv2d-94            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-95            [-1, 256, 8, 8]             512\n",
      "             ReLU-96            [-1, 256, 8, 8]               0\n",
      "        MaxPool2d-97            [-1, 256, 4, 4]               0\n",
      "           Conv2d-98            [-1, 512, 4, 4]       1,180,160\n",
      "      BatchNorm2d-99            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-100            [-1, 512, 4, 4]               0\n",
      "          Conv2d-101            [-1, 512, 4, 4]       2,359,808\n",
      "     BatchNorm2d-102            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-103            [-1, 512, 4, 4]               0\n",
      "       MaxPool2d-104            [-1, 512, 2, 2]               0\n",
      "          Conv2d-105            [-1, 512, 2, 2]       2,359,808\n",
      "     BatchNorm2d-106            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-107            [-1, 512, 2, 2]               0\n",
      "          Conv2d-108            [-1, 512, 2, 2]       2,359,808\n",
      "     BatchNorm2d-109            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-110            [-1, 512, 2, 2]               0\n",
      "       MaxPool2d-111            [-1, 512, 1, 1]               0\n",
      "          Linear-112                 [-1, 1024]         525,312\n",
      "            ReLU-113                 [-1, 1024]               0\n",
      "         Dropout-114                 [-1, 1024]               0\n",
      "          Conv2d-115           [-1, 64, 32, 32]           1,792\n",
      "     BatchNorm2d-116           [-1, 64, 32, 32]             128\n",
      "            ReLU-117           [-1, 64, 32, 32]               0\n",
      "          Conv2d-118           [-1, 64, 32, 32]          36,928\n",
      "     BatchNorm2d-119           [-1, 64, 32, 32]             128\n",
      "            ReLU-120           [-1, 64, 32, 32]               0\n",
      "       MaxPool2d-121           [-1, 64, 16, 16]               0\n",
      "          Conv2d-122          [-1, 128, 16, 16]          73,856\n",
      "     BatchNorm2d-123          [-1, 128, 16, 16]             256\n",
      "            ReLU-124          [-1, 128, 16, 16]               0\n",
      "          Conv2d-125          [-1, 128, 16, 16]         147,584\n",
      "     BatchNorm2d-126          [-1, 128, 16, 16]             256\n",
      "            ReLU-127          [-1, 128, 16, 16]               0\n",
      "       MaxPool2d-128            [-1, 128, 8, 8]               0\n",
      "          Conv2d-129            [-1, 256, 8, 8]         295,168\n",
      "     BatchNorm2d-130            [-1, 256, 8, 8]             512\n",
      "            ReLU-131            [-1, 256, 8, 8]               0\n",
      "          Conv2d-132            [-1, 256, 8, 8]         590,080\n",
      "     BatchNorm2d-133            [-1, 256, 8, 8]             512\n",
      "            ReLU-134            [-1, 256, 8, 8]               0\n",
      "       MaxPool2d-135            [-1, 256, 4, 4]               0\n",
      "          Conv2d-136            [-1, 512, 4, 4]       1,180,160\n",
      "     BatchNorm2d-137            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-138            [-1, 512, 4, 4]               0\n",
      "          Conv2d-139            [-1, 512, 4, 4]       2,359,808\n",
      "     BatchNorm2d-140            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-141            [-1, 512, 4, 4]               0\n",
      "       MaxPool2d-142            [-1, 512, 2, 2]               0\n",
      "          Conv2d-143            [-1, 512, 2, 2]       2,359,808\n",
      "     BatchNorm2d-144            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-145            [-1, 512, 2, 2]               0\n",
      "          Conv2d-146            [-1, 512, 2, 2]       2,359,808\n",
      "     BatchNorm2d-147            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-148            [-1, 512, 2, 2]               0\n",
      "       MaxPool2d-149            [-1, 512, 1, 1]               0\n",
      "          Linear-150                 [-1, 1024]         525,312\n",
      "            ReLU-151                 [-1, 1024]               0\n",
      "         Dropout-152                 [-1, 1024]               0\n",
      "          Linear-153                 [-1, 4096]      16,781,312\n",
      "            ReLU-154                 [-1, 4096]               0\n",
      "         Dropout-155                 [-1, 4096]               0\n",
      "          Linear-156                   [-1, 24]          98,328\n",
      "================================================================\n",
      "Total params: 56,624,408\n",
      "Trainable params: 56,624,408\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 339738624.00\n",
      "Forward/backward pass size (MB): 24.02\n",
      "Params size (MB): 216.00\n",
      "Estimated Total Size (MB): 339738864.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "# Model for learning patch position\n",
    "##################################################\n",
    "\n",
    "class VggNetwork(nn.Module):\n",
    "  def __init__(self,aux_logits = False):\n",
    "\n",
    "      super(VggNetwork, self).__init__()\n",
    "\n",
    "      self.cnn = nn.Sequential(\n",
    "\n",
    "        nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(64), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(64), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "        nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(128), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(128), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "        nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(256), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(256), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "        nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "      )\n",
    "    \n",
    "      self.fc6 = nn.Sequential(\n",
    "        nn.Linear(512, 1024),\n",
    "        nn.ReLU(True),\n",
    "        nn.Dropout(),\n",
    "      )\n",
    "\n",
    "      self.fc = nn.Sequential(\n",
    "        nn.Linear(4*1024, 4096),\n",
    "        nn.ReLU(True),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(4096, 24),\n",
    "      )\n",
    "\n",
    "  def forward_once(self, x):\n",
    "    output= self.cnn(x)\n",
    "    output = output.view(output.size()[0], -1)\n",
    "    output = self.fc6(output)\n",
    "    return output\n",
    "\n",
    "  def forward(self, patch_a, patch_b, patch_c, patch_d):\n",
    "    output_fc6_patch_a = self.forward_once(patch_a)\n",
    "    output_fc6_patch_b = self.forward_once(patch_b)\n",
    "    output_fc6_patch_c = self.forward_once(patch_c)\n",
    "    output_fc6_patch_d = self.forward_once(patch_d)\n",
    "\n",
    "    output = torch.cat((output_fc6_patch_a, output_fc6_patch_b, output_fc6_patch_c, output_fc6_patch_d), 1)\n",
    "    output = self.fc(output)\n",
    "\n",
    "    return output, output_fc6_patch_a, output_fc6_patch_b, output_fc6_patch_c, output_fc6_patch_d\n",
    "\n",
    "model = VggNetwork().to(device)\n",
    "summary(model, [(3, 32, 32), (3, 32, 32), (3, 32, 32), (3, 32, 32)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
