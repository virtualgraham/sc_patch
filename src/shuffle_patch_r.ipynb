{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, datasets\n",
    " \n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    " \n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    " \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm # progress bar\n",
    "\n",
    "import skimage\n",
    "from skimage import img_as_ubyte, img_as_float32\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import math\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Parameters \n",
    "#########################################\n",
    "\n",
    "viz_image_paths = glob('/Users/racoon/Downloads/open-images-sample/*.jpg')\n",
    "training_image_paths = glob('/data/open-images-dataset/train/*.jpg')\n",
    "validation_image_paths = glob('/data/open-images-dataset/validation/*.jpg')\n",
    "\n",
    "train_dataset_length = 40192 # 314 iterations\n",
    "validation_dataset_length = 2048 \n",
    "train_batch_size = 128\n",
    "validation_batch_size = 128\n",
    "num_epochs = 1500\n",
    "save_after_epochs = 1 \n",
    "model_save_prefix = \"shuffle_patch_q\"\n",
    "\n",
    "patch_dim = 96\n",
    "gap = 32\n",
    "jitter = 16\n",
    "gray_portion = .30\n",
    "min_keypoints_per_patch = 4\n",
    "\n",
    "learn_rate = 0.0000625\n",
    "momentum = 0.974\n",
    "weight_decay = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Utilities \n",
    "#########################################\n",
    "\n",
    "def imshow(img,text=None,should_save=False):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
    "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()  \n",
    "\n",
    "def show_plot(iteration,loss,fname):\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.savefig(fname)\n",
    "    plt.show()\n",
    "    \n",
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        for i, t in enumerate(tensor):\n",
    "            t.mul_(self.std[i%3]).add_(self.mean[i%3])\n",
    "        return tensor\n",
    "\n",
    "unorm = UnNormalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########################################\n",
    "# This class generates patches for training\n",
    "#########################################\n",
    "\n",
    "patch_order_arr = [\n",
    "  (0, 1, 2, 3),\n",
    "  (0, 1, 3, 2),\n",
    "  (0, 2, 1, 3),\n",
    "  (0, 2, 3, 1),\n",
    "  (0, 3, 1, 2),\n",
    "  (0, 3, 2, 1),\n",
    "  (1, 0, 2, 3),\n",
    "  (1, 0, 3, 2),\n",
    "  (1, 2, 0, 3),\n",
    "  (1, 2, 3, 0),\n",
    "  (1, 3, 0, 2),\n",
    "  (1, 3, 2, 0),\n",
    "  (2, 0, 1, 3),\n",
    "  (2, 0, 3, 1),\n",
    "  (2, 1, 0, 3),\n",
    "  (2, 1, 3, 0),\n",
    "  (2, 3, 0, 1),\n",
    "  (2, 3, 1, 0),\n",
    "  (3, 0, 1, 2),\n",
    "  (3, 0, 2, 1),\n",
    "  (3, 1, 0, 2),\n",
    "  (3, 1, 2, 0),\n",
    "  (3, 2, 0, 1),\n",
    "  (3, 2, 1, 0)\n",
    "]\n",
    "\n",
    "class ShufflePatchDataset(Dataset):\n",
    "\n",
    "  def __init__(self, image_paths, patch_dim, length, gap, jitter, transform=None):\n",
    "    self.image_paths = image_paths\n",
    "    self.patch_dim = patch_dim\n",
    "    self.length = length\n",
    "    self.gap = gap\n",
    "    self.jitter = jitter\n",
    "    self.transform = transform\n",
    "    self.color_shift = 2\n",
    "    self.margin = math.ceil((2*patch_dim + 2*jitter + 2*self.color_shift + gap)/2)\n",
    "    self.min_width = 2 * self.margin + 1\n",
    "    self.orb = cv2.ORB_create(nfeatures=500, fastThreshold=10)\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.length\n",
    "  \n",
    "  def half_gap(self):\n",
    "    return math.ceil(self.gap/2)\n",
    "\n",
    "  def random_jitter(self):\n",
    "    return int(math.floor((self.jitter * 2 * random.random()))) - self.jitter\n",
    "\n",
    "  def random_shift(self):\n",
    "    return random.randrange(self.color_shift * 2 + 1)\n",
    "\n",
    "  def key_point_check(self, image, center_coord, patch_coords):\n",
    "    kp_margin = 32\n",
    "    window = image[max(0, center_coord[0]-self.margin-kp_margin):center_coord[0]+self.margin+kp_margin, max(0, center_coord[1]-self.margin-kp_margin):center_coord[1]+self.margin+kp_margin]\n",
    "    print('window.shape', window.shape, center_coord[0]-self.margin-kp_margin, center_coord[0]+self.margin+kp_margin, center_coord[1]-self.margin-kp_margin, center_coord[1]+self.margin+kp_margin)\n",
    "    kp = self. orb.detect(cv2.cvtColor(window, cv2.COLOR_RGB2GRAY), None)\n",
    "    window_coord = (center_coord[0]-self.margin-kp_margin, center_coord[1]-self.margin-kp_margin)\n",
    "    kp_counts = [0,0,0,0]\n",
    "    for k in kp:\n",
    "        k_ = (window_coord[0]+k.pt[1],window_coord[1]+k.pt[0]) # the keypoint relative to the whole image\n",
    "        for index, patch_coord in enumerate(patch_coords):\n",
    "          if (  k_[0] >= patch_coord[0] and \n",
    "                k_[0] < patch_coord[0]+self.patch_dim+2*self.color_shift and \n",
    "                k_[1] >= patch_coord[1] and \n",
    "                k_[1] < patch_coord[1]+self.patch_dim+2*self.color_shift ):  \n",
    "            kp_counts[index] += 1\n",
    "\n",
    "    print('kp_counts', kp_counts, len([c for c in kp_counts if c > 5]) > 2)\n",
    "    return True # all(c >= min_keypoints_per_patch for c in kp_counts)\n",
    "\n",
    "  # crops the patch by self.color_shift on each side\n",
    "  def prep_patch(self, image, gray):\n",
    " \n",
    "    cropped = np.empty((self.patch_dim, self.patch_dim, 3), dtype=np.uint8)\n",
    "\n",
    "    if(gray):\n",
    "\n",
    "      pil_patch = Image.fromarray(image)\n",
    "      pil_patch = pil_patch.convert('L')\n",
    "      pil_patch = pil_patch.convert('RGB')\n",
    "      np.copyto(cropped, np.array(pil_patch)[self.color_shift:self.color_shift+self.patch_dim, self.color_shift:self.color_shift+self.patch_dim, :])\n",
    "      \n",
    "    else:\n",
    "\n",
    "      shift = [self.random_shift() for _ in range(6)]\n",
    "      cropped[:,:,0] = image[shift[0]:shift[0]+self.patch_dim, shift[1]:shift[1]+self.patch_dim, 0]\n",
    "      cropped[:,:,1] = image[shift[2]:shift[2]+self.patch_dim, shift[3]:shift[3]+self.patch_dim, 1]\n",
    "      cropped[:,:,2] = image[shift[4]:shift[4]+self.patch_dim, shift[5]:shift[5]+self.patch_dim, 2]\n",
    "\n",
    "    return cropped\n",
    "\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    # [y, x, chan], dtype=uint8, top_left is (0,0)\n",
    "        \n",
    "    image_index = int(math.floor((len(self.image_paths) * random.random())))\n",
    "    \n",
    "    pil_image = Image.open(self.image_paths[image_index]).convert('RGB')\n",
    "\n",
    "    image = np.array(pil_image)\n",
    "\n",
    "    # If image is too small, try another image\n",
    "    if (image.shape[0] - self.min_width) <= 0 or (image.shape[1] - self.min_width) <= 0:\n",
    "        return self.__getitem__(index)\n",
    "    \n",
    "    center_y_coord = int(math.floor((image.shape[0] - self.margin*2) * random.random())) + self.margin\n",
    "    center_x_coord = int(math.floor((image.shape[1] - self.margin*2) * random.random())) + self.margin\n",
    "\n",
    "    patch_coords = [\n",
    "      (\n",
    "        center_y_coord - (self.patch_dim + self.half_gap() + self.random_jitter() + self.color_shift),\n",
    "        center_x_coord - (self.patch_dim + self.half_gap() + self.random_jitter() + self.color_shift)\n",
    "      ),\n",
    "      (\n",
    "        center_y_coord - (self.patch_dim + self.half_gap() + self.random_jitter() + self.color_shift),\n",
    "        center_x_coord + self.half_gap() + self.random_jitter() - self.color_shift\n",
    "      ),\n",
    "      (\n",
    "        center_y_coord + self.half_gap() + self.random_jitter() - self.color_shift,\n",
    "        center_x_coord - (self.patch_dim + self.half_gap() + self.random_jitter() + self.color_shift)\n",
    "      ),\n",
    "      (\n",
    "        center_y_coord + self.half_gap() + self.random_jitter() - self.color_shift,\n",
    "        center_x_coord + self.half_gap() + self.random_jitter() - self.color_shift\n",
    "      )\n",
    "    ]\n",
    "    \n",
    "    patch_shuffle_order_label = int(math.floor((24 * random.random())))\n",
    "\n",
    "    patch_coords = [pc for _,pc in sorted(zip(patch_order_arr[patch_shuffle_order_label],patch_coords))]\n",
    "\n",
    "    if not self.key_point_check(image, (center_y_coord, center_x_coord), patch_coords):\n",
    "      print(\"not enough keypoints\")\n",
    "      return self.__getitem__(index)\n",
    "\n",
    "    patch_a = image[patch_coords[0][0]:patch_coords[0][0]+self.patch_dim+2*self.color_shift, patch_coords[0][1]:patch_coords[0][1]+self.patch_dim+2*self.color_shift]\n",
    "    patch_b = image[patch_coords[1][0]:patch_coords[1][0]+self.patch_dim+2*self.color_shift, patch_coords[1][1]:patch_coords[1][1]+self.patch_dim+2*self.color_shift]\n",
    "    patch_c = image[patch_coords[2][0]:patch_coords[2][0]+self.patch_dim+2*self.color_shift, patch_coords[2][1]:patch_coords[2][1]+self.patch_dim+2*self.color_shift]\n",
    "    patch_d = image[patch_coords[3][0]:patch_coords[3][0]+self.patch_dim+2*self.color_shift, patch_coords[3][1]:patch_coords[3][1]+self.patch_dim+2*self.color_shift]\n",
    "\n",
    "    gray = random.random() < gray_portion\n",
    "\n",
    "    patch_a = self.prep_patch(patch_a, gray)\n",
    "    patch_b = self.prep_patch(patch_b, gray)\n",
    "    patch_c = self.prep_patch(patch_c, gray)\n",
    "    patch_d = self.prep_patch(patch_d, gray)\n",
    "\n",
    "    patch_shuffle_order_label = np.array(patch_shuffle_order_label).astype(np.int64)\n",
    "        \n",
    "    if self.transform:\n",
    "      patch_a = self.transform(patch_a)\n",
    "      patch_b = self.transform(patch_b)\n",
    "      patch_c = self.transform(patch_c)\n",
    "      patch_d = self.transform(patch_d)\n",
    "\n",
    "    return patch_a, patch_b, patch_c, patch_d, patch_shuffle_order_label\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##################################################\n",
    "# Creating Train/Validation dataset and dataloader\n",
    "##################################################\n",
    "\n",
    "traindataset = ShufflePatchDataset(training_image_paths, patch_dim, train_dataset_length, gap, jitter,\n",
    "                         transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(traindataset, \n",
    "                                          batch_size=train_batch_size,\n",
    "                                          num_workers=4,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "valdataset = ShufflePatchDataset(validation_image_paths, patch_dim, validation_dataset_length, gap, jitter,\n",
    "                         transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valdataset,\n",
    "                                        batch_size=validation_batch_size,\n",
    "                                        num_workers=4,\n",
    "                                        shuffle=False)\n",
    "\n",
    "\n",
    "valdataset = ShufflePatchDataset(viz_image_paths, patch_dim, 1, gap, jitter,\n",
    "                         transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valdataset,\n",
    "                                        batch_size=1,\n",
    "                                        shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "# Visualizing validation dataset\n",
    "#############################\n",
    "\n",
    "example_batch_val = next(iter(valloader))\n",
    "concatenated = torch.cat((unorm(example_batch_val[0]),unorm(example_batch_val[1]),unorm(example_batch_val[2]),unorm(example_batch_val[3])),0)\n",
    "imshow(torchvision.utils.make_grid(concatenated))\n",
    "print(f'Labels: {example_batch_val[4].numpy()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
