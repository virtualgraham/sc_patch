{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, datasets\n",
    " \n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    " \n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    " \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm # progress bar\n",
    "\n",
    "import skimage\n",
    "import cv2\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import math\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Parameters \n",
    "#########################################\n",
    "\n",
    "viz_image_paths = glob('/Users/racoon/Documents/sc_patch/src/evaluation_metric/dataset_100/train/*/*.jpg')\n",
    "training_image_paths = glob('/Users/racoon/Documents/sc_patch/src/evaluation_metric/dataset_100/train/*/*.jpg')\n",
    "validation_image_paths = glob('/Users/racoon/Documents/sc_patch/src/evaluation_metric/dataset_100/train/*/*.jpg')\n",
    "\n",
    "train_dataset_length = 40960\n",
    "validation_dataset_length = 4096\n",
    "train_batch_size = 128\n",
    "validation_batch_size = 128\n",
    "num_epochs = 3000\n",
    "save_after_epochs = 1 \n",
    "backup_after_epochs = 10 \n",
    "model_save_prefix = \"rotation_jigsaw\"\n",
    "color_shift = 1\n",
    "patch_dim = 128\n",
    "jitter = 24\n",
    "gray_portion = .30\n",
    "reuse_image_count = 4\n",
    "\n",
    "learn_rate = 0.001\n",
    "momentum = 0.974\n",
    "weight_decay = 0.0005\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# Utilities \n",
    "#########################################\n",
    "\n",
    "def imshow(img,text=None,should_save=False):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
    "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()  \n",
    "\n",
    "def show_plot(iteration,loss,fname):\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.savefig(fname)\n",
    "    plt.show()\n",
    "    \n",
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        for i, t in enumerate(tensor):\n",
    "            t.mul_(self.std[i%3]).add_(self.mean[i%3])\n",
    "        return tensor\n",
    "\n",
    "unorm = UnNormalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########################################\n",
    "# This class generates patches for training\n",
    "#########################################\n",
    "\n",
    "patch_order_arr = [\n",
    "  (0, 1, 2, 3),\n",
    "  (0, 1, 3, 2),\n",
    "  (0, 2, 1, 3),\n",
    "  (0, 2, 3, 1),\n",
    "  (0, 3, 1, 2),\n",
    "  (0, 3, 2, 1),\n",
    "  (1, 0, 2, 3),\n",
    "  (1, 0, 3, 2),\n",
    "  (1, 2, 0, 3),\n",
    "  (1, 2, 3, 0),\n",
    "  (1, 3, 0, 2),\n",
    "  (1, 3, 2, 0),\n",
    "  (2, 0, 1, 3),\n",
    "  (2, 0, 3, 1),\n",
    "  (2, 1, 0, 3),\n",
    "  (2, 1, 3, 0),\n",
    "  (2, 3, 0, 1),\n",
    "  (2, 3, 1, 0),\n",
    "  (3, 0, 1, 2),\n",
    "  (3, 0, 2, 1),\n",
    "  (3, 1, 0, 2),\n",
    "  (3, 1, 2, 0),\n",
    "  (3, 2, 0, 1),\n",
    "  (3, 2, 1, 0)\n",
    "]\n",
    "\n",
    "class ShufflePatchDataset(Dataset):\n",
    "\n",
    "  def __init__(self, image_paths, patch_dim, length, jitter, color_shift, transform=None):\n",
    "    self.image_paths = image_paths\n",
    "    self.patch_dim = patch_dim\n",
    "    self.length = length\n",
    "    self.jitter = jitter\n",
    "    self.color_shift = color_shift\n",
    "    self.transform = transform\n",
    "    self.image_reused = 0\n",
    "\n",
    "    self.sub_window_width = self.patch_dim + 2*self.jitter + 2*self.color_shift\n",
    "    self.window_width = 2*self.sub_window_width\n",
    "    \n",
    "    self.min_image_width = self.window_width + 1\n",
    "\n",
    "    self.saliency = cv2.saliency.StaticSaliencyFineGrained_create()\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.length\n",
    "\n",
    "  def random_jitter(self):\n",
    "    return int(math.floor((self.jitter * 2 * random.random())))\n",
    "\n",
    "  def random_shift(self):\n",
    "    return random.randrange(self.color_shift * 2 + 1)\n",
    "\n",
    "  def prep_patch(self, image):\n",
    " \n",
    "    cropped = np.empty((self.patch_dim, self.patch_dim, 3), dtype=np.uint8)\n",
    "\n",
    "    if(random.random() < gray_portion):\n",
    "\n",
    "      pil_patch = Image.fromarray(image)\n",
    "      pil_patch = pil_patch.convert('L')\n",
    "      pil_patch = pil_patch.convert('RGB')\n",
    "      np.copyto(cropped, np.array(pil_patch)[self.color_shift:self.color_shift+self.patch_dim, self.color_shift:self.color_shift+self.patch_dim, :])\n",
    "      \n",
    "    else:\n",
    "\n",
    "      shift = [self.random_shift() for _ in range(6)]\n",
    "      cropped[:,:,0] = image[shift[0]:shift[0]+self.patch_dim, shift[1]:shift[1]+self.patch_dim, 0]\n",
    "      cropped[:,:,1] = image[shift[2]:shift[2]+self.patch_dim, shift[3]:shift[3]+self.patch_dim, 1]\n",
    "      cropped[:,:,2] = image[shift[4]:shift[4]+self.patch_dim, shift[5]:shift[5]+self.patch_dim, 2]\n",
    "\n",
    "    return cropped\n",
    "\n",
    "  def saliency_check(self, window, patch_coords):\n",
    "    (success, saliency_map) = self.saliency.computeSaliency(cv2.cvtColor(window, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    high_saliency_patches = 0\n",
    "    med_saliency_patches = 0\n",
    "    \n",
    "    for p in patch_coords:\n",
    "        patch_saliency_map = saliency_map[p[0]:p[0]+self.patch_dim, p[1]:p[1]+self.patch_dim]\n",
    "        patch_saliency = np.sum(patch_saliency_map > .40)\n",
    "        print(patch_saliency)\n",
    "        if patch_saliency >= 400:\n",
    "          high_saliency_patches += 1\n",
    "        elif patch_saliency >= 150:\n",
    "          med_saliency_patches += 1\n",
    "\n",
    "    print((high_saliency_patches > 0 and (high_saliency_patches + med_saliency_patches) > 2))\n",
    "    return True\n",
    "    \n",
    "    # return (high_saliency_patches > 0 and (high_saliency_patches + med_saliency_patches) > 2)\n",
    "\n",
    "\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    # [y, x, chan], dtype=uint8, top_left is (0,0)\n",
    "    \n",
    "    image_index = int(math.floor((len(self.image_paths) * random.random())))\n",
    "    \n",
    "    if self.image_reused == 0:\n",
    "      self.pil_image = Image.open(self.image_paths[image_index]).convert('RGB')\n",
    "      self.image_reused = reuse_image_count - 1\n",
    "    else:\n",
    "      self.image_reused -= 1\n",
    "\n",
    "    image = np.array(self.pil_image)\n",
    "\n",
    "    # If image is too small, try another image\n",
    "    if (image.shape[0] - self.min_image_width) <= 0 or (image.shape[1] - self.min_image_width) <= 0:\n",
    "        return self.__getitem__(index)\n",
    "    \n",
    "    window_y_coord = int(math.floor((image.shape[0] - self.window_width) * random.random()))\n",
    "    window_x_coord = int(math.floor((image.shape[1] - self.window_width) * random.random()))\n",
    "\n",
    "    window = image[window_y_coord:window_y_coord+self.window_width, window_x_coord:window_x_coord+self.window_width]\n",
    "    \n",
    "    rotation_label = int(math.floor((4 * random.random())))\n",
    "    order_label = int(math.floor((24 * random.random()))) \n",
    "    \n",
    "    if rotation_label>0:\n",
    "      window = np.rot90(window, rotation_label).copy()\n",
    "\n",
    "    patch_coords = [\n",
    "      (self.random_jitter(), self.random_jitter()),\n",
    "      (self.random_jitter(), self.sub_window_width + self.random_jitter()),\n",
    "      (self.sub_window_width + self.random_jitter(), self.random_jitter()),\n",
    "      (self.sub_window_width + self.random_jitter(), self.sub_window_width + self.random_jitter()),\n",
    "    ]\n",
    "\n",
    "    patch_coords = [pc for _,pc in sorted(zip(patch_order_arr[order_label],patch_coords))]\n",
    "\n",
    "    if not self.saliency_check(window, patch_coords):\n",
    "      return self.__getitem__(index)\n",
    "\n",
    "    patch_a = window[patch_coords[0][0]:patch_coords[0][0]+self.patch_dim+2*self.color_shift, patch_coords[0][1]:patch_coords[0][1]+self.patch_dim+2*self.color_shift]\n",
    "    patch_b = window[patch_coords[1][0]:patch_coords[1][0]+self.patch_dim+2*self.color_shift, patch_coords[1][1]:patch_coords[1][1]+self.patch_dim+2*self.color_shift]\n",
    "    patch_c = window[patch_coords[2][0]:patch_coords[2][0]+self.patch_dim+2*self.color_shift, patch_coords[2][1]:patch_coords[2][1]+self.patch_dim+2*self.color_shift]\n",
    "    patch_d = window[patch_coords[3][0]:patch_coords[3][0]+self.patch_dim+2*self.color_shift, patch_coords[3][1]:patch_coords[3][1]+self.patch_dim+2*self.color_shift]\n",
    "\n",
    "    # gray = random.random() < gray_portion\n",
    "\n",
    "    patch_a = self.prep_patch(patch_a)\n",
    "    patch_b = self.prep_patch(patch_b)\n",
    "    patch_c = self.prep_patch(patch_c)\n",
    "    patch_d = self.prep_patch(patch_d)\n",
    "\n",
    "    combined_label = np.array(rotation_label * 24 + order_label).astype(np.int64)\n",
    "        \n",
    "    if self.transform:\n",
    "      patch_a = self.transform(patch_a)\n",
    "      patch_b = self.transform(patch_b)\n",
    "      patch_c = self.transform(patch_c)\n",
    "      patch_d = self.transform(patch_d)\n",
    "\n",
    "    return patch_a, patch_b, patch_c, patch_d, combined_label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##################################################\n",
    "# Creating Train/Validation dataset and dataloader\n",
    "##################################################\n",
    "\n",
    "\n",
    "vizdataset = ShufflePatchDataset(viz_image_paths, patch_dim, 1, jitter, color_shift,\n",
    "                         transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "\n",
    "vizloader = torch.utils.data.DataLoader(vizdataset,\n",
    "                                        batch_size=1,\n",
    "                                        shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2342\n",
      "4850\n",
      "2899\n",
      "7065\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "# Visualizing validation dataset\n",
    "#############################\n",
    "\n",
    "example_batch_val = next(iter(vizloader))\n",
    "concatenated = torch.cat((unorm(example_batch_val[0]),unorm(example_batch_val[1]),unorm(example_batch_val[2]),unorm(example_batch_val[3])),0)\n",
    "imshow(torchvision.utils.make_grid(concatenated, nrow=2))\n",
    "print(f'Labels: {example_batch_val[4].numpy()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 96, 96]           1,792\n",
      "       BatchNorm2d-2           [-1, 64, 96, 96]             128\n",
      "              ReLU-3           [-1, 64, 96, 96]               0\n",
      "            Conv2d-4           [-1, 64, 96, 96]          36,928\n",
      "       BatchNorm2d-5           [-1, 64, 96, 96]             128\n",
      "              ReLU-6           [-1, 64, 96, 96]               0\n",
      "         MaxPool2d-7           [-1, 64, 48, 48]               0\n",
      "            Conv2d-8          [-1, 128, 48, 48]          73,856\n",
      "       BatchNorm2d-9          [-1, 128, 48, 48]             256\n",
      "             ReLU-10          [-1, 128, 48, 48]               0\n",
      "           Conv2d-11          [-1, 128, 48, 48]         147,584\n",
      "      BatchNorm2d-12          [-1, 128, 48, 48]             256\n",
      "             ReLU-13          [-1, 128, 48, 48]               0\n",
      "        MaxPool2d-14          [-1, 128, 24, 24]               0\n",
      "           Conv2d-15          [-1, 256, 24, 24]         295,168\n",
      "      BatchNorm2d-16          [-1, 256, 24, 24]             512\n",
      "             ReLU-17          [-1, 256, 24, 24]               0\n",
      "           Conv2d-18          [-1, 256, 24, 24]         590,080\n",
      "      BatchNorm2d-19          [-1, 256, 24, 24]             512\n",
      "             ReLU-20          [-1, 256, 24, 24]               0\n",
      "           Conv2d-21          [-1, 256, 24, 24]         590,080\n",
      "      BatchNorm2d-22          [-1, 256, 24, 24]             512\n",
      "             ReLU-23          [-1, 256, 24, 24]               0\n",
      "        MaxPool2d-24          [-1, 256, 12, 12]               0\n",
      "           Conv2d-25          [-1, 512, 12, 12]       1,180,160\n",
      "      BatchNorm2d-26          [-1, 512, 12, 12]           1,024\n",
      "             ReLU-27          [-1, 512, 12, 12]               0\n",
      "           Conv2d-28          [-1, 512, 12, 12]       2,359,808\n",
      "      BatchNorm2d-29          [-1, 512, 12, 12]           1,024\n",
      "             ReLU-30          [-1, 512, 12, 12]               0\n",
      "           Conv2d-31          [-1, 512, 12, 12]       2,359,808\n",
      "      BatchNorm2d-32          [-1, 512, 12, 12]           1,024\n",
      "             ReLU-33          [-1, 512, 12, 12]               0\n",
      "        MaxPool2d-34            [-1, 512, 6, 6]               0\n",
      "           Conv2d-35            [-1, 512, 6, 6]       2,359,808\n",
      "      BatchNorm2d-36            [-1, 512, 6, 6]           1,024\n",
      "             ReLU-37            [-1, 512, 6, 6]               0\n",
      "           Conv2d-38            [-1, 512, 6, 6]       2,359,808\n",
      "      BatchNorm2d-39            [-1, 512, 6, 6]           1,024\n",
      "             ReLU-40            [-1, 512, 6, 6]               0\n",
      "           Conv2d-41            [-1, 512, 6, 6]       2,359,808\n",
      "      BatchNorm2d-42            [-1, 512, 6, 6]           1,024\n",
      "             ReLU-43            [-1, 512, 6, 6]               0\n",
      "        MaxPool2d-44            [-1, 512, 3, 3]               0\n",
      "           Linear-45                 [-1, 4096]      18,878,464\n",
      "             ReLU-46                 [-1, 4096]               0\n",
      "          Dropout-47                 [-1, 4096]               0\n",
      "           Conv2d-48           [-1, 64, 96, 96]           1,792\n",
      "      BatchNorm2d-49           [-1, 64, 96, 96]             128\n",
      "             ReLU-50           [-1, 64, 96, 96]               0\n",
      "           Conv2d-51           [-1, 64, 96, 96]          36,928\n",
      "      BatchNorm2d-52           [-1, 64, 96, 96]             128\n",
      "             ReLU-53           [-1, 64, 96, 96]               0\n",
      "        MaxPool2d-54           [-1, 64, 48, 48]               0\n",
      "           Conv2d-55          [-1, 128, 48, 48]          73,856\n",
      "      BatchNorm2d-56          [-1, 128, 48, 48]             256\n",
      "             ReLU-57          [-1, 128, 48, 48]               0\n",
      "           Conv2d-58          [-1, 128, 48, 48]         147,584\n",
      "      BatchNorm2d-59          [-1, 128, 48, 48]             256\n",
      "             ReLU-60          [-1, 128, 48, 48]               0\n",
      "        MaxPool2d-61          [-1, 128, 24, 24]               0\n",
      "           Conv2d-62          [-1, 256, 24, 24]         295,168\n",
      "      BatchNorm2d-63          [-1, 256, 24, 24]             512\n",
      "             ReLU-64          [-1, 256, 24, 24]               0\n",
      "           Conv2d-65          [-1, 256, 24, 24]         590,080\n",
      "      BatchNorm2d-66          [-1, 256, 24, 24]             512\n",
      "             ReLU-67          [-1, 256, 24, 24]               0\n",
      "           Conv2d-68          [-1, 256, 24, 24]         590,080\n",
      "      BatchNorm2d-69          [-1, 256, 24, 24]             512\n",
      "             ReLU-70          [-1, 256, 24, 24]               0\n",
      "        MaxPool2d-71          [-1, 256, 12, 12]               0\n",
      "           Conv2d-72          [-1, 512, 12, 12]       1,180,160\n",
      "      BatchNorm2d-73          [-1, 512, 12, 12]           1,024\n",
      "             ReLU-74          [-1, 512, 12, 12]               0\n",
      "           Conv2d-75          [-1, 512, 12, 12]       2,359,808\n",
      "      BatchNorm2d-76          [-1, 512, 12, 12]           1,024\n",
      "             ReLU-77          [-1, 512, 12, 12]               0\n",
      "           Conv2d-78          [-1, 512, 12, 12]       2,359,808\n",
      "      BatchNorm2d-79          [-1, 512, 12, 12]           1,024\n",
      "             ReLU-80          [-1, 512, 12, 12]               0\n",
      "        MaxPool2d-81            [-1, 512, 6, 6]               0\n",
      "           Conv2d-82            [-1, 512, 6, 6]       2,359,808\n",
      "      BatchNorm2d-83            [-1, 512, 6, 6]           1,024\n",
      "             ReLU-84            [-1, 512, 6, 6]               0\n",
      "           Conv2d-85            [-1, 512, 6, 6]       2,359,808\n",
      "      BatchNorm2d-86            [-1, 512, 6, 6]           1,024\n",
      "             ReLU-87            [-1, 512, 6, 6]               0\n",
      "           Conv2d-88            [-1, 512, 6, 6]       2,359,808\n",
      "      BatchNorm2d-89            [-1, 512, 6, 6]           1,024\n",
      "             ReLU-90            [-1, 512, 6, 6]               0\n",
      "        MaxPool2d-91            [-1, 512, 3, 3]               0\n",
      "           Linear-92                 [-1, 4096]      18,878,464\n",
      "             ReLU-93                 [-1, 4096]               0\n",
      "          Dropout-94                 [-1, 4096]               0\n",
      "           Conv2d-95           [-1, 64, 96, 96]           1,792\n",
      "      BatchNorm2d-96           [-1, 64, 96, 96]             128\n",
      "             ReLU-97           [-1, 64, 96, 96]               0\n",
      "           Conv2d-98           [-1, 64, 96, 96]          36,928\n",
      "      BatchNorm2d-99           [-1, 64, 96, 96]             128\n",
      "            ReLU-100           [-1, 64, 96, 96]               0\n",
      "       MaxPool2d-101           [-1, 64, 48, 48]               0\n",
      "          Conv2d-102          [-1, 128, 48, 48]          73,856\n",
      "     BatchNorm2d-103          [-1, 128, 48, 48]             256\n",
      "            ReLU-104          [-1, 128, 48, 48]               0\n",
      "          Conv2d-105          [-1, 128, 48, 48]         147,584\n",
      "     BatchNorm2d-106          [-1, 128, 48, 48]             256\n",
      "            ReLU-107          [-1, 128, 48, 48]               0\n",
      "       MaxPool2d-108          [-1, 128, 24, 24]               0\n",
      "          Conv2d-109          [-1, 256, 24, 24]         295,168\n",
      "     BatchNorm2d-110          [-1, 256, 24, 24]             512\n",
      "            ReLU-111          [-1, 256, 24, 24]               0\n",
      "          Conv2d-112          [-1, 256, 24, 24]         590,080\n",
      "     BatchNorm2d-113          [-1, 256, 24, 24]             512\n",
      "            ReLU-114          [-1, 256, 24, 24]               0\n",
      "          Conv2d-115          [-1, 256, 24, 24]         590,080\n",
      "     BatchNorm2d-116          [-1, 256, 24, 24]             512\n",
      "            ReLU-117          [-1, 256, 24, 24]               0\n",
      "       MaxPool2d-118          [-1, 256, 12, 12]               0\n",
      "          Conv2d-119          [-1, 512, 12, 12]       1,180,160\n",
      "     BatchNorm2d-120          [-1, 512, 12, 12]           1,024\n",
      "            ReLU-121          [-1, 512, 12, 12]               0\n",
      "          Conv2d-122          [-1, 512, 12, 12]       2,359,808\n",
      "     BatchNorm2d-123          [-1, 512, 12, 12]           1,024\n",
      "            ReLU-124          [-1, 512, 12, 12]               0\n",
      "          Conv2d-125          [-1, 512, 12, 12]       2,359,808\n",
      "     BatchNorm2d-126          [-1, 512, 12, 12]           1,024\n",
      "            ReLU-127          [-1, 512, 12, 12]               0\n",
      "       MaxPool2d-128            [-1, 512, 6, 6]               0\n",
      "          Conv2d-129            [-1, 512, 6, 6]       2,359,808\n",
      "     BatchNorm2d-130            [-1, 512, 6, 6]           1,024\n",
      "            ReLU-131            [-1, 512, 6, 6]               0\n",
      "          Conv2d-132            [-1, 512, 6, 6]       2,359,808\n",
      "     BatchNorm2d-133            [-1, 512, 6, 6]           1,024\n",
      "            ReLU-134            [-1, 512, 6, 6]               0\n",
      "          Conv2d-135            [-1, 512, 6, 6]       2,359,808\n",
      "     BatchNorm2d-136            [-1, 512, 6, 6]           1,024\n",
      "            ReLU-137            [-1, 512, 6, 6]               0\n",
      "       MaxPool2d-138            [-1, 512, 3, 3]               0\n",
      "          Linear-139                 [-1, 4096]      18,878,464\n",
      "            ReLU-140                 [-1, 4096]               0\n",
      "         Dropout-141                 [-1, 4096]               0\n",
      "          Conv2d-142           [-1, 64, 96, 96]           1,792\n",
      "     BatchNorm2d-143           [-1, 64, 96, 96]             128\n",
      "            ReLU-144           [-1, 64, 96, 96]               0\n",
      "          Conv2d-145           [-1, 64, 96, 96]          36,928\n",
      "     BatchNorm2d-146           [-1, 64, 96, 96]             128\n",
      "            ReLU-147           [-1, 64, 96, 96]               0\n",
      "       MaxPool2d-148           [-1, 64, 48, 48]               0\n",
      "          Conv2d-149          [-1, 128, 48, 48]          73,856\n",
      "     BatchNorm2d-150          [-1, 128, 48, 48]             256\n",
      "            ReLU-151          [-1, 128, 48, 48]               0\n",
      "          Conv2d-152          [-1, 128, 48, 48]         147,584\n",
      "     BatchNorm2d-153          [-1, 128, 48, 48]             256\n",
      "            ReLU-154          [-1, 128, 48, 48]               0\n",
      "       MaxPool2d-155          [-1, 128, 24, 24]               0\n",
      "          Conv2d-156          [-1, 256, 24, 24]         295,168\n",
      "     BatchNorm2d-157          [-1, 256, 24, 24]             512\n",
      "            ReLU-158          [-1, 256, 24, 24]               0\n",
      "          Conv2d-159          [-1, 256, 24, 24]         590,080\n",
      "     BatchNorm2d-160          [-1, 256, 24, 24]             512\n",
      "            ReLU-161          [-1, 256, 24, 24]               0\n",
      "          Conv2d-162          [-1, 256, 24, 24]         590,080\n",
      "     BatchNorm2d-163          [-1, 256, 24, 24]             512\n",
      "            ReLU-164          [-1, 256, 24, 24]               0\n",
      "       MaxPool2d-165          [-1, 256, 12, 12]               0\n",
      "          Conv2d-166          [-1, 512, 12, 12]       1,180,160\n",
      "     BatchNorm2d-167          [-1, 512, 12, 12]           1,024\n",
      "            ReLU-168          [-1, 512, 12, 12]               0\n",
      "          Conv2d-169          [-1, 512, 12, 12]       2,359,808\n",
      "     BatchNorm2d-170          [-1, 512, 12, 12]           1,024\n",
      "            ReLU-171          [-1, 512, 12, 12]               0\n",
      "          Conv2d-172          [-1, 512, 12, 12]       2,359,808\n",
      "     BatchNorm2d-173          [-1, 512, 12, 12]           1,024\n",
      "            ReLU-174          [-1, 512, 12, 12]               0\n",
      "       MaxPool2d-175            [-1, 512, 6, 6]               0\n",
      "          Conv2d-176            [-1, 512, 6, 6]       2,359,808\n",
      "     BatchNorm2d-177            [-1, 512, 6, 6]           1,024\n",
      "            ReLU-178            [-1, 512, 6, 6]               0\n",
      "          Conv2d-179            [-1, 512, 6, 6]       2,359,808\n",
      "     BatchNorm2d-180            [-1, 512, 6, 6]           1,024\n",
      "            ReLU-181            [-1, 512, 6, 6]               0\n",
      "          Conv2d-182            [-1, 512, 6, 6]       2,359,808\n",
      "     BatchNorm2d-183            [-1, 512, 6, 6]           1,024\n",
      "            ReLU-184            [-1, 512, 6, 6]               0\n",
      "       MaxPool2d-185            [-1, 512, 3, 3]               0\n",
      "          Linear-186                 [-1, 4096]      18,878,464\n",
      "            ReLU-187                 [-1, 4096]               0\n",
      "         Dropout-188                 [-1, 4096]               0\n",
      "          Linear-189                 [-1, 4096]      67,112,960\n",
      "            ReLU-190                 [-1, 4096]               0\n",
      "         Dropout-191                 [-1, 4096]               0\n",
      "          Linear-192                   [-1, 96]         393,312\n",
      "================================================================\n",
      "Total params: 201,912,672\n",
      "Trainable params: 201,912,672\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 2229025112064.00\n",
      "Forward/backward pass size (MB): 236.86\n",
      "Params size (MB): 770.24\n",
      "Estimated Total Size (MB): 2229025113071.10\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "# Model for learning patch position\n",
    "##################################################\n",
    "\n",
    "class VggNetwork(nn.Module):\n",
    "  def __init__(self,aux_logits = False):\n",
    "\n",
    "      super(VggNetwork, self).__init__()\n",
    "\n",
    "      self.cnn = nn.Sequential(\n",
    "        nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(64), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(64), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "        nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(128), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(128), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "        nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(256), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(256), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(256), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "        nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "      )\n",
    "    \n",
    "      self.fc6 = nn.Sequential(\n",
    "        nn.Linear(512 * 3 * 3, 4096),\n",
    "        nn.ReLU(True),\n",
    "        nn.Dropout(),\n",
    "      )\n",
    "\n",
    "      self.fc = nn.Sequential(\n",
    "        nn.Linear(4*4096, 4096),\n",
    "        nn.ReLU(True),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(4096, 96),\n",
    "      )\n",
    "\n",
    "  def forward_once(self, x):\n",
    "    output= self.cnn(x)\n",
    "    output = output.view(output.size()[0], -1)\n",
    "    output = self.fc6(output)\n",
    "    return output\n",
    "\n",
    "  def forward(self, patch_a, patch_b, patch_c, patch_d):\n",
    "    output_fc6_patch_a = self.forward_once(patch_a)\n",
    "    output_fc6_patch_b = self.forward_once(patch_b)\n",
    "    output_fc6_patch_c = self.forward_once(patch_c)\n",
    "    output_fc6_patch_d = self.forward_once(patch_d)\n",
    "\n",
    "    output = torch.cat((output_fc6_patch_a, output_fc6_patch_b, output_fc6_patch_c, output_fc6_patch_d), 1)\n",
    "    output = self.fc(output)\n",
    "\n",
    "    return output, output_fc6_patch_a, output_fc6_patch_b, output_fc6_patch_c, output_fc6_patch_d\n",
    "\n",
    "model = VggNetwork().to(device)\n",
    "summary(model, [(3, patch_dim, patch_dim), (3, patch_dim, patch_dim), (3, patch_dim, patch_dim), (3, patch_dim, patch_dim)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
