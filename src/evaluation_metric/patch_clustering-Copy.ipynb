{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hnswlib\n",
    "from PIL import Image\n",
    "from ShufflePatchModel16 import ShufflePatchFeatureExtractor\n",
    "from VggFeatureExtractor import VggFeatureExtractor\n",
    "from glob import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import ipyplot\n",
    "import math\n",
    "from sklearn.cluster import KMeans, MeanShift, estimate_bandwidth\n",
    "from itertools import compress\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 32\n",
    "stride = 24\n",
    "kp_margin = 16 # keypoint detector has a margin around image where it can not find keypoints\n",
    "n_clusters = 1000\n",
    "\n",
    "cnn = VggFeatureExtractor()\n",
    "\n",
    "def extract_windows(frame, pos, window_size):\n",
    "    windows = np.empty((len(pos), window_size, window_size, 3), dtype=np.uint8)\n",
    "\n",
    "    for i in range(len(pos)):\n",
    "        windows[i] = extract_window(frame, pos[i], window_size)\n",
    "\n",
    "    return windows\n",
    "\n",
    "\n",
    "def extract_window(frame, pos, window_size):\n",
    "    half_w = window_size/2.0\n",
    "\n",
    "    top_left = [int(round(pos[0]-half_w)), int(round(pos[1]-half_w))]\n",
    "    bottom_right = [top_left[0]+window_size, top_left[1]+window_size]\n",
    "\n",
    "    return frame[top_left[0]:bottom_right[0], top_left[1]:bottom_right[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extract all patches from dataset and generate features\n",
    "- Cluster features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = glob(\"dataset_100/train/*/*.jpg\")\n",
    "\n",
    "X = []\n",
    "\n",
    "for idx, image_file in enumerate(image_files):\n",
    "    print(idx, image_file)\n",
    "    pil_image = Image.open(image_file).convert('RGB')\n",
    "    pil_image = pil_image.resize((int(round(pil_image.size[0]/3)), int(round(pil_image.size[1]/3))))\n",
    "    image = np.array(pil_image)\n",
    "\n",
    "    grid = (math.floor((image.shape[0] - (window_size - stride)) / stride), math.floor((image.shape[1] - (window_size - stride)) / stride))\n",
    "    margin = ((image.shape[0] - grid[0] * stride)/2, (image.shape[1] - grid[1] * stride)/2)\n",
    "    points = [(margin[0]+y*stride+stride/2,margin[1]+x*stride+stride/2) for y in range(grid[0]) for x in range(grid[1])]\n",
    "    \n",
    "    print('len(points)', len(points))\n",
    "    \n",
    "    patches = extract_windows(image, points, 32)\n",
    "\n",
    "    windows = patches.astype(np.float64)\n",
    "\n",
    "    feats = cnn.evalRGB(windows)\n",
    "    feats = feats.reshape((windows.shape[0], 512))\n",
    "    X.extend(list(feats))\n",
    "\n",
    "\n",
    "print(\"Clustering with KMeans\")\n",
    "clusters = KMeans(n_clusters=n_clusters, verbose=True)\n",
    "clusters.fit(np.array(X, dtype=np.float32))\n",
    "\n",
    "cluster_count = len(np.unique(clusters.labels_))\n",
    "print('cluster_count', cluster_count)\n",
    "\n",
    "pickle.dump(clusters, open(\"clusters.pkl\", \"wb\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select_count = 10\n",
    "\n",
    "# select_ids = random.sample(patch_dict.keys(), select_count)\n",
    "# #print(select_ids)\n",
    "# select_feats = index.get_items(select_ids)\n",
    "# #print(len(select_feats))\n",
    "# nn_ids, nn_dis = index.knn_query(select_feats, 10)\n",
    "\n",
    "# for i in range(select_count):\n",
    "#     patch = patch_dict.get(select_ids[i])\n",
    "#     nn_patches = [patch_dict.get(q) for q in nn_ids[i]]\n",
    "#     nn_dis_labels = [q for q in nn_dis[i]]\n",
    "\n",
    "#     ipyplot.plot_images([patch], ['patch'])\n",
    "#     ipyplot.plot_images(nn_patches, nn_dis_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save Cluster Model\n",
    "- Perform random walks from patch to  patch\n",
    "- generate graph of adjacencies and frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build adjacency graph with patch walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salient_grid_locations(image, stride, offsets, orb):\n",
    "\n",
    "    kp = orb.detect(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), None)\n",
    "\n",
    "    grid = set()\n",
    "\n",
    "    for k in kp:\n",
    "        p = (k.pt[1], k.pt[0]) \n",
    "        g = (int(math.floor((p[0]-offsets[0])/stride)), int(math.floor((p[1]-offsets[1])/stride)))\n",
    "        grid.add(g)\n",
    "    \n",
    "    return grid\n",
    "\n",
    "\n",
    "def get_rad_grid(grid_pos, rad, grid_shape):\n",
    "\n",
    "    top_left = (grid_pos[0]-rad, grid_pos[1]-rad)\n",
    "\n",
    "    res = []\n",
    "\n",
    "    for i in range(2*rad+1):\n",
    "        p = (top_left[0]+i, top_left[1])\n",
    "        if p[0] >= 0 and p[1] >= 0 and p[0] < grid_shape[0] and p[1] < grid_shape[1]:\n",
    "            res.append(p)\n",
    " \n",
    "    for i in range(2*rad+1):\n",
    "        p = (top_left[0]+i, top_left[1]+(2*rad))\n",
    "        if p[0] >= 0 and p[1] >= 0 and p[0] < grid_shape[0] and p[1] < grid_shape[1]:\n",
    "            res.append(p)\n",
    "\n",
    "    for i in range(2*rad-1):\n",
    "        p = (top_left[0], top_left[1]+(i+1))\n",
    "        if p[0] >= 0 and p[1] >= 0 and p[0] < grid_shape[0] and p[1] < grid_shape[1]:\n",
    "            res.append(p)\n",
    "\n",
    "    for i in range(2*rad-1):\n",
    "        p = (top_left[0]+(2*rad), top_left[1]+(i+1))\n",
    "        if p[0] >= 0 and p[1] >= 0 and p[0] < grid_shape[0] and p[1] < grid_shape[1]:\n",
    "            res.append(p)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_image_adjacencies(image_file, clusters, feature_extractor, adjacency_graph, orb):\n",
    "    print(\"add_image_adjacencies\", image_file)\n",
    "\n",
    "    pil_image = Image.open(image_file).convert('RGB')\n",
    "    pil_image = pil_image.resize((int(round(pil_image.size[0]/3)), int(round(pil_image.size[1]/3))))\n",
    "    image = np.array(pil_image)\n",
    "\n",
    "    margin = max(window_size, kp_margin*2)\n",
    "    grid_shape = (math.floor((image.shape[0] - margin) / stride), math.floor((image.shape[1] - margin) / stride))\n",
    "    offsets = (round((image.shape[0] - grid_shape[0] * stride)/2), round((image.shape[1] - grid_shape[1] * stride)/2))\n",
    "\n",
    "    grid_locations_set = salient_grid_locations(image, stride, offsets, orb)\n",
    "    grid_locations_list = list(grid_locations_set)\n",
    "    \n",
    "    points = [(y*stride + stride/2 + offsets[0], x*stride + stride/2 + offsets[1]) for (y,x) in grid_locations_list]\n",
    "    \n",
    "    print('salient grid locations', grid_shape, len(grid_locations_list), 'of', grid_shape[0] * grid_shape[1])\n",
    "        \n",
    "    patches = extract_windows(image, points, window_size)\n",
    "    windows = patches.astype(np.float64)\n",
    "\n",
    "    feats = cnn.evalRGB(windows)\n",
    "    feats = feats.reshape((windows.shape[0], 512))\n",
    "\n",
    "    grid_cluster_ids = clusters.predict(feats)\n",
    "    \n",
    "    adjacency_count = 0\n",
    "    \n",
    "    for location in grid_locations_list:\n",
    "        cluster_id = grid_cluster_ids[grid_locations_list.index(location)]\n",
    "        \n",
    "        adjacent_locations = get_rad_grid(location, 1, grid_shape)\n",
    "        \n",
    "        adjacent_cluster_ids = [grid_cluster_ids[grid_locations_list.index(g)] for g in adjacent_locations if g in grid_locations_set]\n",
    "        \n",
    "#         print(location, adjacent_locations, cluster_id, adjacent_cluster_ids)\n",
    "        \n",
    "        for adjacent_cluster_id in adjacent_cluster_ids:\n",
    "            if adjacency_graph.has_edge(cluster_id, adjacent_cluster_id):\n",
    "                adjacency_graph[cluster_id][adjacent_cluster_id]['weight'] += 1\n",
    "            else:\n",
    "                adjacency_graph.add_edge(cluster_id, adjacent_cluster_id, weight=1)\n",
    "            adjacency_count += 1\n",
    "        \n",
    "    print('adjacency_count', adjacency_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = glob(\"dataset_100/train/*/*.jpg\")\n",
    "\n",
    "clusters = pickle.load(open(\"clusters.pkl\", \"rb\"))\n",
    "feature_extractor = VggFeatureExtractor()\n",
    "orb = cv2.ORB_create(nfeatures=100000, fastThreshold=7)\n",
    "\n",
    "adjacency_graph = nx.Graph()\n",
    "\n",
    "for i in range(len(image_files)):\n",
    "    add_image_adjacencies(image_files[i], clusters, feature_extractor, adjacency_graph, orb)\n",
    "\n",
    "nx.write_gpickle(adjacency_graph, \"adjacency_graph.gpickle\")\n",
    "    \n",
    "nx.draw(adjacency_graph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a graph containing overlapping communities\n",
    "Given a sequence of observations, find communities that likely generated sequence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
