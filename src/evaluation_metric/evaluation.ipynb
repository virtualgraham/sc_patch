{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import math\n",
    "import random \n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def rsetattr(obj, attr, val):\n",
    "    pre, _, post = attr.rpartition('.')\n",
    "    return setattr(rgetattr(obj, pre) if pre else obj, post, val)\n",
    "\n",
    "def rgetattr(obj, attr, *args):\n",
    "    def _getattr(obj, attr):\n",
    "        return getattr(obj, attr, *args)\n",
    "    return functools.reduce(_getattr, [obj] + attr.split('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Model for Evaluation\n",
    "##################################################\n",
    "\n",
    "class ShufflePatchEvalNet(nn.Module):\n",
    "  def __init__(self,aux_logits = False):\n",
    "\n",
    "      super(ShufflePatchEvalNet, self).__init__()\n",
    "\n",
    "      self.cnn = nn.Sequential(\n",
    "\n",
    "        nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(64), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        # nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "        # nn.BatchNorm2d(64), \n",
    "        # nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "        nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(128), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        # nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "        # nn.BatchNorm2d(128), \n",
    "        # nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "        nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(256), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(256), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "        nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "\n",
    "        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(512), \n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "      )\n",
    "    \n",
    "  def forward(self, patch):\n",
    "    return self.cnn(patch)\n",
    "\n",
    "\n",
    "# https://github.com/pratogab/batch-transforms/blob/master/batch_transforms.py\n",
    "\n",
    "class ToTensor:\n",
    "    \"\"\"Applies the :class:`~torchvision.transforms.ToTensor` transform to a batch of images.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.max = 255\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor of size (N, C, H, W) to be tensorized.\n",
    "        Returns:\n",
    "            Tensor: Tensorized Tensor.\n",
    "        \"\"\"\n",
    "        return tensor.float().div_(self.max)\n",
    "\n",
    "\n",
    "class Normalize:\n",
    "    \"\"\"Applies the :class:`~torchvision.transforms.Normalize` transform to a batch of images.\n",
    "    .. note::\n",
    "        This transform acts out of place by default, i.e., it does not mutate the input tensor.\n",
    "    Args:\n",
    "        mean (sequence): Sequence of means for each channel.\n",
    "        std (sequence): Sequence of standard deviations for each channel.\n",
    "        inplace(bool,optional): Bool to make this operation in-place.\n",
    "        dtype (torch.dtype,optional): The data type of tensors to which the transform will be applied.\n",
    "        device (torch.device,optional): The device of tensors to which the transform will be applied.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean, std, inplace=False, dtype=torch.float, device='cpu'):\n",
    "        self.mean = torch.as_tensor(mean, dtype=dtype, device=device)[None, :, None, None]\n",
    "        self.std = torch.as_tensor(std, dtype=dtype, device=device)[None, :, None, None]\n",
    "        self.inplace = inplace\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor of size (N, C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized Tensor.\n",
    "        \"\"\"\n",
    "        if not self.inplace:\n",
    "            tensor = tensor.clone()\n",
    "\n",
    "        tensor.sub_(self.mean).div_(self.std)\n",
    "        return tensor\n",
    "\n",
    "    \n",
    "class ShufflePatchFeatureExtractor():\n",
    "    def __init__(self, weights_path):\n",
    "        self.model = ShufflePatchEvalNet().to(device)\n",
    "        \n",
    "        print('Loading Weights...', weights_path)\n",
    "        checkpoint = torch.load(weights_path, map_location=torch.device(device))\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        self.transform_batch = transforms.Compose([\n",
    "            ToTensor(),\n",
    "            Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]\n",
    "        )\n",
    "               \n",
    "    # Numpy array of size (N, H, W, C)\n",
    "    def evalRGB(self, patches):\n",
    "        print('a', patches[0,0,0])\n",
    "        patches = torch.from_numpy(patches)\n",
    "        patches = patches.permute(0, 3, 1, 2)\n",
    "        patches = self.transform_batch(patches)\n",
    "        output = self.model(patches.to(device))\n",
    "        return output.cpu().detach().numpy()\n",
    "\n",
    "    # Numpy array of size (N, H, W, C)\n",
    "    def evalBGR(self, patches):\n",
    "        print('b', patches[0,0,0])\n",
    "        patches = patches[...,::-1].copy()\n",
    "        return self.evalRGB(patches)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Weights... /Users/racoon/Desktop/variation_2b_migrated_0135_0.001_1.4328_63.80.pt\n",
      "a [0 0 0]\n",
      "b [0 0 0]\n",
      "a [0 0 0]\n",
      "0.0\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True]\n",
      "[2.37595773e+00 1.71877980e+00 2.35975012e-02 0.00000000e+00\n",
      " 0.00000000e+00 2.45537114e+00 2.84083247e-01 2.16430378e+00\n",
      " 5.20011783e-01 9.68305767e-03 5.99690191e-02 1.27284276e+00\n",
      " 0.00000000e+00 9.14226592e-01 1.15859759e+00 2.11398149e+00\n",
      " 2.85282254e-01 9.64452684e-01 6.47424579e-01 1.79864168e-01\n",
      " 0.00000000e+00 0.00000000e+00 1.20435476e+00 2.34791017e+00\n",
      " 0.00000000e+00 3.37944269e+00 2.85390711e+00 9.16547298e-01\n",
      " 1.49001598e-01 1.58966756e+00 1.62729228e+00 5.24675958e-02\n",
      " 3.16684544e-02 1.17729820e-01 5.69267392e-01 9.20588076e-01\n",
      " 2.19051671e+00 9.19925928e-01 6.77128255e-01 0.00000000e+00\n",
      " 0.00000000e+00 1.09824204e+00 7.15979397e-01 6.36109561e-02\n",
      " 0.00000000e+00 5.99784017e-01 1.63349599e-01 2.02595830e+00\n",
      " 3.03596020e+00 8.81409824e-01 1.13546558e-01 1.58267117e+00\n",
      " 1.34885705e+00 4.33836520e-01 2.23812914e+00 5.66852510e-01\n",
      " 1.87466109e+00 1.78049552e+00 1.44924924e-01 0.00000000e+00\n",
      " 5.21955550e-01 1.26572824e+00 6.14734948e-01 0.00000000e+00\n",
      " 3.41678238e+00 4.34944212e-01 1.14040565e+00 3.37844849e-01\n",
      " 1.08476734e+00 2.06810760e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.67945421e+00 1.46088576e+00 9.34860706e-02\n",
      " 1.79116917e+00 7.05651119e-02 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 2.00817037e+00 1.65484488e+00 3.59681630e+00\n",
      " 2.29257643e-02 3.78880978e-01 3.71267796e-01 2.23341084e+00\n",
      " 0.00000000e+00 7.12166488e-01 3.76040220e-01 0.00000000e+00\n",
      " 4.75940228e-01 0.00000000e+00 1.73070240e+00 0.00000000e+00\n",
      " 1.85532737e+00 2.26917529e+00 1.09345937e+00 6.90318584e-01\n",
      " 2.58859587e+00 0.00000000e+00 0.00000000e+00 3.02611613e+00\n",
      " 1.67041868e-02 9.79867697e-01 8.44341338e-01 2.88469887e+00\n",
      " 0.00000000e+00 1.30943143e+00 0.00000000e+00 1.11013019e+00\n",
      " 1.14714354e-01 3.81296650e-02 3.34528351e+00 2.45678544e+00\n",
      " 1.16010773e+00 1.23537457e+00 0.00000000e+00 0.00000000e+00\n",
      " 5.29314518e-01 3.02254248e+00 8.40116143e-01 0.00000000e+00\n",
      " 1.29085159e+00 1.28575075e+00 8.64107907e-03 3.81206758e-02\n",
      " 3.70339811e-01 0.00000000e+00 0.00000000e+00 2.82005215e+00\n",
      " 0.00000000e+00 2.97292501e-01 2.36879259e-01 1.24978149e+00\n",
      " 1.80169865e-01 1.62427282e+00 0.00000000e+00 2.30036116e+00\n",
      " 1.35799241e+00 4.02218103e-01 6.31759286e-01 1.23365149e-02\n",
      " 0.00000000e+00 4.01502800e+00 0.00000000e+00 2.70991850e+00\n",
      " 2.32315660e-01 1.59886789e+00 2.02841759e+00 0.00000000e+00\n",
      " 2.36207604e+00 0.00000000e+00 4.20560062e-01 3.34519029e+00\n",
      " 0.00000000e+00 0.00000000e+00 3.16986322e+00 1.19521415e+00\n",
      " 1.13038078e-01 0.00000000e+00 6.87948018e-02 1.64068475e-01\n",
      " 0.00000000e+00 6.53340340e-01 1.74593043e+00 7.72411078e-02\n",
      " 8.53826553e-02 1.64871311e+00 1.67311907e+00 2.75336981e-01\n",
      " 3.03419456e-02 0.00000000e+00 7.03392327e-02 8.04805607e-02\n",
      " 1.80113578e+00 0.00000000e+00 1.90201044e+00 2.67989010e-01\n",
      " 9.42378193e-02 1.84273744e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.62269604e+00 1.60178706e-01 3.27957964e+00\n",
      " 0.00000000e+00 1.36943832e-01 0.00000000e+00 0.00000000e+00\n",
      " 2.98499656e+00 9.00920928e-02 1.31598210e+00 3.78230959e-03\n",
      " 9.82839391e-02 0.00000000e+00 1.01145156e-01 2.81130493e-01\n",
      " 1.93115354e+00 2.81033546e-01 2.46678934e-01 0.00000000e+00\n",
      " 2.03901982e+00 2.02887610e-01 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 2.93434215e+00 8.83776426e-01 0.00000000e+00\n",
      " 2.25331807e+00 2.83337188e+00 2.26263881e+00 9.34863627e-01\n",
      " 9.41555500e-01 3.25234950e-01 0.00000000e+00 6.90466523e-01\n",
      " 1.64989138e+00 1.13563502e+00 1.46722078e-01 3.09104383e-01\n",
      " 3.13749015e-01 2.02452707e+00 1.17307258e+00 2.28846335e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.43637693e+00 6.55160397e-02\n",
      " 1.25662637e+00 7.15495288e-01 0.00000000e+00 8.48857313e-02\n",
      " 0.00000000e+00 0.00000000e+00 1.46584487e+00 0.00000000e+00\n",
      " 6.84426427e-01 1.62013662e+00 2.78951377e-01 5.69128871e-01\n",
      " 2.54881620e+00 1.55291885e-01 0.00000000e+00 2.16452599e+00\n",
      " 0.00000000e+00 2.63075638e+00 4.70563024e-02 7.21690476e-01\n",
      " 1.60565302e-01 2.73629606e-01 1.42799592e+00 3.97617638e-01\n",
      " 2.31569552e+00 2.32516193e+00 2.18307829e+00 0.00000000e+00\n",
      " 0.00000000e+00 6.58643246e-02 5.43094516e-01 1.26044977e+00\n",
      " 4.32206392e-01 0.00000000e+00 0.00000000e+00 4.05657113e-01\n",
      " 1.49456525e+00 7.21709609e-01 0.00000000e+00 1.71593070e+00\n",
      " 5.16440943e-02 0.00000000e+00 9.72521901e-02 1.75727618e+00\n",
      " 5.64452291e-01 2.35540017e-01 9.67491031e-01 1.65941969e-01\n",
      " 1.89846551e+00 9.63980258e-02 0.00000000e+00 1.52680218e+00\n",
      " 0.00000000e+00 2.18019485e+00 5.26298821e-01 2.50982642e-02\n",
      " 0.00000000e+00 3.33023763e+00 2.45875239e+00 8.63299817e-02\n",
      " 2.72874162e-02 0.00000000e+00 9.04725790e-02 0.00000000e+00\n",
      " 1.52373612e+00 1.54845440e+00 4.14693713e-01 1.51546538e-01\n",
      " 0.00000000e+00 2.20481658e+00 2.58164215e+00 0.00000000e+00\n",
      " 1.43115652e+00 7.45376050e-01 1.50938720e-01 1.81294620e+00\n",
      " 1.92490888e+00 1.83763015e+00 9.53330874e-01 8.50498736e-01\n",
      " 0.00000000e+00 1.10434368e-01 0.00000000e+00 9.72210169e-01\n",
      " 1.67899656e+00 2.60775555e-02 6.85823560e-02 1.04017593e-02\n",
      " 3.41685653e-01 0.00000000e+00 1.91418779e+00 0.00000000e+00\n",
      " 6.21003434e-02 0.00000000e+00 4.56983924e-01 1.46828502e-01\n",
      " 1.56252086e-03 3.23349535e-01 1.41777062e+00 3.42519581e-01\n",
      " 1.65634584e+00 3.20922852e-01 3.84465218e-01 1.65613627e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.10857725e-01 1.96852013e-01\n",
      " 2.76780665e-01 1.36916602e+00 0.00000000e+00 5.56879282e-01\n",
      " 1.18297017e+00 0.00000000e+00 3.15397120e+00 0.00000000e+00\n",
      " 3.16887331e+00 0.00000000e+00 3.24126220e+00 1.68396699e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00911999e+00 0.00000000e+00\n",
      " 1.85145640e+00 1.24406397e+00 1.28608179e+00 8.38390946e-01\n",
      " 5.23395985e-02 3.70669305e-01 1.94367945e-01 0.00000000e+00\n",
      " 3.91961366e-01 0.00000000e+00 8.49041760e-01 0.00000000e+00\n",
      " 1.38973117e-01 1.94094944e+00 0.00000000e+00 4.25205529e-01\n",
      " 3.72188568e-01 3.29286718e+00 1.57959545e+00 1.03734708e+00\n",
      " 0.00000000e+00 3.32488477e-01 3.51020575e-01 2.94637609e+00\n",
      " 5.14783919e-01 1.01566717e-01 2.63831806e+00 0.00000000e+00\n",
      " 3.49807668e+00 1.59739339e+00 1.19038188e+00 2.29131150e+00\n",
      " 3.15281606e+00 2.53505230e-01 9.06984657e-02 2.57201290e+00\n",
      " 0.00000000e+00 6.27806932e-02 8.38755488e-01 0.00000000e+00\n",
      " 2.17999840e+00 1.23293251e-02 1.39317662e-02 7.30744749e-02\n",
      " 2.64607728e-01 0.00000000e+00 0.00000000e+00 1.02561820e+00\n",
      " 2.24099541e+00 2.79912114e-01 2.40076733e+00 1.43117392e+00\n",
      " 6.28605306e-01 3.79596382e-01 5.04957587e-02 4.07807156e-02\n",
      " 2.07006860e+00 1.79247141e-01 3.45970243e-02 5.88949680e-01\n",
      " 5.13132960e-02 1.20374210e-01 0.00000000e+00 2.61102414e+00\n",
      " 1.98655283e+00 9.29416001e-01 2.06145346e-02 1.12720215e+00\n",
      " 3.02943158e+00 3.75968277e-01 2.93649936e+00 9.74932194e-01\n",
      " 1.76518932e-02 0.00000000e+00 1.61308765e+00 1.70873773e+00\n",
      " 1.63178012e-01 1.80676579e+00 3.02908182e+00 2.33129993e-01\n",
      " 4.06526625e-01 7.97428071e-01 0.00000000e+00 2.13434148e+00\n",
      " 0.00000000e+00 3.53977537e+00 1.01059161e-01 0.00000000e+00\n",
      " 0.00000000e+00 1.43344104e+00 3.45811129e-01 4.68872964e-01\n",
      " 1.67078972e-01 2.83906102e+00 4.91493046e-02 3.57208538e+00\n",
      " 2.67059731e+00 1.14650762e+00 1.51386142e+00 1.71031728e-01\n",
      " 1.23577833e+00 5.15180379e-02 2.91116387e-01 8.22561905e-02\n",
      " 4.71038342e-01 1.51150063e-01 3.38708448e+00 1.81757259e+00\n",
      " 1.90507245e+00 6.10653281e-01 0.00000000e+00 0.00000000e+00\n",
      " 1.44002485e+00 0.00000000e+00 1.03849792e+00 2.70529962e+00\n",
      " 2.27502918e+00 1.83274269e-01 0.00000000e+00 3.48876685e-01\n",
      " 1.10466981e+00 0.00000000e+00 1.35906935e+00 2.98291802e+00\n",
      " 3.19752717e+00 0.00000000e+00 9.37019765e-01 7.21812367e-01\n",
      " 3.84386271e-01 2.31297053e-02 1.61880100e+00 0.00000000e+00\n",
      " 7.28093743e-01 1.81635571e+00 3.17217374e+00 2.98032904e+00\n",
      " 3.12126136e+00 0.00000000e+00 7.92825997e-01 0.00000000e+00\n",
      " 0.00000000e+00 9.46813643e-01 2.04178631e-01 3.57531428e-01\n",
      " 6.74969435e-01 0.00000000e+00 1.27170011e-02 1.52767074e+00\n",
      " 3.21433067e-01 1.59156919e-01 3.56048793e-02 1.42353034e+00\n",
      " 1.36290833e-01 3.64785647e+00 3.68823910e+00 3.46937752e+00]\n",
      "[2.37595773e+00 1.71877980e+00 2.35975012e-02 0.00000000e+00\n",
      " 0.00000000e+00 2.45537114e+00 2.84083247e-01 2.16430378e+00\n",
      " 5.20011783e-01 9.68305767e-03 5.99690191e-02 1.27284276e+00\n",
      " 0.00000000e+00 9.14226592e-01 1.15859759e+00 2.11398149e+00\n",
      " 2.85282254e-01 9.64452684e-01 6.47424579e-01 1.79864168e-01\n",
      " 0.00000000e+00 0.00000000e+00 1.20435476e+00 2.34791017e+00\n",
      " 0.00000000e+00 3.37944269e+00 2.85390711e+00 9.16547298e-01\n",
      " 1.49001598e-01 1.58966756e+00 1.62729228e+00 5.24675958e-02\n",
      " 3.16684544e-02 1.17729820e-01 5.69267392e-01 9.20588076e-01\n",
      " 2.19051671e+00 9.19925928e-01 6.77128255e-01 0.00000000e+00\n",
      " 0.00000000e+00 1.09824204e+00 7.15979397e-01 6.36109561e-02\n",
      " 0.00000000e+00 5.99784017e-01 1.63349599e-01 2.02595830e+00\n",
      " 3.03596020e+00 8.81409824e-01 1.13546558e-01 1.58267117e+00\n",
      " 1.34885705e+00 4.33836520e-01 2.23812914e+00 5.66852510e-01\n",
      " 1.87466109e+00 1.78049552e+00 1.44924924e-01 0.00000000e+00\n",
      " 5.21955550e-01 1.26572824e+00 6.14734948e-01 0.00000000e+00\n",
      " 3.41678238e+00 4.34944212e-01 1.14040565e+00 3.37844849e-01\n",
      " 1.08476734e+00 2.06810760e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.67945421e+00 1.46088576e+00 9.34860706e-02\n",
      " 1.79116917e+00 7.05651119e-02 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 2.00817037e+00 1.65484488e+00 3.59681630e+00\n",
      " 2.29257643e-02 3.78880978e-01 3.71267796e-01 2.23341084e+00\n",
      " 0.00000000e+00 7.12166488e-01 3.76040220e-01 0.00000000e+00\n",
      " 4.75940228e-01 0.00000000e+00 1.73070240e+00 0.00000000e+00\n",
      " 1.85532737e+00 2.26917529e+00 1.09345937e+00 6.90318584e-01\n",
      " 2.58859587e+00 0.00000000e+00 0.00000000e+00 3.02611613e+00\n",
      " 1.67041868e-02 9.79867697e-01 8.44341338e-01 2.88469887e+00\n",
      " 0.00000000e+00 1.30943143e+00 0.00000000e+00 1.11013019e+00\n",
      " 1.14714354e-01 3.81296650e-02 3.34528351e+00 2.45678544e+00\n",
      " 1.16010773e+00 1.23537457e+00 0.00000000e+00 0.00000000e+00\n",
      " 5.29314518e-01 3.02254248e+00 8.40116143e-01 0.00000000e+00\n",
      " 1.29085159e+00 1.28575075e+00 8.64107907e-03 3.81206758e-02\n",
      " 3.70339811e-01 0.00000000e+00 0.00000000e+00 2.82005215e+00\n",
      " 0.00000000e+00 2.97292501e-01 2.36879259e-01 1.24978149e+00\n",
      " 1.80169865e-01 1.62427282e+00 0.00000000e+00 2.30036116e+00\n",
      " 1.35799241e+00 4.02218103e-01 6.31759286e-01 1.23365149e-02\n",
      " 0.00000000e+00 4.01502800e+00 0.00000000e+00 2.70991850e+00\n",
      " 2.32315660e-01 1.59886789e+00 2.02841759e+00 0.00000000e+00\n",
      " 2.36207604e+00 0.00000000e+00 4.20560062e-01 3.34519029e+00\n",
      " 0.00000000e+00 0.00000000e+00 3.16986322e+00 1.19521415e+00\n",
      " 1.13038078e-01 0.00000000e+00 6.87948018e-02 1.64068475e-01\n",
      " 0.00000000e+00 6.53340340e-01 1.74593043e+00 7.72411078e-02\n",
      " 8.53826553e-02 1.64871311e+00 1.67311907e+00 2.75336981e-01\n",
      " 3.03419456e-02 0.00000000e+00 7.03392327e-02 8.04805607e-02\n",
      " 1.80113578e+00 0.00000000e+00 1.90201044e+00 2.67989010e-01\n",
      " 9.42378193e-02 1.84273744e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.62269604e+00 1.60178706e-01 3.27957964e+00\n",
      " 0.00000000e+00 1.36943832e-01 0.00000000e+00 0.00000000e+00\n",
      " 2.98499656e+00 9.00920928e-02 1.31598210e+00 3.78230959e-03\n",
      " 9.82839391e-02 0.00000000e+00 1.01145156e-01 2.81130493e-01\n",
      " 1.93115354e+00 2.81033546e-01 2.46678934e-01 0.00000000e+00\n",
      " 2.03901982e+00 2.02887610e-01 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 2.93434215e+00 8.83776426e-01 0.00000000e+00\n",
      " 2.25331807e+00 2.83337188e+00 2.26263881e+00 9.34863627e-01\n",
      " 9.41555500e-01 3.25234950e-01 0.00000000e+00 6.90466523e-01\n",
      " 1.64989138e+00 1.13563502e+00 1.46722078e-01 3.09104383e-01\n",
      " 3.13749015e-01 2.02452707e+00 1.17307258e+00 2.28846335e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.43637693e+00 6.55160397e-02\n",
      " 1.25662637e+00 7.15495288e-01 0.00000000e+00 8.48857313e-02\n",
      " 0.00000000e+00 0.00000000e+00 1.46584487e+00 0.00000000e+00\n",
      " 6.84426427e-01 1.62013662e+00 2.78951377e-01 5.69128871e-01\n",
      " 2.54881620e+00 1.55291885e-01 0.00000000e+00 2.16452599e+00\n",
      " 0.00000000e+00 2.63075638e+00 4.70563024e-02 7.21690476e-01\n",
      " 1.60565302e-01 2.73629606e-01 1.42799592e+00 3.97617638e-01\n",
      " 2.31569552e+00 2.32516193e+00 2.18307829e+00 0.00000000e+00\n",
      " 0.00000000e+00 6.58643246e-02 5.43094516e-01 1.26044977e+00\n",
      " 4.32206392e-01 0.00000000e+00 0.00000000e+00 4.05657113e-01\n",
      " 1.49456525e+00 7.21709609e-01 0.00000000e+00 1.71593070e+00\n",
      " 5.16440943e-02 0.00000000e+00 9.72521901e-02 1.75727618e+00\n",
      " 5.64452291e-01 2.35540017e-01 9.67491031e-01 1.65941969e-01\n",
      " 1.89846551e+00 9.63980258e-02 0.00000000e+00 1.52680218e+00\n",
      " 0.00000000e+00 2.18019485e+00 5.26298821e-01 2.50982642e-02\n",
      " 0.00000000e+00 3.33023763e+00 2.45875239e+00 8.63299817e-02\n",
      " 2.72874162e-02 0.00000000e+00 9.04725790e-02 0.00000000e+00\n",
      " 1.52373612e+00 1.54845440e+00 4.14693713e-01 1.51546538e-01\n",
      " 0.00000000e+00 2.20481658e+00 2.58164215e+00 0.00000000e+00\n",
      " 1.43115652e+00 7.45376050e-01 1.50938720e-01 1.81294620e+00\n",
      " 1.92490888e+00 1.83763015e+00 9.53330874e-01 8.50498736e-01\n",
      " 0.00000000e+00 1.10434368e-01 0.00000000e+00 9.72210169e-01\n",
      " 1.67899656e+00 2.60775555e-02 6.85823560e-02 1.04017593e-02\n",
      " 3.41685653e-01 0.00000000e+00 1.91418779e+00 0.00000000e+00\n",
      " 6.21003434e-02 0.00000000e+00 4.56983924e-01 1.46828502e-01\n",
      " 1.56252086e-03 3.23349535e-01 1.41777062e+00 3.42519581e-01\n",
      " 1.65634584e+00 3.20922852e-01 3.84465218e-01 1.65613627e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.10857725e-01 1.96852013e-01\n",
      " 2.76780665e-01 1.36916602e+00 0.00000000e+00 5.56879282e-01\n",
      " 1.18297017e+00 0.00000000e+00 3.15397120e+00 0.00000000e+00\n",
      " 3.16887331e+00 0.00000000e+00 3.24126220e+00 1.68396699e+00\n",
      " 0.00000000e+00 0.00000000e+00 1.00911999e+00 0.00000000e+00\n",
      " 1.85145640e+00 1.24406397e+00 1.28608179e+00 8.38390946e-01\n",
      " 5.23395985e-02 3.70669305e-01 1.94367945e-01 0.00000000e+00\n",
      " 3.91961366e-01 0.00000000e+00 8.49041760e-01 0.00000000e+00\n",
      " 1.38973117e-01 1.94094944e+00 0.00000000e+00 4.25205529e-01\n",
      " 3.72188568e-01 3.29286718e+00 1.57959545e+00 1.03734708e+00\n",
      " 0.00000000e+00 3.32488477e-01 3.51020575e-01 2.94637609e+00\n",
      " 5.14783919e-01 1.01566717e-01 2.63831806e+00 0.00000000e+00\n",
      " 3.49807668e+00 1.59739339e+00 1.19038188e+00 2.29131150e+00\n",
      " 3.15281606e+00 2.53505230e-01 9.06984657e-02 2.57201290e+00\n",
      " 0.00000000e+00 6.27806932e-02 8.38755488e-01 0.00000000e+00\n",
      " 2.17999840e+00 1.23293251e-02 1.39317662e-02 7.30744749e-02\n",
      " 2.64607728e-01 0.00000000e+00 0.00000000e+00 1.02561820e+00\n",
      " 2.24099541e+00 2.79912114e-01 2.40076733e+00 1.43117392e+00\n",
      " 6.28605306e-01 3.79596382e-01 5.04957587e-02 4.07807156e-02\n",
      " 2.07006860e+00 1.79247141e-01 3.45970243e-02 5.88949680e-01\n",
      " 5.13132960e-02 1.20374210e-01 0.00000000e+00 2.61102414e+00\n",
      " 1.98655283e+00 9.29416001e-01 2.06145346e-02 1.12720215e+00\n",
      " 3.02943158e+00 3.75968277e-01 2.93649936e+00 9.74932194e-01\n",
      " 1.76518932e-02 0.00000000e+00 1.61308765e+00 1.70873773e+00\n",
      " 1.63178012e-01 1.80676579e+00 3.02908182e+00 2.33129993e-01\n",
      " 4.06526625e-01 7.97428071e-01 0.00000000e+00 2.13434148e+00\n",
      " 0.00000000e+00 3.53977537e+00 1.01059161e-01 0.00000000e+00\n",
      " 0.00000000e+00 1.43344104e+00 3.45811129e-01 4.68872964e-01\n",
      " 1.67078972e-01 2.83906102e+00 4.91493046e-02 3.57208538e+00\n",
      " 2.67059731e+00 1.14650762e+00 1.51386142e+00 1.71031728e-01\n",
      " 1.23577833e+00 5.15180379e-02 2.91116387e-01 8.22561905e-02\n",
      " 4.71038342e-01 1.51150063e-01 3.38708448e+00 1.81757259e+00\n",
      " 1.90507245e+00 6.10653281e-01 0.00000000e+00 0.00000000e+00\n",
      " 1.44002485e+00 0.00000000e+00 1.03849792e+00 2.70529962e+00\n",
      " 2.27502918e+00 1.83274269e-01 0.00000000e+00 3.48876685e-01\n",
      " 1.10466981e+00 0.00000000e+00 1.35906935e+00 2.98291802e+00\n",
      " 3.19752717e+00 0.00000000e+00 9.37019765e-01 7.21812367e-01\n",
      " 3.84386271e-01 2.31297053e-02 1.61880100e+00 0.00000000e+00\n",
      " 7.28093743e-01 1.81635571e+00 3.17217374e+00 2.98032904e+00\n",
      " 3.12126136e+00 0.00000000e+00 7.92825997e-01 0.00000000e+00\n",
      " 0.00000000e+00 9.46813643e-01 2.04178631e-01 3.57531428e-01\n",
      " 6.74969435e-01 0.00000000e+00 1.27170011e-02 1.52767074e+00\n",
      " 3.21433067e-01 1.59156919e-01 3.56048793e-02 1.42353034e+00\n",
      " 1.36290833e-01 3.64785647e+00 3.68823910e+00 3.46937752e+00]\n"
     ]
    }
   ],
   "source": [
    "feat = ShufflePatchFeatureExtractor(\"/Users/racoon/Desktop/variation_2b_migrated_0135_0.001_1.4328_63.80.pt\")\n",
    "\n",
    "patch_dim = 32\n",
    "\n",
    "image_paths = glob('/Users/racoon/Downloads/open-images-sample/*.jpg')\n",
    "image_index = int(math.floor((len(image_paths) * random.random())))\n",
    "\n",
    "cv2_image = cv2.imread(image_paths[image_index])\n",
    "\n",
    "pil_image = Image.open(image_paths[image_index]).convert('RGB')\n",
    "pil_image = np.array(pil_image)\n",
    "\n",
    "\n",
    "y_coord = int(math.floor((pil_image.shape[0] - patch_dim) * random.random()))\n",
    "x_coord = int(math.floor((pil_image.shape[1] - patch_dim) * random.random()))\n",
    "\n",
    "\n",
    "cv2_patch = cv2_image[y_coord:y_coord+patch_dim, x_coord:x_coord+patch_dim]\n",
    "cv2_patchs = np.expand_dims(cv2_patch, axis=0)\n",
    "\n",
    "pil_patch = pil_image[y_coord:y_coord+patch_dim, x_coord:x_coord+patch_dim]\n",
    "pil_patchs = np.expand_dims(pil_patch, axis=0)\n",
    "\n",
    "\n",
    "f1 = feat.evalRGB(pil_patchs)\n",
    "f2 = feat.evalBGR(cv2_patchs)\n",
    "\n",
    "from scipy.spatial import distance\n",
    "print( distance.cosine(f1.reshape((512,)), f2.reshape((512,))))\n",
    "\n",
    "print(f1.reshape((512,)) == f2.reshape((512,)))\n",
    "print(f1.reshape((512,)))\n",
    "print(f2.reshape((512,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Checkpoint... /Users/racoon/Desktop/variation_2b_0135_0.001_1.4328_63.80.pt\n",
      "odict_keys(['cnn.0.weight', 'cnn.0.bias', 'cnn.1.weight', 'cnn.1.bias', 'cnn.1.running_mean', 'cnn.1.running_var', 'cnn.1.num_batches_tracked', 'cnn.4.weight', 'cnn.4.bias', 'cnn.5.weight', 'cnn.5.bias', 'cnn.5.running_mean', 'cnn.5.running_var', 'cnn.5.num_batches_tracked', 'cnn.8.weight', 'cnn.8.bias', 'cnn.9.weight', 'cnn.9.bias', 'cnn.9.running_mean', 'cnn.9.running_var', 'cnn.9.num_batches_tracked', 'cnn.11.weight', 'cnn.11.bias', 'cnn.12.weight', 'cnn.12.bias', 'cnn.12.running_mean', 'cnn.12.running_var', 'cnn.12.num_batches_tracked', 'cnn.15.weight', 'cnn.15.bias', 'cnn.16.weight', 'cnn.16.bias', 'cnn.16.running_mean', 'cnn.16.running_var', 'cnn.16.num_batches_tracked', 'cnn.18.weight', 'cnn.18.bias', 'cnn.19.weight', 'cnn.19.bias', 'cnn.19.running_mean', 'cnn.19.running_var', 'cnn.19.num_batches_tracked', 'cnn.22.weight', 'cnn.22.bias', 'cnn.23.weight', 'cnn.23.bias', 'cnn.23.running_mean', 'cnn.23.running_var', 'cnn.23.num_batches_tracked', 'cnn.25.weight', 'cnn.25.bias', 'cnn.26.weight', 'cnn.26.bias', 'cnn.26.running_mean', 'cnn.26.running_var', 'cnn.26.num_batches_tracked', 'fc6.0.weight', 'fc6.0.bias', 'fc.0.weight', 'fc.0.bias', 'fc.3.weight', 'fc.3.bias'])\n",
      "cnn.0.weight\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-dfdf3d8effd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cnn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mrgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel_save_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/Users/racoon/Desktop/variation_2b_migrated_0135_0.001_1.4328_63.80.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Migrate Model\n",
    "\n",
    "model_save_path = \"/Users/racoon/Desktop/variation_2b_0135_0.001_1.4328_63.80.pt\"\n",
    "\n",
    "print('Loading Checkpoint...', model_save_path)\n",
    "\n",
    "checkpoint = torch.load(model_save_path, map_location=torch.device(device))\n",
    "\n",
    "state_dict = checkpoint['model_state_dict']\n",
    "print(state_dict.keys())\n",
    "\n",
    "with torch.no_grad():\n",
    "    for k in state_dict.keys():\n",
    "        if k.startswith('cnn.'):\n",
    "            print(k)\n",
    "            rgetattr(model, k).copy_(state_dict[k])\n",
    "\n",
    "model_save_path = \"/Users/racoon/Desktop/variation_2b_migrated_0135_0.001_1.4328_63.80.pt\"\n",
    "\n",
    "torch.save(\n",
    "{\n",
    "    'model_state_dict': model.state_dict(),\n",
    "}, model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Checkpoint... /Users/racoon/Desktop/variation_2b_migrated_0135_0.001_1.4328_63.80.pt\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-d7f1bf40eed2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading Checkpoint...'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_save_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Load Migrated Model\n",
    "model_save_path = \"/Users/racoon/Desktop/variation_2b_migrated_0135_0.001_1.4328_63.80.pt\"\n",
    "print('Loading Checkpoint...', model_save_path)\n",
    "checkpoint = torch.load(model_save_path, map_location=torch.device(device))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_dim = 32\n",
    "validation_image_paths = glob('/Users/racoon/Downloads/open-images-sample/*.jpg')\n",
    "reuse_image_count = 0\n",
    "\n",
    "class ShufflePatchDataset(Dataset):\n",
    "\n",
    "  def __init__(self, image_paths, patch_dim, length, transform=None):\n",
    "    self.image_paths = image_paths\n",
    "    self.patch_dim = patch_dim\n",
    "    self.length = length\n",
    "    self.transform = transform\n",
    "    self.image_reused = 0\n",
    "    self.min_width = self.patch_dim\n",
    "    \n",
    "  def __len__(self):\n",
    "    return self.length\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    # [y, x, chan], dtype=uint8, top_left is (0,0)\n",
    "    \n",
    "    image_index = int(math.floor((len(self.image_paths) * random.random())))\n",
    "    \n",
    "    if self.image_reused == 0:\n",
    "      pil_image = Image.open(self.image_paths[image_index]).convert('RGB')\n",
    "      self.pil_image = pil_image.resize((int(round(pil_image.size[0]/3)), int(round(pil_image.size[1]/3))))\n",
    "      self.image_reused = reuse_image_count\n",
    "    else:\n",
    "      self.image_reused -= 1\n",
    "\n",
    "    image = np.array(self.pil_image)\n",
    "\n",
    "    # If image is too small, try another image\n",
    "    if (image.shape[0] - self.min_width) <= 0 or (image.shape[1] - self.min_width) <= 0:\n",
    "        return self.__getitem__(index)\n",
    "    \n",
    "    y_coord = int(math.floor((image.shape[0] - self.patch_dim) * random.random()))\n",
    "    x_coord = int(math.floor((image.shape[1] - self.patch_dim) * random.random()))\n",
    "\n",
    "    patch = image[y_coord:y_coord+self.patch_dim, x_coord:x_coord+self.patch_dim]\n",
    "\n",
    "    if self.transform:\n",
    "      patch = self.transform(patch)\n",
    "\n",
    "    return patch\n",
    "\n",
    "\n",
    "valdataset = ShufflePatchDataset(validation_image_paths, patch_dim, 1,\n",
    "                         transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(valdataset,\n",
    "                                        batch_size=1,\n",
    "                                        num_workers=0,\n",
    "                                        shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-f5ea4d85f775>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mimg0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "feat.model.eval()\n",
    "\n",
    "preprocess_input =  transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "data = next(iter(valloader))\n",
    "\n",
    "\n",
    "img0 = data.to(device)\n",
    "output = feat.model(img0)\n",
    "output = output.cpu().detach().numpy()\n",
    "print(output.shape)\n",
    "output = output.reshape((512,))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
