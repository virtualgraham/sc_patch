{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import random\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import ipyplot\n",
    "from PIL import Image\n",
    "from sklearn.cluster import KMeans\n",
    "from itertools import compress\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import ipyplot\n",
    "import gensim\n",
    "from ast import literal_eval\n",
    "\n",
    "# from ShufflePatchModel16 import ShufflePatchFeatureExtractor\n",
    "# from VggFeatureExtractor import VggFeatureExtractor\n",
    "from MoCoFeatureExtractor import MoCoFeatureExtractor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters and Utility methods for extracting patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 288\n",
    "stride = 144\n",
    "kp_margin = 16 # keypoint detector has a margin around image where it can not find keypoints\n",
    "\n",
    "n_clusters = 100\n",
    "word_format_string = '{:02d}'\n",
    "\n",
    "walk_length = 10\n",
    "walks_per_image = 100\n",
    "\n",
    "cluster_patches_per_image = 24\n",
    "\n",
    "image_scale = 1\n",
    "\n",
    "feature_dim = 2048\n",
    "\n",
    "cluster_file = f'clusters_{window_size}_{stride}_{n_clusters}.pkl'\n",
    "image_cluster_grid_file = f'image_cluster_grids_{window_size}_{stride}_{n_clusters}.npy'\n",
    "sequences_file = f'sequences_{window_size}_{stride}_{n_clusters}.csv'\n",
    "doc2vec_file = f'doc2vec_{window_size}_{stride}_{n_clusters}.model'\n",
    "\n",
    "cnn = MoCoFeatureExtractor(params_path='/home/ubuntu/moco_v2_800ep_pretrain.pth.tar')\n",
    "\n",
    "image_files = glob(\"/home/ubuntu/dataset_1000/train/*/*.jpg\")\n",
    "\n",
    "image_id_to_class = dict([(f.split('/')[-1].split('.')[0], f.split('/')[-2]) for f in image_files])\n",
    "\n",
    "def extract_windows(frame, pos, window_size):\n",
    "    windows = np.empty((len(pos), window_size, window_size, 3), dtype=np.uint8)\n",
    "\n",
    "    for i in range(len(pos)):\n",
    "        windows[i] = extract_window(frame, pos[i], window_size)\n",
    "\n",
    "    return windows\n",
    "\n",
    "\n",
    "def extract_window(frame, pos, window_size):\n",
    "    half_w = window_size/2.0\n",
    "\n",
    "    top_left = [int(round(pos[0]-half_w)), int(round(pos[1]-half_w))]\n",
    "    bottom_right = [top_left[0]+window_size, top_left[1]+window_size]\n",
    "\n",
    "    return frame[top_left[0]:bottom_right[0], top_left[1]:bottom_right[1]]\n",
    "\n",
    "\n",
    "\n",
    "def get_rad_grid(grid_pos, rad, grid_shape):\n",
    "\n",
    "    top_left = (grid_pos[0]-rad, grid_pos[1]-rad)\n",
    "\n",
    "    res = []\n",
    "\n",
    "    for i in range(2*rad+1):\n",
    "        p = (top_left[0]+i, top_left[1])\n",
    "        if p[0] >= 0 and p[1] >= 0 and p[0] < grid_shape[0] and p[1] < grid_shape[1]:\n",
    "            res.append(p)\n",
    " \n",
    "    for i in range(2*rad+1):\n",
    "        p = (top_left[0]+i, top_left[1]+(2*rad))\n",
    "        if p[0] >= 0 and p[1] >= 0 and p[0] < grid_shape[0] and p[1] < grid_shape[1]:\n",
    "            res.append(p)\n",
    "\n",
    "    for i in range(2*rad-1):\n",
    "        p = (top_left[0], top_left[1]+(i+1))\n",
    "        if p[0] >= 0 and p[1] >= 0 and p[0] < grid_shape[0] and p[1] < grid_shape[1]:\n",
    "            res.append(p)\n",
    "\n",
    "    for i in range(2*rad-1):\n",
    "        p = (top_left[0]+(2*rad), top_left[1]+(i+1))\n",
    "        if p[0] >= 0 and p[1] >= 0 and p[0] < grid_shape[0] and p[1] < grid_shape[1]:\n",
    "            res.append(p)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def next_pos(salient_grid_positions, grid_shape, current_position):\n",
    "    \n",
    "    if current_position is not None:\n",
    "\n",
    "        rad_grid = get_rad_grid(current_position, 1, grid_shape)\n",
    "\n",
    "        # print('rad_grid', current_position, rad_grid)\n",
    "        \n",
    "        if len(rad_grid) == 0:\n",
    "            print(\"frame empty?\")\n",
    "            \n",
    "        else:\n",
    "            random.shuffle(rad_grid)\n",
    "            for loc in rad_grid:\n",
    "                if loc in salient_grid_positions:\n",
    "                    return loc\n",
    "    \n",
    "    return random.sample(salient_grid_positions,1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample and cluster patches\n",
    "This simply uses a fixed grid system. Future patch sampling methods could incorporate an intrest point detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 12602/15537 [30:46<07:08,  6.84it/s]"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "\n",
    "\n",
    "for idx, image_file in tqdm(enumerate(image_files), total=len(image_files)):\n",
    "\n",
    "    pil_image = Image.open(image_file).convert('RGB')\n",
    "    pil_image = pil_image.resize((int(round(pil_image.size[0] * image_scale)), int(round(pil_image.size[1] * image_scale))))\n",
    "    image = np.array(pil_image)\n",
    "\n",
    "    if image.shape[0] < window_size * 2 or image.shape[1] < window_size * 2:\n",
    "        continue\n",
    "\n",
    "    margin = max(window_size-stride, kp_margin*2)\n",
    "    grid_shape = (math.floor((image.shape[0] - margin) / stride), math.floor((image.shape[1] - margin) / stride))\n",
    "    offsets = (round((image.shape[0] - grid_shape[0] * stride)/2), round((image.shape[1] - grid_shape[1] * stride)/2))\n",
    "\n",
    "    points = [(offsets[0]+y*stride+stride/2,offsets[1]+x*stride+stride/2) for y in range(grid_shape[0]) for x in range(grid_shape[1])]\n",
    "\n",
    "    if len(points) > cluster_patches_per_image:\n",
    "        points = random.sample(points, cluster_patches_per_image)\n",
    "\n",
    "    patches = extract_windows(image, points, window_size)\n",
    "\n",
    "    windows = patches.astype(np.float64)\n",
    "\n",
    "    try:\n",
    "        feats = cnn.evalRGB(windows)\n",
    "    except:\n",
    "        print(\"ERROR windows.shape\", windows.shape)\n",
    "        raise\n",
    "\n",
    "    feats = feats.reshape((windows.shape[0], feature_dim))\n",
    "    X.extend(list(feats))\n",
    "\n",
    "\n",
    "print(\"Clustering with KMeans: len(X)\", len(X))\n",
    "\n",
    "clusters = KMeans(n_clusters=n_clusters, verbose=False)\n",
    "clusters.fit(np.array(X, dtype=np.float32))\n",
    "\n",
    "pickle.dump(clusters, open(cluster_file, \"wb\"))\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate sequence dataset with random walks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid_locations(grid_shape, stride, offsets, mask=None):\n",
    "    \n",
    "    if mask is not None:\n",
    "        object_grid_locations = set()\n",
    "\n",
    "        for y in range(grid_shape[0]):\n",
    "            for x in range(grid_shape[1]):\n",
    "                p = (offsets[0] + y * stride + 0.5 * stride, offsets[1] + x * stride + 0.5 * stride)\n",
    "                w = extract_window(mask, p, stride)\n",
    "\n",
    "                if np.sum(w) >= stride * stride * 0.3:\n",
    "                    object_grid_locations.add((y, x))\n",
    "        \n",
    "        return object_grid_locations\n",
    "    \n",
    "    else:\n",
    "        return [(y,x) for y in range(grid_shape[0]) for x in range(grid_shape[1])]\n",
    "    \n",
    "def generate_image_cluster_grid(image_file, image_scale, clusters, feature_extractor):\n",
    "    # print(\"generate_image_sequences\", image_file)\n",
    "\n",
    "    pil_image = Image.open(image_file).convert('RGB')\n",
    "    pil_image = pil_image.resize((int(round(pil_image.size[0] * image_scale)), int(round(pil_image.size[1] * image_scale))))\n",
    "    image = np.array(pil_image)\n",
    "\n",
    "    if image.shape[0] < window_size * 2 or image.shape[1] < window_size * 2:\n",
    "        print(\"image too small, image_file\")\n",
    "        return None\n",
    "            \n",
    "    margin = max(window_size, kp_margin*2)\n",
    "    grid_shape = (math.floor((image.shape[0] - margin) / stride), math.floor((image.shape[1] - margin) / stride))\n",
    "    offsets = (round((image.shape[0] - grid_shape[0] * stride)/2), round((image.shape[1] - grid_shape[1] * stride)/2))\n",
    "\n",
    "    grid_locations_set = get_grid_locations(grid_shape, stride, offsets)\n",
    "    grid_locations_list = list(grid_locations_set)\n",
    "    \n",
    "    points = [(y*stride + stride/2 + offsets[0], x*stride + stride/2 + offsets[1]) for (y,x) in grid_locations_list]\n",
    "        \n",
    "    patches = extract_windows(image, points, window_size)\n",
    "    windows = patches.astype(np.float64)\n",
    "\n",
    "    # print(windows.shape)\n",
    "    \n",
    "    feats = cnn.evalRGB(windows)\n",
    "    feats = feats.reshape((windows.shape[0], feature_dim))\n",
    "\n",
    "    grid_cluster_ids = clusters.predict(feats)\n",
    "        \n",
    "    cluster_grid = np.full(grid_shape, -1, dtype=int)\n",
    "    \n",
    "    for i in range(len(grid_locations_list)):\n",
    "        cluster_grid[grid_locations_list[i]] = grid_cluster_ids[i]\n",
    "        \n",
    "    return cluster_grid\n",
    "\n",
    "def generate_image_sequences(image_cluster_grid, seq_count=walks_per_image):\n",
    "\n",
    "    cluster_seqs = []\n",
    "    \n",
    "    grid_locations_set = set([(y,x) for y in range(image_cluster_grid.shape[0]) for x in range(image_cluster_grid.shape[1])])\n",
    "    \n",
    "    for i in range(seq_count):\n",
    "        cluster_seq = []\n",
    "\n",
    "        pos = None\n",
    "        \n",
    "        for t in range(walk_length):\n",
    "            pos = next_pos(grid_locations_set, image_cluster_grid.shape, pos)\n",
    "            cluster_seq.append(image_cluster_grid[pos])\n",
    "            \n",
    "        cluster_seqs.append([word_format_string.format(w) for w in cluster_seq])\n",
    "        \n",
    "    return cluster_seqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_locations(mask, stride, grid_shape, offsets):\n",
    "    \n",
    "    object_grid_locations = set()\n",
    "\n",
    "    for y in range(grid_shape[0]):\n",
    "        for x in range(grid_shape[1]):\n",
    "            p = (offsets[0] + y * stride + 0.5 * stride, offsets[1] + x * stride + 0.5 * stride)\n",
    "            w = extract_window(mask, p, stride)\n",
    "\n",
    "            # print(np.sum(w))\n",
    "            if np.sum(w) >= stride * stride * 0.3:\n",
    "                object_grid_locations.add((y, x))\n",
    "\n",
    "    return object_grid_locations\n",
    "\n",
    "     \n",
    "    \n",
    "\n",
    "def generate_masked_image_sequences(image_file, mask_file, clusters, feature_extractor, seq_count=walks_per_image):\n",
    "\n",
    "    pil_image = Image.open(image_file).convert('RGB')\n",
    "    pil_image = pil_image.resize((int(round(pil_image.size[0] * image_scale)), int(round(pil_image.size[1] * image_scale))))\n",
    "    image = np.array(pil_image)\n",
    "\n",
    "    if image.shape[0] < window_size * 2 or image.shape[1] < window_size * 2:\n",
    "        print(\"image too small, image_file\")\n",
    "        return None\n",
    "            \n",
    "    pil_mask = Image.open(mask_file).convert('1')\n",
    "    pil_mask = pil_mask.resize((int(round(pil_mask.size[0] * image_scale)), int(round(pil_mask.size[1] * image_scale))))\n",
    "    mask = np.array(pil_mask)\n",
    "        \n",
    "    margin = max(window_size, kp_margin*2)\n",
    "    grid_shape = (math.floor((image.shape[0] - margin) / stride), math.floor((image.shape[1] - margin) / stride))\n",
    "    offsets = (round((image.shape[0] - grid_shape[0] * stride)/2), round((image.shape[1] - grid_shape[1] * stride)/2))\n",
    "\n",
    "    grid_locations_set = mask_locations(mask, stride, grid_shape, offsets)\n",
    "    grid_locations_list = list(grid_locations_set)\n",
    "    \n",
    "    points = [(y*stride + stride/2 + offsets[0], x*stride + stride/2 + offsets[1]) for (y,x) in grid_locations_list]\n",
    "        \n",
    "    patches = extract_windows(image, points, window_size)\n",
    "    windows = patches.astype(np.float64)\n",
    "\n",
    "    feats = cnn.evalRGB(windows)\n",
    "    feats = feats.reshape((windows.shape[0], feature_dim))\n",
    "\n",
    "    grid_cluster_ids = clusters.predict(feats)\n",
    "    grid_location_to_cluster_id = dict([(grid_locations_list[i], grid_cluster_ids[i]) for i in range(len(grid_locations_list))])\n",
    "          \n",
    "    cluster_seqs = []\n",
    "    for i in range(seq_count):\n",
    "        cluster_seq = []\n",
    "        \n",
    "        pos = None\n",
    "        \n",
    "        for t in range(walk_length):\n",
    "            pos = next_pos(grid_locations_set, grid_shape, pos)\n",
    "            cluster_seq.append(grid_location_to_cluster_id[pos])\n",
    "            \n",
    "        cluster_seqs.append([word_format_string.format(w) for w in cluster_seq])\n",
    "  \n",
    "    return cluster_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15537/15537 [37:34<00:00,  6.89it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "clusters = pickle.load(open(cluster_file, \"rb\"))\n",
    "\n",
    "image_cluster_grids = {}\n",
    "\n",
    "for idx, image_file in tqdm(enumerate(image_files), total=len(image_files)):\n",
    "\n",
    "    image_cluster_grid = generate_image_cluster_grid(image_file, image_scale, clusters, cnn)\n",
    "    if image_cluster_grid is None:\n",
    "        continue\n",
    "    image_id = image_file.split('/')[-1].split('.')[0]\n",
    "    image_cluster_grids[image_id] = image_cluster_grid    \n",
    "    \n",
    "np.save(image_cluster_grid_file, image_cluster_grids)   \n",
    "\n",
    "print(\"done\")\n",
    "# print(np.load(image_cluster_grid_file, allow_pickle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15530/15530 [02:33<00:00, 101.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "clusters = pickle.load(open(cluster_file, \"rb\"))\n",
    "image_cluster_grids = np.load(image_cluster_grid_file, allow_pickle=True).item()\n",
    "\n",
    "cluster_seqs = []\n",
    "image_file_colummn = []\n",
    "\n",
    "image_files = list(image_cluster_grids.keys())\n",
    "\n",
    "for idx, image_file in tqdm(enumerate(image_files), total=len(image_files)):\n",
    "    c_seqs = generate_image_sequences(image_cluster_grids[image_file])\n",
    "    if c_seqs is None:\n",
    "        continue\n",
    "    cluster_seqs.extend(c_seqs)\n",
    "    image_file_colummn.extend([image_file] * walks_per_image)\n",
    "\n",
    "data_frame = pd.DataFrame({'words':cluster_seqs, 'file':image_file_colummn})\n",
    "\n",
    "data_frame.to_csv(sequences_file)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TaggedDocument(words=['687', '202', '286', '091', '286', '091', '091', '091', '837', '837'], tags=[0]), TaggedDocument(words=['091', '806', '806', '806', '286', '286', '286', '806', '266', '687'], tags=[1])]\n",
      "epoch 0\n",
      "epoch 1\n",
      "epoch 2\n",
      "epoch 3\n",
      "epoch 4\n",
      "epoch 5\n",
      "epoch 6\n",
      "epoch 7\n",
      "epoch 8\n",
      "epoch 9\n",
      "epoch 10\n",
      "epoch 11\n",
      "epoch 12\n",
      "epoch 13\n",
      "epoch 14\n",
      "epoch 15\n",
      "epoch 16\n",
      "epoch 17\n",
      "epoch 18\n",
      "epoch 19\n",
      "epoch 20\n",
      "epoch 21\n",
      "epoch 22\n",
      "epoch 23\n",
      "epoch 24\n",
      "epoch 25\n",
      "epoch 26\n",
      "epoch 27\n",
      "epoch 28\n",
      "epoch 29\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "class callback(gensim.models.callbacks.CallbackAny2Vec):\n",
    "    '''Callback to print loss after each epoch.'''\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        print('epoch {}'.format(self.epoch))\n",
    "        self.epoch += 1\n",
    "              \n",
    "def read_corpus(fname, tokens_only=False):\n",
    "    data_frame = pd.read_csv(sequences_file,converters={\"words\": literal_eval})\n",
    "    \n",
    "    for index, row in data_frame.iterrows():\n",
    "        if tokens_only:\n",
    "            yield row['words']\n",
    "        else:\n",
    "            yield gensim.models.doc2vec.TaggedDocument(row['words'], [index])\n",
    "\n",
    "train_corpus = list(read_corpus(sequences_file))\n",
    "print(train_corpus[:2])\n",
    "\n",
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=256, epochs=30)\n",
    "model.build_vocab(train_corpus)\n",
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs, callbacks=[callback()])\n",
    "\n",
    "model.save(doc2vec_file)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dataset_100/test/airplane/35b11a04c24db20c.jpg\n",
      "score 0.73\n",
      "test dataset_100/test/airplane/4ad0f079b979be5d.jpg\n",
      "score 0.291\n",
      "test dataset_100/test/airplane/839ce813ca97084c.jpg\n",
      "score 0.386\n",
      "test dataset_100/test/airplane/93b5bf58149adefd.jpg\n",
      "score 0.909\n",
      "test dataset_100/test/airplane/9dc879c35a26d2d3.jpg\n",
      "score 0.721\n",
      "test dataset_100/test/airplane/a48f1d15812036fa.jpg\n",
      "score 0.297\n",
      "test dataset_100/test/airplane/b6ac22d7db1769ee.jpg\n",
      "score 0.355\n",
      "test dataset_100/test/airplane/d5422871fd63b8b8.jpg\n",
      "score 0.837\n",
      "test dataset_100/test/airplane/e95bc413d4b748ba.jpg\n",
      "score 0.323\n",
      "test dataset_100/test/airplane/fbe835c5944f93e5.jpg\n",
      "score 0.293\n",
      "test dataset_100/test/car/455c29cd8db5b225.jpg\n",
      "score 0.24\n",
      "test dataset_100/test/car/56d1d8aca15ae219.jpg\n",
      "score 0.413\n",
      "test dataset_100/test/car/89297009b1d18663.jpg\n",
      "score 0.364\n",
      "test dataset_100/test/car/9bac3f90244fef7e.jpg\n",
      "score 0.271\n",
      "test dataset_100/test/car/a051a80f600fd919.jpg\n",
      "score 0.373\n",
      "test dataset_100/test/car/b30bc1fe86057942.jpg\n",
      "score 0.33\n",
      "test dataset_100/test/car/cc0c6a5753fbe006.jpg\n",
      "score 0.406\n",
      "test dataset_100/test/car/cdbfe2973b6fdaf2.jpg\n",
      "score 0.22\n",
      "test dataset_100/test/car/d12414ad4d3e845e.jpg\n",
      "score 0.234\n",
      "test dataset_100/test/car/d16cb785f98e3d1c.jpg\n",
      "score 0.265\n",
      "test dataset_100/test/horse/167af8f2bde5db07.jpg\n",
      "score 0.191\n",
      "test dataset_100/test/horse/18e5dbb67158438c.jpg\n",
      "score 0.143\n",
      "test dataset_100/test/horse/405bd80086a4588d.jpg\n",
      "score 0.23\n",
      "test dataset_100/test/horse/406512ee7efc2b43.jpg\n",
      "score 0.35\n",
      "test dataset_100/test/horse/51ae02f6c585c444.jpg\n",
      "score 0.175\n",
      "test dataset_100/test/horse/6b243472d75334b0.jpg\n",
      "score 0.228\n",
      "test dataset_100/test/horse/865610e59aaa728f.jpg\n",
      "score 0.286\n",
      "test dataset_100/test/horse/9b88ca5d575fc632.jpg\n",
      "score 0.302\n",
      "test dataset_100/test/horse/b171e2886317f12d.jpg\n",
      "score 0.182\n",
      "test dataset_100/test/horse/f3cb2620040852c4.jpg\n",
      "score 0.32\n",
      "final score 0.3555\n"
     ]
    }
   ],
   "source": [
    "clusters = pickle.load(open(cluster_file, \"rb\"))\n",
    "model = gensim.models.doc2vec.Doc2Vec.load(doc2vec_file)\n",
    "\n",
    "data_frame = pd.read_csv(sequences_file, converters={\"words\": literal_eval})\n",
    "\n",
    "test_image_files = glob(\"dataset_100/test/*/*.jpg\")\n",
    "test_mask_files = glob(\"dataset_100/test/*/*.mask.png\")\n",
    "\n",
    "test_image_files.sort()\n",
    "test_mask_files.sort()\n",
    "\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for i in range(len(test_image_files)):\n",
    "    \n",
    "    image_correct = 0\n",
    "    image_total = 0\n",
    "    \n",
    "    image_file = test_image_files[i]\n",
    "    mask_file = test_mask_files[i]\n",
    "\n",
    "    print(\"test\", image_file)\n",
    "\n",
    "    c_seqs = generate_masked_image_sequences(image_file, mask_file, clusters, cnn, seq_count=100)\n",
    "\n",
    "    if c_seqs is None:\n",
    "        continue\n",
    "        \n",
    "    vectors = [[model.infer_vector(s)] for s in c_seqs]\n",
    "\n",
    "    for v in vectors:\n",
    "        similar = model.docvecs.most_similar(v, topn=10)\n",
    "        #print('similar', similar)\n",
    "\n",
    "        for s in similar:\n",
    "            f = data_frame.loc[s[0],'file']\n",
    "            \n",
    "            a = image_file.split('/')[-2]\n",
    "            b = image_id_to_class[f]\n",
    "           \n",
    "            if a == b:\n",
    "                image_correct += 1\n",
    "                correct += 1\n",
    "           \n",
    "            image_total += 1\n",
    "            total += 1\n",
    "            \n",
    "    print(\"score\", image_correct/image_total)\n",
    "    \n",
    "print(\"final score\", correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
