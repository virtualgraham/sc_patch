{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hnswlib\n",
    "from PIL import Image\n",
    "from MoCoFeatureExtractor import MoCoFeatureExtractor\n",
    "from glob import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import ipyplot\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters and Utility methods for extracting patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'e'\n",
    "\n",
    "window_size = 224\n",
    "image_sizes = [224, 448, 672]\n",
    "stride = 112\n",
    "feature_dim = 2048\n",
    "\n",
    "# cnn = ResNetFeatureExtractor()\n",
    "cnn = MoCoFeatureExtractor(params_path='/Users/racoon/Desktop/moco_v2_800ep_pretrain.pth.tar')\n",
    "image_files = glob(\"dataset_1000/train/*/*.jpg\")\n",
    "\n",
    "\n",
    "def extract_windows(frame, pos, window_size):\n",
    "    windows = np.empty((len(pos), window_size, window_size, 3), dtype=np.uint8)\n",
    "\n",
    "    for i in range(len(pos)):\n",
    "        windows[i] = extract_window(frame, pos[i], window_size)\n",
    "\n",
    "    return windows\n",
    "\n",
    "\n",
    "def extract_window(frame, pos, window_size):\n",
    "    half_w = window_size/2.0\n",
    "\n",
    "    top_left = [int(round(pos[0]-half_w)), int(round(pos[1]-half_w))]\n",
    "    bottom_right = [top_left[0]+window_size, top_left[1]+window_size]\n",
    "\n",
    "    return frame[top_left[0]:bottom_right[0], top_left[1]:bottom_right[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features from each image for each image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, image_file in tqdm(enumerate(image_files), total=len(image_files)):\n",
    "    \n",
    "    pil_image = Image.open(image_file).convert('RGB')\n",
    "    \n",
    "    image_grids = {}\n",
    "    \n",
    "    for image_size in image_sizes:\n",
    "        if pil_image.size[1] > pil_image.size[0]:\n",
    "            resized_image = pil_image.resize((image_size, int(round(pil_image.size[1]/pil_image.size[0] * image_size))))\n",
    "        else:\n",
    "            resized_image = pil_image.resize((int(round(pil_image.size[0]/pil_image.size[1] * image_size)), image_size))\n",
    "        \n",
    "        image = np.array(resized_image)\n",
    "        \n",
    "        margin = window_size-stride\n",
    "        grid_shape = (math.floor((image.shape[0] - margin) / stride), math.floor((image.shape[1] - margin) / stride))\n",
    "        offsets = (round((image.shape[0] - grid_shape[0] * stride)/2), round((image.shape[1] - grid_shape[1] * stride)/2))\n",
    "\n",
    "        points = [(offsets[0]+y*stride+stride/2,offsets[1]+x*stride+stride/2) for y in range(grid_shape[0]) for x in range(grid_shape[1])]\n",
    "        \n",
    "        patches = extract_windows(image, points, window_size)\n",
    "        windows = patches.astype(np.float64)\n",
    "\n",
    "        try:\n",
    "            feats = cnn.evalRGB(windows)\n",
    "        except:\n",
    "            print(\"ERROR cnn.evalRGB\", image_file, image.shape, windows.shape)\n",
    "            raise\n",
    "\n",
    "        feat_grid = feats.reshape((grid_shape[0], grid_shape[1], feature_dim))\n",
    "        \n",
    "        image_grids[str(image_size)] = feat_grid\n",
    "    \n",
    "    path_parts = image_file.split('/')\n",
    "    image_id = path_parts[-1].split('.')[0]\n",
    "    image_class = path_parts[-2]\n",
    "\n",
    "    pathlib.Path(f'feat_grids_{window_size}_{stride}_{version}/{image_class}').mkdir(parents=True, exist_ok=True)\n",
    "    np.savez_compressed(f'feat_grids_{window_size}_{stride}_{version}/{image_class}/{image_id}.npz', **image_grids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create nn index of all features from training images of a given size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "\n",
    "npz_files = glob(f'/Users/racoon/Desktop/feat_grids_{window_size}_{stride}_{version}/*/*.npz')\n",
    "\n",
    "index = hnswlib.Index(space='cosine', dim=2048) \n",
    "index.init_index(max_elements=1000000, ef_construction=300 * 2, M=64)\n",
    "index.set_ef(300)\n",
    "\n",
    "id = 0\n",
    "\n",
    "patch_dict = {}\n",
    "\n",
    "for idx, npz_file in tqdm(enumerate(npz_files), total=len(npz_files)):\n",
    "    \n",
    "    loaded = np.load(npz_file)\n",
    "    feat_grid = loaded[str(image_size)]\n",
    "    feats = feat_grid.reshape((feat_grid.shape[0]*feat_grid.shape[1], feat_grid.shape[2]))\n",
    "    \n",
    "    # print(feat_grid.shape, feats.shape)\n",
    "    \n",
    "    ids = [i for i in range(id, id + feats.shape[0])]\n",
    "    id += feats.shape[0]\n",
    "    \n",
    "    index.add_items(feats, ids)\n",
    "\n",
    "    for j in range(feats.shape[0]):\n",
    "        patch_dict[ids[j]] = npz_file\n",
    "        \n",
    "index.save_index(f'nn_index_{str(image_size)}.idx')\n",
    "pickle.dump(patch_dict, open(f'patch_dict_{str(image_size)}.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_locations(mask, stride, grid_shape, offsets):\n",
    "    \n",
    "    object_grid_locations = set()\n",
    "\n",
    "    for y in range(grid_shape[0]):\n",
    "        for x in range(grid_shape[1]):\n",
    "            p = (offsets[0] + y * stride + 0.5 * stride, offsets[1] + x * stride + 0.5 * stride)\n",
    "            w = extract_window(mask, p, stride)\n",
    "\n",
    "            # print(np.sum(w))\n",
    "            #if np.sum(w) >= stride * stride * 0.3:\n",
    "            object_grid_locations.add((y, x))\n",
    "\n",
    "    return object_grid_locations\n",
    "\n",
    "test_image_files = glob(\"dataset_1000/test/*/*.jpg\")\n",
    "test_mask_files = glob(\"dataset_1000/test/*/*.mask.png\")\n",
    "\n",
    "test_image_files.sort()\n",
    "test_mask_files.sort()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for i in range(len(test_image_files)):\n",
    "    \n",
    "    image_correct = 0\n",
    "    image_total = 0\n",
    "    \n",
    "    image_file = test_image_files[i]\n",
    "    mask_file = test_mask_files[i]\n",
    "\n",
    "    print(image_file)\n",
    "    \n",
    "    pil_image = Image.open(image_file).convert('RGB')\n",
    "\n",
    "    if pil_image.size[1] > pil_image.size[0]:\n",
    "        resized_image = pil_image.resize((image_size, int(round(pil_image.size[1]/pil_image.size[0] * image_size))))\n",
    "    else:\n",
    "        resized_image = pil_image.resize((int(round(pil_image.size[0]/pil_image.size[1] * image_size)), image_size))\n",
    "\n",
    "    image = np.array(resized_image)\n",
    "        \n",
    "            \n",
    "    pil_mask = Image.open(mask_file).convert('1')\n",
    "\n",
    "    if pil_mask.size[1] > pil_mask.size[0]:\n",
    "        resized_mask = pil_mask.resize((image_size, int(round(pil_mask.size[1]/pil_mask.size[0] * image_size))))\n",
    "    else:\n",
    "        resized_mask = pil_mask.resize((int(round(pil_mask.size[0]/pil_mask.size[1] * image_size)), image_size))\n",
    "        \n",
    "    mask = np.array(resized_mask)\n",
    "    \n",
    "        \n",
    "    margin = window_size-stride\n",
    "    grid_shape = (math.floor((image.shape[0] - margin) / stride), math.floor((image.shape[1] - margin) / stride))\n",
    "    offsets = (round((image.shape[0] - grid_shape[0] * stride)/2), round((image.shape[1] - grid_shape[1] * stride)/2))\n",
    "\n",
    "    grid_locations = list(mask_locations(mask, stride, grid_shape, offsets))\n",
    "    points = [(y*stride + stride/2 + offsets[0], x*stride + stride/2 + offsets[1]) for (y,x) in grid_locations]\n",
    "    print('len(points)', len(points))\n",
    "    \n",
    "    patches = extract_windows(image, points, window_size)\n",
    "    windows = patches.astype(np.float64)\n",
    "\n",
    "    feats = cnn.evalRGB(windows)\n",
    "    feats = feats.reshape((windows.shape[0], feature_dim))\n",
    "    \n",
    "    nn_ids, _ = index.knn_query(feats, 10)\n",
    "    \n",
    "    for foo in nn_ids:\n",
    "        nn_files = [patch_dict.get(q) for q in foo]\n",
    "\n",
    "        for f in nn_files:\n",
    "\n",
    "            a = image_file.split('/')[-2]\n",
    "            b = f.split('/')[-2]\n",
    "\n",
    "            # print(a, b)\n",
    "\n",
    "            if a == b:\n",
    "                image_correct += 1\n",
    "                correct += 1\n",
    "\n",
    "            image_total += 1\n",
    "            total += 1\n",
    "\n",
    "    print(\"score\", image_correct/image_total)\n",
    "    \n",
    "print(\"final score\", correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing with dataset_100\n",
    "672: final score 0.8107003891050584  \n",
    "448: final score 0.8972972972972973  \n",
    "224: final score 0.9666666666666667\n",
    "\n",
    "## testing with dataset_1000\n",
    "224: final score 0.8968137254901961"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
